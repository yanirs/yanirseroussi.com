<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>How hackable are automated coding assessments? | Yanir Seroussi | Data &amp; AI for Startup Impact</title>
<meta name="keywords" content="artificial intelligence, career, hackers, software engineering">
<meta name="description" content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study.">
<meta name="author" content="Yanir Seroussi">
<link rel="canonical" href="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/">
<meta name="google-site-verification" content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU">
<link crossorigin="anonymous" href="/assets/css/stylesheet.0139a50c6e3f53193500e07972ba88238beaf3384629640b34fa4fd38dc956f6.css" integrity="sha256-ATmlDG4/Uxk1AOB5crqII4vq8zhGKWQLNPpP043JVvY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yanirseroussi.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yanirseroussi.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yanirseroussi.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yanirseroussi.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://yanirseroussi.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="How hackable are automated coding assessments?" />
<meta property="og:description" content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/" />
<meta property="og:image" content="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-26T00:03:00+00:00" />
<meta property="article:modified_time" content="2024-02-13T08:24:54+10:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg" />
<meta name="twitter:title" content="How hackable are automated coding assessments?"/>
<meta name="twitter:description" content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Browse Posts",
      "item": "https://yanirseroussi.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "How hackable are automated coding assessments?",
      "item": "https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "How hackable are automated coding assessments?",
  "name": "How hackable are automated coding assessments?",
  "description": "Exploring the hackability of speed-based coding tests, using CodeSignal\u0026rsquo;s Industry Coding Framework as a case study.",
  "keywords": [
    "artificial intelligence", "career", "hackers", "software engineering"
  ],
  "articleBody": "In the essay The Lesson to Unlearn, Paul Graham makes the claim that students are trained to win by hacking bad tests. That is, to get good grades, one has to avoid spending too much time on material that won’t be turned into test questions. Instead, one’s focus has to be on test-specific study. Students are taught that actual learning is less important than maximising grades. That is the lesson to unlearn.1\nEven though the essay is a few years old, it’s been on my mind recently for two reasons. The first reason is that large language models are excelling in standardised tests: I’m impressed by this progress, but it’s also a reminder of the hackability of such tests and the need to employ critical thinking to stay ahead of the AI automation wave. The second reason is that I did a CodeSignal test myself, which led me to think more deeply on the hackability of automated and timed coding assessments. This post discusses my thoughts on the topic, using CodeSignal’s Industry Coding Framework as a case study. However, most of my observations should apply to similar tests.\nWhat are hackable tests? Hacking a test is different from cheating. Hacking entails following the test’s rules, but optimising your work to exploit its weaknesses and increase your score. It doesn’t necessarily entail changing the underlying properties that the test purports to measure. By contrast, cheating entails behaviours that are prohibited by the test’s rules, such as letting someone else do the test for you, or consulting resources that are defined as off limits.\nA test’s hackability isn’t a binary property. Hackability lies on a scale from unhackable to fully hackable, as demonstrated by the following examples and plot.\nSay we take an adult and measure their height every day around the same time, over a period of a month. We can expect the measurements to have low variance. There’s little the test taker can do to significantly increase their height without cheating. The test is a good representation of the property it aims to measure – an unhackable test.\nOn the other end of the scale, say we take the same person and ask them the same set of questions over the course of a month. Our aim is to assess their skills in a subject area such as programming. Given that we’re repeating the same questions, they can find the answers and try to memorise them after each attempt. Assuming they’re sufficiently motivated, we can expect their scores to increase even if they know nothing about programming. This test is highly hackable. It’s hard to say that it accurately reflects the property it purports to measure, i.e., programming skills. This is because scores are strongly influenced by motivation to succeed in the test, as well as short-term memorisation and retrieval abilities.\nAn improvement over the unchanged test is generating variations from a set of possible questions.2 While our test taker would benefit from deeper skills in the subject area, they can also improve their scores by learning to recognise patterns in test questions, managing their time well, and memorising recurring elements. Again, we can expect their scores to improve over time and fail to accurately reflect the skills we care about. This gets us into the familiar territory of standardised testing, a category that I believe CodeSignal’s Industry Coding Assessments fall under. That is, tests that are not fully hackable, but still fall short of reflecting the properties they claim to measure.\nVisualising hackable test scores as a function of time: f(t) = b + h * sqrt(t) + N(0, σ2). Starting from the same baseline b, scores increase with time t due to the hackability factor h that is multiplied by sqrt(t) (ability to improve decays with time). Each test attempt is affected by measurement noise, which comes from a normal distribution with mean zero and variance σ2. I assume that variance and hackability are positively correlated. While this function is made up and missing an upper bound, the shape of the curves should be about right. See notebook for source code. Confessions of a test hacker Before diving into the hackability of CodeSignal’s Industry Coding Framework, here’s a bit of background on my history as a test hacker.\nBack in the day, I got pretty good at hacking tests. I enjoyed learning, but I also enjoyed getting high grades. This goes back to primary and high school and to my undergraduate degree in computer science – I graduated summa cum laude from a well-regarded university. My undergraduate days included hacks such as spending nearly all my waking hours solving past test questions during exam periods, as well as avoiding electives that had a reputation for being excessively time-consuming.\nSimilar test hacking skills were useful when interviewing with big tech companies. Early in my career, I worked with Intel, Qualcomm, and Google, and successfully interviewed with a few other tech companies. On a conceptual level, tech company tests weren’t that different from university tests, except that they were mostly oral (the dreaded whiteboard coding test), and could cover a wider breadth of topics. But even in 2005-2010, many questions leaked online, so I could follow the tried-and-tested hack of preparing by solving old test questions.\nWhile I can do well in standardised timed tests, I never liked them. Despite being hackable, they are stressful, and maximising one’s score requires adequate preparation that is different from learning deeply about the subject matter. Perhaps the most absurd example of this was when I had to take an IELTS exam (a standardised English test) for the second time after completing my PhD, as part of my Australian permanent residency application.3 This was four years after taking the IELTS exam for the first time (in Israel). I spent the intervening years in Australia, authored peer-reviewed papers and a thesis, and gave multiple conference talks. There’s no doubt that my English skills improved over those years, and yet my second IELTS scores were lower.\nWhy were my second IELTS scores lower? Partly because I didn’t prepare for the speaking part of the exam, so I didn’t have much to say when the examiner asked me about my favourite colours and the favourite colours of my friends (yes, for real). I ended up paying the fee to contest the result, and it got bumped up to be closer to my pre-PhD scores. Still, this serves as a salient example of a hackable test. You can improve your IELTS score by getting better at doing IELTS exams, and without any change to your underlying English skills.\nOnce I became an Australian permanent resident, I had to do a driving test to convert my Israeli licence. This was also silly, as I was legally allowed to drive in Australia while I was on a student visa. Those years of driving weren’t enough to automatically convert my licence to the Australian system, so I was subjected to the driving test. While a bit stressful, it wasn’t too bad because driving tests are a close simulation of the skill they aim to measure – driving on streets and highways. As such, they’re not too hackable, though I was careful to signal my intent to the tester in a way that’s somewhat unnatural (e.g., braking and indicating earlier than necessary to avoid getting penalised). I had no issues passing the test.\nFortunately, I managed to avoid convoluted tests in the decade or so since that second IELTS exam. For job applications, I’ve mostly had my skills assessed through custom take-home assignments and paid trial work, e.g., in my long application process with Automattic and my last position with Orkestra, which started as a short-term contract. Those evaluations were less hackable than the whiteboard engineering questions of my early career, and therefore felt like a better reflection of the skills they were assessing.\nOn the hackability of CodeSignal’s Industry Coding Framework Last week, I went through CodeSignal’s Industry Coding Assessment as part of a job application. While I agreed not to share the content of the assessment, there’s plenty I can discuss based on public information from CodeSignal’s website.\nThe whole experience felt like an unpleasant throwback to my old test hacking days in the noughties, but with a shinier user interface. While I’m rusty at standardised code tests, I did what any good test hacker would do: I started my preparation by searching for “Industry Coding Framework” on the web and on Blind, and reading through CodeSignal’s blog and resources. My initial search didn’t yield any unusual hacks, so I followed CodeSignal’s advice and did some of their practice questions. These turned out to be similar to the sort of questions I solved on whiteboards back in the day, except that these days, solutions are automatically scored in a web-based IDE.\nGetting familiar with CodeSignal’s environment and refreshing my speed-solving abilities was definitely helpful when I took the real assessment, and that is a prime indicator of hackability. CodeSignal states that their Industry Coding Framework is designed to evaluate the programming skills of mid-to-senior engineers. These are skills that accrue over years and decades, much like English language skills. The ideal test for such skills shouldn’t be hackable, i.e., scores should be unaffected by repetition of similar tests over a short period. However, on the morning of the test I discovered that CodeSignal’s Industry Coding Assessments are hackable by design.\nWhat I discovered was in a technical brief I initially overlooked, titled Industry Coding Skills Evaluation Framework (a longer version is stored in the Internet Archive). In the brief, they give the following breakdown of questions in their Industry Coding Assessments:\nLevel Expected time in minutes 1 10-15 2 20-30 3 30-60 4 30-60 Adding up the time ranges gives us an estimate of 90-165 minutes to complete the assessment. But the time they give candidates to complete the test is… 90 minutes! In their own words:\nThe maximum allowed completion time for the assessment is 90 minutes; however, candidates are not necessarily expected to complete all tasks within this time limit. While longer assessments allow more accurate measurement of candidate skills, the willingness to complete assessments decreases dramatically for tests longer than 2 hours. Moreover, a major factor in assessing candidates’ skill levels is to see how far they can progress within the given time frame.\nIt makes sense that candidates don’t want to spend too much time on artificial tests. But a better approach would be to design a test that can be completed within the allotted time by skilled candidates who don’t engage in test hacking. Alternatively, they could allow more time and penalise candidates for going over the minimum of 90 minutes. This would make it easier to tell the difference between people who are slightly slower than the cut-off and those who are significantly slower. Implementation speed does matter in the real world, but it’s rarely measured on the order of minutes.\nAs it stands, my opinion is that making speed a key factor in test success makes it hackable because test-specific practice can lead to dramatically better results. CodeSignal’s decision to emphasise speed turns the test into a game like Speedcubing, and a game can be defined as the overcoming of unnecessary obstacles. Gamification may be in vogue, but I believe it’s better to keep it out of the job application process.\nFurther evidence for hackability comes from the fact that CodeSignal limits test attempts over varying time windows. If CodeSignal’s assessments were more like measuring one’s height or basic driving skills, this wouldn’t be needed. Further, this somewhat favours people who are in better assessment shape, e.g., because they’re applying to many jobs and are highly motivated to get them. Sadly, I found a thread on CodeSignal’s General Coding Assessment that says that the same CodeSignal results can be used by multiple companies, which means that people get locked out of opportunities for the time window that’s determined by CodeSignal. Anecdotally, while researching this post, I also discovered that many people dislike CodeSignal and have made similar observations to mine about the validity of their evaluations. Further, when it comes to General Coding Assessments, one can find many tips on test hacking (e.g., on Reddit and GitHub).\nAnother key issue is that the effective time given for the test isn’t 90 minutes. It’s typically two weeks from the time of notification, where one can’t see the test, plus 90 minutes to do the test. The two weeks can be used for extensive test hacking, depending on the test taker’s available time and motivation.\nAs both my available time and motivation were lacking, I didn’t use the full two weeks. I quickly lost interest in solving the same kind of questions I solved around 2005. I also suspected that some of the practice questions provided by CodeSignal had little relevance to the Industry Coding Framework. In addition, I read on Glassdoor and Blind that the company (a top AI lab) that asked me to take the test had ghosted some candidates after they had passed it, so I figured that maximising my test preparation time wasn’t worth it. With more than a week left before the deadline, I decided to take the test and move on.\nBeyond hackability: Other issues with CodeSignal and automated assessments To my surprise, when I clicked the Take Test button, I was given an option to do a demo test. Hiding the demo behind that button feels a bit unfair. I assume that candidates would click the button when they’re ready to take the test, not when they want to do further preparation. But I finished the demo test in 15 out of the allotted 60 minutes, so I felt good enough about it and moved on to the real thing.\nUnfortunately, I ran out of time on the real test and scored 800 / 1000. According to the distribution in the archived version of CodeSignal’s Industry Coding Framework brief, this would have put me at the top 5% of test takers. But I’m not pleased with the result. The code I wrote was horrible and followed practices I’d never follow if I wasn’t trying to optimise for speed. There were also technical issues with the platform that got in my way: The IDE refreshed multiple times and claimed that I had lost connection, and having to use their IDE rather than a notebook environment is also a bit of a pain given the strict time constraints.\nIt’s likely I could have scored higher if I had maximised my test hacking efforts. Spending another week on preparation would have probably made a difference given that the hackability of the test is similar to that of an IELTS exam: Getting from zero to a perfect score is probably impossible over a short time span, but it is possible to nudge the score up by optimising the test-taking strategy and refreshing one’s bag of tricks (the sort of tricks that you don’t have to worry about retrieving quickly from memory under normal circumstances). For example, one relevant preparation step I could have followed was to attempt the sample questions from the Industry Coding Framework brief. I could have even taken it further and used ChatGPT (or another chatbot) to generate variations on the same theme. But as noted, I didn’t feel like it was worth maximising my hacking efforts given the circumstances.\nRegardless of hackability, I believe that the test fails to capture many of the skills it purports to measure. Specifically:\nNo points are given for good design without code that passes the automated tests. This is unlike more manual testing with a human assessor, where partial credit is given for having good ideas but running out of time. Not having to write any tests encourages lazy coding. Normally I’d think through edge cases, but optimising for the test score means that the only edge cases that matter are those that get caught by automated tests. It’s easier to deal with such issues if they get caught rather than spend precious time thinking about them. In real work, you need to spend time testing your code, which often requires more thinking than implementing the core logic. While CodeSignal claims that they test refactoring skills, the test design doesn’t even offer a caricature of real refactoring. In reality, new requirements are added over the course of days, weeks, months, and years – not minutes. And you need to refactor legacy code that runs in production and was written by many people of varying levels of proficiency and time pressures. This is nothing like tweaking throwaway code that you’ve written minutes ago. Putting a high emphasis on implementation speed when aiming to test mid-to-senior developers disadvantages those who have gotten into the habit of avoiding software engineering classic mistakes such as shortchanged quality assurance and code-like-hell programming.4 As noted by Martin Fowler, ignoring internal quality increases the pace of feature delivery early in a project’s life, but slows it down in the longer term (within weeks). Setting a 90-minute time limit on a test that’s supposed to take a minimum of 90 minutes may filter out experienced engineers who have developed good habits and didn’t bother unlearning them for test hacking purposes. This is an instance of the McNamara fallacy – time is easy to measure, but deep skills and good habits aren’t. Unfortunately, CodeSignal is heavily biased towards that which is easy to measure, but rather than admitting these flaws, they make unsupported claims about the effectiveness of their measurement approach (just read the archived version of the brief for a bit of a laugh). Hacking timed tests can be at odds with habits that are needed to develop high-quality feature-rich software. Source: Martin Fowler’s Is High Quality Software Worth the Cost? Closing thoughts: Partial hackability doesn’t imply complete uselessness Hackability is a non-binary measurement. Even hackable tests can be reflective of the properties they’re supposed to measure. As CodeSignal says in their marketing materials, they offer a cost-effective approach to filtering out candidates, at least when compared to manual in-house recruitment. From a hiring perspective, cheap filters are valuable when a company is flooded with qualified candidates, even if such filters have a high false negative rate. The goal is achieved as long as the filter also decreases the false positive rate. Favouring test hackers is a small price to pay for an initial filter – even if you get candidates to optimise for the wrong metrics, this can be corrected with more thoughtful testing down the track. However, turning the application process into a series of games risks alienating some candidates, who won’t bother applying even if they can do the job well.\nAmong other factors, test scores are a function of the test taker’s skills, test design/hackability, and the test taker’s preparation for the specific test.5 I believe that take-home coding assessments and real-work simulations offer a better candidate experience and provide a better signal to companies than artificial time-limited tests like CodeSignal’s Industry Coding Assessments. This is supported by statements from CodeSignal: The brief discussed above explicitly says that “longer assessments allow more accurate measurement of candidate skills”, and they found in their 2023 survey that candidates prefer take-home coding challenges to CodeSignal assessments.6\nMy hope is that this post would help future users of automated coding assessments in general, and CodeSignal’s Industry Coding Framework in particular. Perhaps it’d also nudge CodeSignal to improve their platform. They can do better. I won’t be holding my breath, though – standardised assessments like CodeSignal and IELTS are a part of a massive industry. There’s little incentive for incumbents to change their ways, but it is possible that large language models excelling in test hacking would force their hand.\nSome comments from a Blind thread on coding assessments. Seeing it all as a somewhat-useful game is probably the way to go. Note: I reached out to CodeSignal for a comment on this post, but haven’t heard back after more than a week.\nAs with many Paul Graham essays, I find myself in agreement with some of his ideas and disagreement with others. But hackable tests are definitely a thing, e.g., see teaching to the test and Campbell’s law. ↩︎\nTaking a machine learning analogy, asking the same questions repeatedly is likely to lead to overfitting. Drawing new questions from the same distribution is akin to adding a validation set, while dealing with the sort of problems encountered outside standardised tests is indicative of the generalisation error of the test taker. ↩︎\nIt says a lot about the hackability of higher education that the Australian government requires a PhD graduate from a top Australian university to prove that their English skills haven’t deteriorated after four years in Australia. Similarly, companies that look at educational pedigree but put recent graduates through their own set of tests implicitly distrust the grades given by universities. ↩︎\nThe only time you’re likely to face ridiculous time pressures that are measured in minutes is when something breaks in production. Production issues can be minimised through investment in solid processes and quality over a project’s lifetime. That is, you go slow to go fast and avoid fire-fighting. Take-home exams and real-work simulations are more reflective of the sort of thinking that’s required from senior engineers because good ideas often manifest when you take the time to design a system and avoid jumping into code-like-hell mode. Going with the first thing that comes to mind is a habit that’s better left to chatbots. ↩︎\nPreparation is partly a function of motivation to pass the test, which is a positive indicator despite being unrelated to possessing the skills the test purports to measure. In my case, motivation to maximise the score was lacking, so the company got useful information out of my imperfect score. Why was my motivation lacking? Because the role seemed interesting enough to apply to, but not worth working too hard to get. The opportunity cost of neglecting my other endeavours in favour of test hacking seemed too high. ↩︎\nSee page 11 of the linked survey. Like other materials from CodeSignal, it’s somewhat comical. They state that “candidates view CodeSignal assessments more favorably than timed coding assessments in general (p = 0.034)”, but looking at the table, the mean score given to CodeSignal assessments is 3.41 / 5, while general timed coding assessments were given a mean score of 3.37. That is, a difference of 0.04 – it’s hard to call this practically significant, despite the p-value. Could it be that CodeSignal’s IO psychologists missed the many memos on p-value pitfalls, such as the one by the American Statistical Association? In any case, if they consider the 0.04 difference to be notable, why do they say nothing about the 0.06 difference in favour of take-home coding assignments or the 0.17 difference in favour of coding interviews? Personally, I’d also report the full distribution rather than just the means. It’s easy enough to visualise a five-point scale. ↩︎\n",
  "wordCount" : "3836",
  "inLanguage": "en",
  "image":"https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg","datePublished": "2023-05-26T00:03:00Z",
  "dateModified": "2024-02-13T08:24:54+10:00",
  "author":{
    "@type": "Person",
    "name": "Yanir Seroussi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yanir Seroussi | Data \u0026 AI for Startup Impact",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yanirseroussi.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yanirseroussi.com/" accesskey="h" title="Yanir Seroussi | Data &amp; AI for Startup Impact (Alt + H)">Yanir Seroussi | Data &amp; AI for Startup Impact</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <button id="menu-trigger" aria-haspopup="menu" aria-label="Menu Button">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
                <line x1="3" y1="12" x2="21" y2="12"></line>
                <line x1="3" y1="6" x2="21" y2="6"></line>
                <line x1="3" y1="18" x2="21" y2="18"></line>
            </svg>
        </button>
        <ul class="menu hidden">
            <li>
                <a href="https://yanirseroussi.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/consult/" title="Consulting">
                    <span>Consulting</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      How hackable are automated coding assessments?
    </h1>
    <div class="post-meta"><span title='2023-05-26 00:03:00 +0000 UTC'>May 26, 2023</span>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" srcset="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_360x0_resize_q75_box.jpg 360w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_480x0_resize_q75_box.jpg 480w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_720x0_resize_q75_box.jpg 720w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg 1023w" 
            sizes="(min-width: 768px) 720px, 100vw" src="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg" alt="Bing&#39;s interpretation of _an otter coding furiously in an attempt to pass a coding test_" 
            width="1023" height="914">
        <p>Bing&rsquo;s interpretation of <em>an otter coding furiously in an attempt to pass a coding test</em></p>
</figure>
  <div class="post-content"><p>In the essay <a href="http://www.paulgraham.com/lesson.html" target="_blank" rel="noopener">The Lesson to Unlearn</a>, Paul Graham makes the claim that students are trained to win by hacking bad tests. That is, to get good grades, one has to avoid spending too much time on material that won&rsquo;t be turned into test questions. Instead, one&rsquo;s focus has to be on test-specific study. Students are taught that actual learning is less important than maximising grades. That is the lesson to unlearn.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>Even though the essay is a few years old, it&rsquo;s been on my mind recently for two reasons. The first reason is that <a href="https://openai.com/product/gpt-4" target="_blank" rel="noopener">large language models are excelling in standardised tests</a>: <a href="https://yanirseroussi.com/2022/12/11/chatgpt-is-transformative-ai/">I&rsquo;m impressed by this progress</a>, but it&rsquo;s also a reminder of the hackability of such tests and <a href="https://yanirseroussi.com/2023/04/21/remaining-relevant-as-a-small-language-model/">the need to employ critical thinking to stay ahead of the AI automation wave</a>. The second reason is that I did a <a href="https://codesignal.com/" target="_blank" rel="noopener">CodeSignal</a> test myself, which led me to think more deeply on the hackability of automated and timed coding assessments. This post discusses my thoughts on the topic, using CodeSignal&rsquo;s Industry Coding Framework as a case study. However, most of my observations should apply to similar tests.</p>
<h2 id="what-are-hackable-tests">What are hackable tests?<a hidden class="anchor" aria-hidden="true" href="#what-are-hackable-tests">#</a></h2>
<p>Hacking a test is different from cheating. Hacking entails following the test&rsquo;s rules, but optimising your work to exploit its weaknesses and increase your score. It doesn&rsquo;t necessarily entail changing the underlying properties that the test purports to measure. By contrast, cheating entails behaviours that are prohibited by the test&rsquo;s rules, such as letting someone else do the test for you, or consulting resources that are defined as off limits.</p>
<p>A test&rsquo;s hackability isn&rsquo;t a binary property. Hackability lies on a scale from unhackable to fully hackable, as demonstrated by the following examples and plot.</p>
<p>Say we take an adult and measure their height every day around the same time, over a period of a month. We can expect the measurements to have low variance. There&rsquo;s little the test taker can do to significantly increase their height without cheating. The test is a good representation of the property it aims to measure – <strong>an unhackable test.</strong></p>
<p>On the other end of the scale, say we take the same person and ask them the same set of questions over the course of a month. Our aim is to assess their skills in a subject area such as programming. Given that we&rsquo;re repeating the same questions, they can find the answers and try to memorise them after each attempt. Assuming they&rsquo;re sufficiently motivated, we can expect their scores to increase even if they know nothing about programming. <strong>This test is highly hackable.</strong> It&rsquo;s hard to say that it accurately reflects the property it purports to measure, i.e., programming skills. This is because scores are strongly influenced by motivation to succeed in the test, as well as short-term memorisation and retrieval abilities.</p>
<p>An improvement over the unchanged test is generating variations from a set of possible questions.<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> While our test taker would benefit from deeper skills in the subject area, they can also improve their scores by learning to recognise patterns in test questions, managing their time well, and memorising recurring elements. Again, we can expect their scores to improve over time and fail to accurately reflect the skills we care about. This gets us into the familiar territory of standardised testing, a category that I believe <a href="https://codesignal.com/resource/industry-coding-data-sheet/" target="_blank" rel="noopener">CodeSignal&rsquo;s Industry Coding Assessments</a> fall under. That is, tests that are not fully hackable, but still fall short of reflecting the properties they claim to measure.</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
  
  
  



<figure>
  <a href="test-hackability-plot.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_1080x0_resize_box_3.png 1080w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_1500x0_resize_box_3.png 1500w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_800x0_resize_box_3.png"
        
      
        alt="Plot showing different hackability curves, based on f(t) = b &#43; h * sqrt(t) &#43; N(0, σ ** 2)"loading="lazy"
    />
  </a><figcaption>
        <p>Visualising hackable test scores as a function of time: <code>f(t) = b + h * sqrt(t) + N(0, σ<sup>2</sup>)</code>. Starting from the same baseline <code>b</code>, scores increase with time <code>t</code> due to the hackability factor <code>h</code> that is multiplied by <code>sqrt(t)</code> (ability to improve decays with time). Each test attempt is affected by measurement noise, which comes from a normal distribution with mean zero and variance <code>σ<sup>2</sup></code>. I assume that variance and hackability are positively correlated. While this function is made up and missing an upper bound, the shape of the curves should be about right. See <a href="https://www.kaggle.com/code/yanirseroussi/test-hackability-plots/notebook" target="_blank" rel="noopener">notebook</a> for source code.
          </p>
      </figcaption>
</figure>

<h2 id="confessions-of-a-test-hacker">Confessions of a test hacker<a hidden class="anchor" aria-hidden="true" href="#confessions-of-a-test-hacker">#</a></h2>
<p>Before diving into the hackability of CodeSignal&rsquo;s Industry Coding Framework, here&rsquo;s a bit of background on my history as a test hacker.</p>
<p>Back in the day, I got pretty good at hacking tests. I enjoyed learning, but I also enjoyed getting high grades. This goes back to primary and high school and to my undergraduate degree in computer science – I graduated summa cum laude from <a href="https://en.wikipedia.org/wiki/Technion_%E2%80%93_Israel_Institute_of_Technology" target="_blank" rel="noopener">a well-regarded university</a>. My undergraduate days included hacks such as spending nearly all my waking hours solving past test questions during exam periods, as well as avoiding electives that had a reputation for being excessively time-consuming.</p>
<p>Similar test hacking skills were useful when interviewing with big tech companies. Early in my career, I worked with Intel, Qualcomm, and Google, and successfully interviewed with a few other tech companies. On a conceptual level, tech company tests weren&rsquo;t that different from university tests, except that they were mostly oral (the dreaded whiteboard coding test), and could cover a wider breadth of topics. But even in 2005-2010, many questions leaked online, so I could follow the tried-and-tested hack of preparing by solving old test questions.</p>
<p>While I can do well in standardised timed tests, I never liked them. Despite being hackable, they are stressful, and maximising one&rsquo;s score requires adequate preparation that is different from learning deeply about the subject matter. Perhaps the most absurd example of this was when I had to take an IELTS exam (<a href="https://en.wikipedia.org/wiki/International_English_Language_Testing_System" target="_blank" rel="noopener">a standardised English test</a>) for the second time after completing my PhD, as part of my Australian permanent residency application.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> This was four years after taking the IELTS exam for the first time (in Israel). I spent the intervening years in Australia, authored peer-reviewed papers and a thesis, and gave multiple conference talks. There&rsquo;s no doubt that my English skills improved over those years, and yet my second IELTS scores were lower.</p>
<p>Why were my second IELTS scores lower? Partly because I didn&rsquo;t prepare for the speaking part of the exam, so I didn&rsquo;t have much to say when the examiner asked me about my favourite colours and the favourite colours of my friends (yes, for real). I ended up paying the fee to contest the result, and it got bumped up to be closer to my pre-PhD scores. Still, this serves as a salient example of a hackable test. You can improve your IELTS score by getting better at doing IELTS exams, and without any change to your underlying English skills.</p>
<p>Once I became an Australian permanent resident, I had to do a driving test to convert my Israeli licence. This was also silly, as I was legally allowed to drive in Australia while I was on a student visa. Those years of driving weren&rsquo;t enough to automatically convert my licence to the Australian system, so I was subjected to the driving test. While a bit stressful, it wasn&rsquo;t too bad because driving tests are a close simulation of the skill they aim to measure – driving on streets and highways. As such, they&rsquo;re not too hackable, though I was careful to signal my intent to the tester in a way that&rsquo;s somewhat unnatural (e.g., braking and indicating earlier than necessary to avoid getting penalised). I had no issues passing the test.</p>
<p>Fortunately, I managed to avoid convoluted tests in the decade or so since that second IELTS exam. For job applications, I&rsquo;ve mostly had my skills assessed through custom take-home assignments and paid trial work, e.g., in <a href="https://yanirseroussi.com/2017/07/29/my-10-step-path-to-becoming-a-remote-data-scientist-with-automattic/">my long application process with Automattic</a> and <a href="https://yanirseroussi.com/2022/06/06/the-mission-matters-moving-to-climate-tech-as-a-data-scientist/">my last position with Orkestra, which started as a short-term contract</a>. Those evaluations were less hackable than the whiteboard engineering questions of my early career, and therefore felt like a better reflection of the skills they were assessing.</p>
<h2 id="on-the-hackability-of-codesignals-industry-coding-framework">On the hackability of CodeSignal&rsquo;s Industry Coding Framework<a hidden class="anchor" aria-hidden="true" href="#on-the-hackability-of-codesignals-industry-coding-framework">#</a></h2>
<p>Last week, I went through CodeSignal&rsquo;s Industry Coding Assessment as part of a job application. While I agreed not to share the content of the assessment, there&rsquo;s plenty I can discuss based on public information from CodeSignal&rsquo;s website.</p>
<p>The whole experience felt like an unpleasant throwback to my old test hacking days in the noughties, but with a shinier user interface. While I&rsquo;m rusty at standardised code tests, I did what any good test hacker would do: I started my preparation by searching for <em>&ldquo;Industry Coding Framework&rdquo;</em> on the web and on Blind, and reading through CodeSignal&rsquo;s blog and resources. My initial search didn&rsquo;t yield any unusual hacks, so I followed <a href="https://codesignal.com/blog/interview-prep/coding-assessment-checklist/" target="_blank" rel="noopener">CodeSignal&rsquo;s advice</a> and did some of their practice questions. These turned out to be similar to the sort of questions I solved on whiteboards back in the day, except that these days, solutions are automatically scored in a web-based IDE.</p>
<p>Getting familiar with CodeSignal&rsquo;s environment and refreshing my speed-solving abilities was definitely helpful when I took the real assessment, <strong>and that is a prime indicator of hackability</strong>. CodeSignal states that their Industry Coding Framework is designed to evaluate the programming skills of mid-to-senior engineers. These are skills that accrue over years and decades, much like English language skills. The ideal test for such skills shouldn&rsquo;t be hackable, i.e., scores should be unaffected by repetition of similar tests over a short period. However, on the morning of the test I discovered that <strong>CodeSignal&rsquo;s Industry Coding Assessments are hackable by design</strong>.</p>
<p>What I discovered was in a technical brief I initially overlooked, titled <a href="https://discover.codesignal.com/rs/659-AFH-023/images/Industry-Coding-Skills-Evaluation-Framework-CodeSignal-Skills-Evaluation-Lab-Short.pdf" target="_blank" rel="noopener">Industry Coding Skills Evaluation Framework</a> (<a href="https://web.archive.org/web/20230321142915/https://discover.codesignal.com/rs/659-AFH-023/images/Industry-Coding-Skills-Evaluation-Framework-CodeSignal-Skills-Evaluation-Lab-Short.pdf" target="_blank" rel="noopener">a longer version is stored in the Internet Archive</a>). In the brief, they give the following breakdown of questions in their Industry Coding Assessments:</p>
<table style="width: fit-content; margin-left: auto; margin-right: auto;">
  <tr>
    <th>Level</th>
    <th>Expected time in minutes</th>
  </tr>
  <tr>
    <td>1</td>
    <td>10-15</td>
  </tr>
  <tr>
    <td>2</td>
    <td>20-30</td>
  </tr>
  <tr>
    <td>3</td>
    <td>30-60</td>
  </tr>
  <tr>
    <td>4</td>
    <td>30-60</td>
  </tr>
</table>
<p>Adding up the time ranges gives us an estimate of 90-165 minutes to complete the assessment. But the time they give candidates to complete the test is&hellip; 90 minutes! In their own words:</p>
<blockquote>
<p>The maximum allowed completion time for the assessment is 90 minutes; however, candidates are not necessarily expected to complete all tasks within this time limit. While longer assessments allow more accurate measurement of candidate skills, the willingness to complete assessments decreases dramatically for tests longer than 2 hours. Moreover, a major factor in assessing candidates&rsquo; skill levels is to see how far they can progress within the given time frame.</p>
</blockquote>
<p>It makes sense that candidates don&rsquo;t want to spend too much time on artificial tests. But a better approach would be to design a test that can be completed within the allotted time by skilled candidates who don&rsquo;t engage in test hacking. Alternatively, they could allow more time and penalise candidates for going over the minimum of 90 minutes. This would make it easier to tell the difference between people who are slightly slower than the cut-off and those who are significantly slower. Implementation speed does matter in the real world, but it&rsquo;s rarely measured on the order of minutes.</p>
<p>As it stands, my opinion is that <strong>making speed a key factor in test success makes it hackable because test-specific practice can lead to dramatically better results.</strong> CodeSignal&rsquo;s decision to emphasise speed turns the test into a game like <a href="https://en.wikipedia.org/wiki/Speedcubing" target="_blank" rel="noopener">Speedcubing</a>, and a game can be defined as <a href="https://en.wikipedia.org/wiki/Lusory_attitude" target="_blank" rel="noopener">the overcoming of unnecessary obstacles</a>. Gamification may be in vogue, but I believe it&rsquo;s better to keep it out of the job application process.</p>
<p>Further evidence for hackability comes from the fact that <a href="https://support.codesignal.com/hc/en-us/articles/11635510785047-What-is-a-cooldown-period-and-how-does-it-impact-my-ability-to-take-an-assessment-" target="_blank" rel="noopener">CodeSignal limits test attempts over varying time windows</a>. If CodeSignal&rsquo;s assessments were more like measuring one&rsquo;s height or basic driving skills, this wouldn&rsquo;t be needed. Further, this somewhat favours people who are in better assessment shape, e.g., because they&rsquo;re applying to many jobs and are highly motivated to get them. Sadly, <a href="https://www.reddit.com/r/csMajors/comments/ighloy/can_i_retake_the_codesignal_test_within_14_days/" target="_blank" rel="noopener">I found a thread on CodeSignal&rsquo;s General Coding Assessment</a> that says that the same CodeSignal results can be used by multiple companies, which means that people get locked out of opportunities for the time window that&rsquo;s determined by CodeSignal. Anecdotally, while researching this post, I also discovered that <a href="https://www.reddit.com/r/csMajors/comments/12uq2pc/psa_2023_codesignal_changes/" target="_blank" rel="noopener">many people dislike CodeSignal</a> and <a href="https://www.reddit.com/r/cscareerquestions/comments/q0zle4/when_the_hell_did_leetcode_and_codesignal_become/" target="_blank" rel="noopener">have made similar observations to mine about the validity of their evaluations</a>. Further, when it comes to General Coding Assessments, one can find many tips on test hacking (e.g., on <a href="https://www.reddit.com/r/cscareerquestions/comments/iqy99x/codesignal_tips_from_someone_with_844_843/" target="_blank" rel="noopener">Reddit</a> and <a href="https://github.com/Leader-board/OA-and-Interviews/" target="_blank" rel="noopener">GitHub</a>).</p>
<p>Another key issue is that the effective time given for the test isn&rsquo;t 90 minutes. It&rsquo;s typically <a href="https://support.codesignal.com/hc/en-us/articles/9539278064919-Quick-Start-Guide-Pre-Screen" target="_blank" rel="noopener">two weeks from the time of notification</a>, where one can&rsquo;t see the test, plus 90 minutes to do the test. The two weeks can be used for extensive test hacking, depending on the test taker&rsquo;s available time and motivation.</p>
<p>As both my available time and motivation were lacking, I didn&rsquo;t use the full two weeks. I quickly lost interest in solving the same kind of questions I solved around 2005. I also suspected that some of the practice questions provided by CodeSignal had little relevance to the Industry Coding Framework. In addition, I read on Glassdoor and Blind that the company (a top AI lab) that asked me to take the test had ghosted some candidates after they had passed it, so I figured that maximising my test preparation time wasn&rsquo;t worth it. With more than a week left before the deadline, I decided to take the test and move on.</p>
<h2 id="beyond-hackability-other-issues-with-codesignal-and-automated-assessments">Beyond hackability: Other issues with CodeSignal and automated assessments<a hidden class="anchor" aria-hidden="true" href="#beyond-hackability-other-issues-with-codesignal-and-automated-assessments">#</a></h2>
<p>To my surprise, when I clicked the <em>Take Test</em> button, I was given an option to do a demo test. Hiding the demo behind that button feels a bit unfair. I assume that candidates would click the button when they&rsquo;re ready to take the test, not when they want to do further preparation. But I finished the demo test in 15 out of the allotted 60 minutes, so I felt good enough about it and moved on to the real thing.</p>
<p>Unfortunately, I ran out of time on the real test and scored 800 / 1000. According to the distribution in the archived version of CodeSignal&rsquo;s Industry Coding Framework brief, this would have put me at the top 5% of test takers. But I&rsquo;m not pleased with the result. The code I wrote was horrible and followed practices I&rsquo;d never follow if I wasn&rsquo;t trying to optimise for speed. There were also technical issues with the platform that got in my way: The IDE refreshed multiple times and claimed that I had lost connection, and having to use their IDE rather than a notebook environment is also a bit of a pain given the strict time constraints.</p>
<p>It&rsquo;s likely I could have scored higher if I had maximised my test hacking efforts. Spending another week on preparation would have probably made a difference given that the hackability of the test is similar to that of an IELTS exam: Getting from zero to a perfect score is probably impossible over a short time span, but it is possible to nudge the score up by optimising the test-taking strategy and refreshing one&rsquo;s bag of tricks (the sort of tricks that you don&rsquo;t have to worry about retrieving quickly from memory under normal circumstances). For example, one relevant preparation step I could have followed was to attempt the sample questions from the Industry Coding Framework brief. I could have even taken it further and used ChatGPT (or another chatbot) to generate variations on the same theme. But as noted, I didn&rsquo;t feel like it was worth maximising my hacking efforts given the circumstances.</p>
<p>Regardless of hackability, I believe that the test fails to capture many of the skills it purports to measure. Specifically:</p>
<ul>
<li>No points are given for good design without code that passes the automated tests. This is unlike more manual testing with a human assessor, where partial credit is given for having good ideas but running out of time.</li>
<li>Not having to write any tests encourages lazy coding. Normally I&rsquo;d think through edge cases, but optimising for the test score means that the only edge cases that matter are those that get caught by automated tests. It&rsquo;s easier to deal with such issues if they get caught rather than spend precious time thinking about them. In real work, you need to spend time testing your code, which often requires more thinking than implementing the core logic.</li>
<li>While CodeSignal claims that they test refactoring skills, the test design doesn&rsquo;t even offer a caricature of real refactoring. In reality, new requirements are added over the course of days, weeks, months, and years – not minutes. And you need to refactor legacy code that runs in production and was written by many people of varying levels of proficiency and time pressures. This is nothing like tweaking throwaway code that you&rsquo;ve written minutes ago.</li>
<li>Putting a high emphasis on implementation speed when aiming to test mid-to-senior developers disadvantages those who have gotten into the habit of avoiding <a href="https://smallbusinessprogramming.com/steve-mcconnells-classic-software-mistakes-revisited/" target="_blank" rel="noopener">software engineering classic mistakes</a> such as shortchanged quality assurance and code-like-hell programming.<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> As <a href="https://martinfowler.com/articles/is-quality-worth-cost.html" target="_blank" rel="noopener">noted by Martin Fowler</a>, ignoring internal quality increases the pace of feature delivery early in a project&rsquo;s life, but slows it down in the longer term (within weeks). Setting a 90-minute time limit on a test that&rsquo;s supposed to take a minimum of 90 minutes may filter out experienced engineers who have developed good habits and didn&rsquo;t bother unlearning them for test hacking purposes. This is an instance of <a href="https://en.wikipedia.org/wiki/McNamara_fallacy" target="_blank" rel="noopener">the McNamara fallacy</a> – time is easy to measure, but deep skills and good habits aren&rsquo;t. Unfortunately, CodeSignal is heavily biased towards that which is easy to measure, but rather than admitting these flaws, they make unsupported claims about the effectiveness of their measurement approach (just read the archived version of the brief for a bit of a laugh).</li>
</ul>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="internal-quality-functionality-over-time.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time.png 857w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_800x0_resize_box_3.png"
        
      
        alt="Graph showing how higher internal quality leads to more cumulative functionality"loading="lazy"
    />
  </a><figcaption>
        <p>Hacking timed tests can be at odds with habits that are needed to develop high-quality feature-rich software. Source: <a href="https://martinfowler.com/articles/is-quality-worth-cost.html" target="_blank" rel="noopener">Martin Fowler&rsquo;s Is High Quality Software Worth the Cost?</a>
          </p>
      </figcaption>
</figure>

<h2 id="closing-thoughts-partial-hackability-doesnt-imply-complete-uselessness">Closing thoughts: Partial hackability doesn&rsquo;t imply complete uselessness<a hidden class="anchor" aria-hidden="true" href="#closing-thoughts-partial-hackability-doesnt-imply-complete-uselessness">#</a></h2>
<p>Hackability is a non-binary measurement. Even hackable tests can be reflective of the properties they&rsquo;re supposed to measure. As CodeSignal says in their marketing materials, they offer a cost-effective approach to filtering out candidates, at least when compared to manual in-house recruitment. From a hiring perspective, cheap filters are valuable when a company is flooded with qualified candidates, even if such filters have a high false negative rate. The goal is achieved as long as the filter also decreases the false positive rate. Favouring test hackers is a small price to pay for an initial filter – even if you get candidates to optimise for the wrong metrics, this can be corrected with more thoughtful testing down the track. However, turning the application process into a series of games risks alienating some candidates, who won&rsquo;t bother applying even if they can do the job well.</p>
<p>Among other factors, test scores are a function of the test taker&rsquo;s skills, test design/hackability, and the test taker&rsquo;s preparation for the specific test.<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> I believe that take-home coding assessments and real-work simulations offer a better candidate experience and provide a better signal to companies than artificial time-limited tests like CodeSignal&rsquo;s Industry Coding Assessments. This is supported by statements from CodeSignal: The brief discussed above explicitly says that <em>&ldquo;longer assessments allow more accurate measurement of candidate skills&rdquo;</em>, and they found in their <a href="https://discover.codesignal.com/rs/659-AFH-023/images/2023-State-of-Engineer-Hiring-Survey-CodeSignal.pdf" target="_blank" rel="noopener">2023 survey</a> that candidates prefer take-home coding challenges to CodeSignal assessments.<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<p>My hope is that this post would help future users of automated coding assessments in general, and CodeSignal&rsquo;s Industry Coding Framework in particular. Perhaps it&rsquo;d also nudge CodeSignal to improve their platform. They can do better. I won&rsquo;t be holding my breath, though – standardised assessments like CodeSignal and IELTS are a part of a massive industry. There&rsquo;s little incentive for incumbents to change their ways, but it is possible that large language models excelling in test hacking would force their hand.</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
  
  
    
  
  
  



<figure>
  <a href="blind-code-assessment-game.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_1080x0_resize_box_3.png 1080w,
            
          
            
              https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game.png 1244w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_800x0_resize_box_3.png"
        
      
        alt="Screenshot from a Blind thread on coding assessments"loading="lazy"
    />
  </a><figcaption>
        <p>Some comments from a <a href="https://www.teamblind.com/post/Thank-you-for-fcking-up-the-coding-industry-GchJZKmF" target="_blank" rel="noopener">Blind thread on coding assessments</a>. Seeing it all as a somewhat-useful game is probably the way to go.
          </p>
      </figcaption>
</figure>

<p><small><em>Note: I reached out to CodeSignal for a comment on this post, but haven&rsquo;t heard back after more than a week.</em></small></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>As with many Paul Graham essays, I find myself in agreement with some of his ideas and disagreement with others. But hackable tests are definitely a thing, e.g., see <a href="https://en.wikipedia.org/wiki/Teaching_to_the_test" target="_blank" rel="noopener">teaching to the test</a> and <a href="https://en.wikipedia.org/wiki/Campbell%27s_law" target="_blank" rel="noopener">Campbell&rsquo;s law</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Taking a machine learning analogy, asking the same questions repeatedly is likely to lead to <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="noopener">overfitting</a>. Drawing new questions from the same distribution is akin to adding a validation set, while dealing with the sort of problems encountered outside standardised tests is indicative of <a href="https://en.wikipedia.org/wiki/Generalization_error" target="_blank" rel="noopener">the generalisation error</a> of the test taker.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>It says a lot about the hackability of higher education that the Australian government requires a PhD graduate from a top Australian university to prove that their English skills haven&rsquo;t deteriorated after four years in Australia. Similarly, companies that look at educational pedigree but put recent graduates through their own set of tests implicitly distrust the grades given by universities.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>The only time you&rsquo;re likely to face ridiculous time pressures that are measured in minutes is when something breaks in production. Production issues can be minimised through investment in solid processes and quality over a project&rsquo;s lifetime. That is, you go slow to go fast and avoid fire-fighting. Take-home exams and real-work simulations are more reflective of the sort of thinking that&rsquo;s required from senior engineers because good ideas often manifest when you take the time to design a system and avoid jumping into code-like-hell mode. Going with the first thing that comes to mind is a habit that&rsquo;s better left to chatbots.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>Preparation is partly a function of motivation to pass the test, which is a positive indicator despite being unrelated to possessing the skills the test purports to measure. In my case, motivation to maximise the score was lacking, so the company got useful information out of my imperfect score. Why was my motivation lacking? Because the role seemed interesting enough to apply to, but not worth working too hard to get. The opportunity cost of neglecting my other endeavours in favour of test hacking seemed too high.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>See page 11 of the linked survey. Like other materials from CodeSignal, it&rsquo;s somewhat comical. They state that <em>&ldquo;candidates view CodeSignal assessments more favorably than timed coding assessments in general (p = 0.034)&rdquo;</em>, but looking at the table, the mean score given to CodeSignal assessments is 3.41 / 5, while general timed coding assessments were given a mean score of 3.37. That is, a difference of 0.04 – it&rsquo;s hard to call this <a href="https://en.wikipedia.org/wiki/Clinical_significance" target="_blank" rel="noopener">practically significant</a>, despite the p-value. Could it be that CodeSignal&rsquo;s <a href="https://codesignal.com/solutions/io-psychologists/" target="_blank" rel="noopener">IO psychologists</a> missed the many memos on p-value pitfalls, such as <a href="https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf" target="_blank" rel="noopener">the one by the American Statistical Association</a>? In any case, if they consider the 0.04 difference to be notable, why do they say nothing about the 0.06 difference in favour of take-home coding assignments or the 0.17 difference in favour of coding interviews? Personally, I&rsquo;d also report the full distribution rather than just the means. It&rsquo;s easy enough to visualise a five-point scale.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://yanirseroussi.com/tags/artificial-intelligence/">Artificial Intelligence</a></li>
      <li><a href="https://yanirseroussi.com/tags/career/">Career</a></li>
      <li><a href="https://yanirseroussi.com/tags/hackers/">Hackers</a></li>
      <li><a href="https://yanirseroussi.com/tags/software-engineering/">Software Engineering</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on x"
            href="https://x.com/intent/tweet/?text=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&amp;hashtags=artificialintelligence%2ccareer%2chackers%2csoftwareengineering">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&amp;title=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;summary=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;source=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&title=How%20hackable%20are%20automated%20coding%20assessments%3f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on whatsapp"
            href="https://api.whatsapp.com/send?text=How%20hackable%20are%20automated%20coding%20assessments%3f%20-%20https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on telegram"
            href="https://telegram.me/share/url?text=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=How%20hackable%20are%20automated%20coding%20assessments%3f&u=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>

<a href="/contact/#mailing-list-email" target="_blank" aria-label="subscribe to mailing list" class="mailing-list-link" id="mailing-list-link">
  Subscribe
</a>

<script>
  
  const mailingListButton = document.getElementById("mailing-list-link");
  window.onscroll = function () {
    if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
      mailingListButton.style.visibility = "visible";
      mailingListButton.style.opacity = "1";
    } else {
      mailingListButton.style.visibility = "hidden";
      mailingListButton.style.opacity = "0";
    }
  };
</script>




<div class="mailing-list-container">
  <script src="https://f.convertkit.com/ckjs/ck.5.js"></script>
  <form
    class="mailing-list seva-form formkit-form"
    action="https://app.convertkit.com/forms/6549537/subscriptions"
    method="post"
    data-sv-form="6549537"
    data-uid="9157759fce"
    data-format="inline"
    data-version="5"
    data-options='{&#34;settings&#34;:{&#34;after_subscribe&#34;:{&#34;action&#34;:&#34;message&#34;,&#34;redirect_url&#34;:&#34;&#34;,&#34;success_message&#34;:&#34;Success! Now check your email to confirm your subscription.&#34;},&#34;recaptcha&#34;:{&#34;enabled&#34;:false},&#34;return_visitor&#34;:{&#34;action&#34;:&#34;show&#34;,&#34;custom_content&#34;:&#34;&#34;}},&#34;version&#34;:&#34;5&#34;}'
  >
    <div data-style="clean">
      <ul class="formkit-alert formkit-alert-error" data-element="errors" data-group="alert"></ul>
      <div data-element="fields" data-stacked="false">
        <label for="mailing-list-email">Get weekly posts in your mailbox</label>
        <input
          id="mailing-list-email"
          name="email_address"
          aria-label="Email address"
          placeholder="Email address"
          required=""
          type="email"
        >
        
        <button data-element="submit">Subscribe</button>
      </div>
    </div>
  </form>
  
  <div class="footer">
    Alternatively, <a href="https://yanirseroussi.com/index.xml">subscribe to RSS feed</a>.
  </div>
  
</div>


<section class="comment-section">
  

  <p class="post-content contact-cta">
    Public comments are closed, but I love hearing from readers. Feel free to
    <a href="/contact/" target="_blank">contact me</a> with your thoughts.
  </p>

  
  
  
  

  
</section>



</article>
    </main>
    <div class="global-footer">
  <div class="footer">
    <span>Text and figures licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener">CC BY-NC-ND 4.0</a> by <a href="https://yanirseroussi.com/about/">Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
    <span>
      Powered by
      <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
      <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
  </div>
</div>

<script>
  
  const menuTrigger = document.querySelector("#menu-trigger");
  const menuElem = document.querySelector(".menu");
  menuTrigger.addEventListener("click", function () {
    menuElem.classList.toggle("hidden");
  });
  document.body.addEventListener('click', function (event) {
    if (!menuTrigger.contains(event.target)) {
      menuElem.classList.add("hidden");
    }
  });
</script>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
