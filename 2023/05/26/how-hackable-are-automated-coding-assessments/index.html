<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How hackable are automated coding assessments? | Yanir Seroussi | Engineering Data Science & More</title>
<meta name=keywords content="artificial intelligence,career,hackers,software engineering"><meta name=description content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study."><meta name=author content="Yanir Seroussi"><link rel=canonical href=https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/><meta name=google-site-verification content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU"><link crossorigin=anonymous href=/assets/css/stylesheet.6fb9fcf3671a76afec60509d26e3f0084405763b2a64fe4e9d447c94605f7822.css integrity="sha256-b7n882cadq/sYFCdJuPwCEQFdjsqZP5OnUR8lGBfeCI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://yanirseroussi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yanirseroussi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yanirseroussi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://yanirseroussi.com/apple-touch-icon.png><link rel=mask-icon href=https://yanirseroussi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="How hackable are automated coding assessments?"><meta property="og:description" content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study."><meta property="og:type" content="article"><meta property="og:url" content="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/"><meta property="og:image" content="https://yanirseroussi.com/otter-coding-furiously.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-26T00:03:00+00:00"><meta property="article:modified_time" content="2023-05-26T13:08:24+10:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yanirseroussi.com/otter-coding-furiously.jpg"><meta name=twitter:title content="How hackable are automated coding assessments?"><meta name=twitter:description content="Exploring the hackability of speed-based coding tests, using CodeSignal&rsquo;s Industry Coding Framework as a case study."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"How hackable are automated coding assessments?","item":"https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How hackable are automated coding assessments?","name":"How hackable are automated coding assessments?","description":"Exploring the hackability of speed-based coding tests, using CodeSignal\u0026rsquo;s Industry Coding Framework as a case study.","keywords":["artificial intelligence","career","hackers","software engineering"],"articleBody":"In the essay The Lesson to Unlearn, Paul Graham makes the claim that students are trained to win by hacking bad tests. That is, to get good grades, one has to avoid spending too much time on material that won’t be turned into test questions. Instead, one’s focus has to be on test-specific study. Students are taught that actual learning is less important than maximising grades. That is the lesson to unlearn.1\nEven though the essay is a few years old, it’s been on my mind recently for two reasons. The first reason is that large language models are excelling in standardised tests: I’m impressed by this progress, but it’s also a reminder of the hackability of such tests and the need to employ critical thinking to stay ahead of the AI automation wave. The second reason is that I did a CodeSignal test myself, which led me to think more deeply on the hackability of automated and timed coding assessments. This post discusses my thoughts on the topic, using CodeSignal’s Industry Coding Framework as a case study. However, most of my observations should apply to similar tests.\nWhat are hackable tests? Hacking a test is different from cheating. Hacking entails following the test’s rules, but optimising your work to exploit its weaknesses and increase your score. It doesn’t necessarily entail changing the underlying properties that the test purports to measure. By contrast, cheating entails behaviours that are prohibited by the test’s rules, such as letting someone else do the test for you, or consulting resources that are defined as off limits.\nA test’s hackability isn’t a binary property. Hackability lies on a scale from unhackable to fully hackable, as demonstrated by the following examples and plot.\nSay we take an adult and measure their height every day around the same time, over a period of a month. We can expect the measurements to have low variance. There’s little the test taker can do to significantly increase their height without cheating. The test is a good representation of the property it aims to measure – an unhackable test.\nOn the other end of the scale, say we take the same person and ask them the same set of questions over the course of a month. Our aim is to assess their skills in a subject area such as programming. Given that we’re repeating the same questions, they can find the answers and try to memorise them after each attempt. Assuming they’re sufficiently motivated, we can expect their scores to increase even if they know nothing about programming. This test is highly hackable. It’s hard to say that it accurately reflects the property it purports to measure, i.e., programming skills. This is because scores are strongly influenced by motivation to succeed in the test, as well as short-term memorisation and retrieval abilities.\nAn improvement over the unchanged test is generating variations from a set of possible questions.2 While our test taker would benefit from deeper skills in the subject area, they can also improve their scores by learning to recognise patterns in test questions, managing their time well, and memorising recurring elements. Again, we can expect their scores to improve over time and fail to accurately reflect the skills we care about. This gets us into the familiar territory of standardised testing, a category that I believe CodeSignal’s Industry Coding Assessments fall under. That is, tests that are not fully hackable, but still fall short of reflecting the properties they claim to measure.\nVisualising hackable test scores as a function of time: f(t) = b + h * sqrt(t) + N(0, σ2). Starting from the same baseline b, scores increase with time t due to the hackability factor h that is multiplied by sqrt(t) (ability to improve decays with time). Each test attempt is affected by measurement noise, which comes from a normal distribution with mean zero and variance σ2. I assume that variance and hackability are positively correlated. While this function is made up and missing an upper bound, the shape of the curves should be about right. See notebook for source code. Confessions of a test hacker Before diving into the hackability of CodeSignal’s Industry Coding Framework, here’s a bit of background on my history as a test hacker.\nBack in the day, I got pretty good at hacking tests. I enjoyed learning, but I also enjoyed getting high grades. This goes back to primary and high school and to my undergraduate degree in computer science – I graduated summa cum laude from a well-regarded university. My undergraduate days included hacks such as spending nearly all my waking hours solving past test questions during exam periods, as well as avoiding electives that had a reputation for being excessively time-consuming.\nSimilar test hacking skills were useful when interviewing with big tech companies. Early in my career, I worked with Intel, Qualcomm, and Google, and successfully interviewed with a few other tech companies. On a conceptual level, tech company tests weren’t that different from university tests, except that they were mostly oral (the dreaded whiteboard coding test), and could cover a wider breadth of topics. But even in 2005-2010, many questions leaked online, so I could follow the tried-and-tested hack of preparing by solving old test questions.\nWhile I can do well in standardised timed tests, I never liked them. Despite being hackable, they are stressful, and maximising one’s score requires adequate preparation that is different from learning deeply about the subject matter. Perhaps the most absurd example of this was when I had to take an IELTS exam (a standardised English test) for the second time after completing my PhD, as part of my Australian permanent residency application.3 This was four years after taking the IELTS exam for the first time (in Israel). I spent the intervening years in Australia, authored peer-reviewed papers and a thesis, and gave multiple conference talks. There’s no doubt that my English skills improved over those years, and yet my second IELTS scores were lower.\nWhy were my second IELTS scores lower? Partly because I didn’t prepare for the speaking part of the exam, so I didn’t have much to say when the examiner asked me about my favourite colours and the favourite colours of my friends (yes, for real). I ended up paying the fee to contest the result, and it got bumped up to be closer to my pre-PhD scores. Still, this serves as a salient example of a hackable test. You can improve your IELTS score by getting better at doing IELTS exams, and without any change to your underlying English skills.\nOnce I became an Australian permanent resident, I had to do a driving test to convert my Israeli licence. This was also silly, as I was legally allowed to drive in Australia while I was on a student visa. Those years of driving weren’t enough to automatically convert my licence to the Australian system, so I was subjected to the driving test. While a bit stressful, it wasn’t too bad because driving tests are a close simulation of the skill they aim to measure – driving on streets and highways. As such, they’re not too hackable, though I was careful to signal my intent to the tester in a way that’s somewhat unnatural (e.g., braking and indicating earlier than necessary to avoid getting penalised). I had no issues passing the test.\nFortunately, I managed to avoid convoluted tests in the decade or so since that second IELTS exam. For job applications, I’ve mostly had my skills assessed through custom take-home assignments and paid trial work, e.g., in my long application process with Automattic and my last position with Orkestra, which started as a short-term contract. Those evaluations were less hackable than the whiteboard engineering questions of my early career, and therefore felt like a better reflection of the skills they were assessing.\nOn the hackability of CodeSignal’s Industry Coding Framework Last week, I went through CodeSignal’s Industry Coding Assessment as part of a job application. While I agreed not to share the content of the assessment, there’s plenty I can discuss based on public information from CodeSignal’s website.\nThe whole experience felt like an unpleasant throwback to my old test hacking days in the noughties, but with a shinier user interface. While I’m rusty at standardised code tests, I did what any good test hacker would do: I started my preparation by searching for “Industry Coding Framework” on the web and on Blind, and reading through CodeSignal’s blog and resources. My initial search didn’t yield any unusual hacks, so I followed CodeSignal’s advice and did some of their practice questions. These turned out to be similar to the sort of questions I solved on whiteboards back in the day, except that these days, solutions are automatically scored in a web-based IDE.\nGetting familiar with CodeSignal’s environment and refreshing my speed-solving abilities was definitely helpful when I took the real assessment, and that is a prime indicator of hackability. CodeSignal states that their Industry Coding Framework is designed to evaluate the programming skills of mid-to-senior engineers. These are skills that accrue over years and decades, much like English language skills. The ideal test for such skills shouldn’t be hackable, i.e., scores should be unaffected by repetition of similar tests over a short period. However, on the morning of the test I discovered that CodeSignal’s Industry Coding Assessments are hackable by design.\nWhat I discovered was in a technical brief I initially overlooked, titled Industry Coding Skills Evaluation Framework (a longer version is stored in the Internet Archive). In the brief, they give the following breakdown of questions in their Industry Coding Assessments:\nLevel Expected time in minutes 1 10-15 2 20-30 3 30-60 4 30-60 Adding up the time ranges gives us an estimate of 90-165 minutes to complete the assessment. But the time they give candidates to complete the test is… 90 minutes! In their own words:\nThe maximum allowed completion time for the assessment is 90 minutes; however, candidates are not necessarily expected to complete all tasks within this time limit. While longer assessments allow more accurate measurement of candidate skills, the willingness to complete assessments decreases dramatically for tests longer than 2 hours. Moreover, a major factor in assessing candidates’ skill levels is to see how far they can progress within the given time frame.\nIt makes sense that candidates don’t want to spend too much time on artificial tests. But a better approach would be to design a test that can be completed within the allotted time by skilled candidates who don’t engage in test hacking. Alternatively, they could allow more time and penalise candidates for going over the minimum of 90 minutes. This would make it easier to tell the difference between people who are slightly slower than the cut-off and those who are significantly slower. Implementation speed does matter in the real world, but it’s rarely measured on the order of minutes.\nAs it stands, my opinion is that making speed a key factor in test success makes it hackable because test-specific practice can lead to dramatically better results. CodeSignal’s decision to emphasise speed turns the test into a game like Speedcubing, and a game can be defined as the overcoming of unnecessary obstacles. Gamification may be in vogue, but I believe it’s better to keep it out of the job application process.\nFurther evidence for hackability comes from the fact that CodeSignal limits test attempts over varying time windows. If CodeSignal’s assessments were more like measuring one’s height or basic driving skills, this wouldn’t be needed. Further, this somewhat favours people who are in better assessment shape, e.g., because they’re applying to many jobs and are highly motivated to get them. Sadly, I found a thread on CodeSignal’s General Coding Assessment that says that the same CodeSignal results can be used by multiple companies, which means that people get locked out of opportunities for the time window that’s determined by CodeSignal. Anecdotally, while researching this post, I also discovered that many people dislike CodeSignal and have made similar observations to mine about the validity of their evaluations. Further, when it comes to General Coding Assessments, one can find many tips on test hacking (e.g., on Reddit and GitHub).\nAnother key issue is that the effective time given for the test isn’t 90 minutes. It’s typically two weeks from the time of notification, where one can’t see the test, plus 90 minutes to do the test. The two weeks can be used for extensive test hacking, depending on the test taker’s available time and motivation.\nAs both my available time and motivation were lacking, I didn’t use the full two weeks. I quickly lost interest in solving the same kind of questions I solved around 2005. I also suspected that some of the practice questions provided by CodeSignal had little relevance to the Industry Coding Framework. In addition, I read on Glassdoor and Blind that the company that asked me to take the test had ghosted some candidates after they had passed it, so I figured that maximising my test preparation time wasn’t worth it. With more than a week left before the deadline, I decided to take the test and move on.\nBeyond hackability: Other issues with CodeSignal and automated assessments To my surprise, when I clicked the Take Test button, I was given an option to do a demo test. Hiding the demo behind that button feels a bit unfair. I assume that candidates would click the button when they’re ready to take the test, not when they want to do further preparation. But I finished the demo test in 15 out of the allotted 60 minutes, so I felt good enough about it and moved on to the real thing.\nUnfortunately, I ran out of time on the real test and scored 800 / 1000. According to the distribution in the archived version of CodeSignal’s Industry Coding Framework brief, this would have put me at the top 5% of test takers. But I’m not pleased with the result. The code I wrote was horrible and followed practices I’d never follow if I wasn’t trying to optimise for speed. There were also technical issues with the platform that got in my way: The IDE refreshed multiple times and claimed that I had lost connection, and having to use their IDE rather than a notebook environment is also a bit of a pain given the strict time constraints.\nIt’s likely I could have scored higher if I had maximised my test hacking efforts. Spending another week on preparation would have probably made a difference given that the hackability of the test is similar to that of an IELTS exam: Getting from zero to a perfect score is probably impossible over a short time span, but it is possible to nudge the score up by optimising the test-taking strategy and refreshing one’s bag of tricks (the sort of tricks that you don’t have to worry about retrieving quickly from memory under normal circumstances). For example, one relevant preparation step I could have followed was to attempt the sample questions from the Industry Coding Framework brief. I could have even taken it further and used ChatGPT (or another chatbot) to generate variations on the same theme. But as noted, I didn’t feel like it was worth maximising my hacking efforts given the circumstances.\nRegardless of hackability, I believe that the test fails to capture many of the skills it purports to measure. Specifically:\nNo points are given for good design without code that passes the automated tests. This is unlike more manual testing with a human assessor, where partial credit is given for having good ideas but running out of time. Not having to write any tests encourages lazy coding. Normally I’d think through edge cases, but optimising for the test score means that the only edge cases that matter are those that get caught by automated tests. It’s easier to deal with such issues if they get caught rather than spend precious time thinking about them. In real work, you need to spend time testing your code, which often requires more thinking than implementing the core logic. While CodeSignal claims that they test refactoring skills, the test design doesn’t even offer a caricature of real refactoring. In reality, new requirements are added over the course of days, weeks, months, and years – not minutes. And you need to refactor legacy code that runs in production and was written by many people of varying levels of proficiency and time pressures. This is nothing like tweaking throwaway code that you’ve written minutes ago. Putting a high emphasis on implementation speed when aiming to test mid-to-senior developers disadvantages those who have gotten into the habit of avoiding software engineering classic mistakes such as shortchanged quality assurance and code-like-hell programming.4 As noted by Martin Fowler, ignoring internal quality increases the pace of feature delivery early in a project’s life, but slows it down in the longer term (within weeks). Setting a 90-minute time limit on a test that’s supposed to take a minimum of 90 minutes may filter out experienced engineers who have developed good habits and didn’t bother unlearning them for test hacking purposes. This is an instance of the McNamara fallacy – time is easy to measure, but deep skills and good habits aren’t. Unfortunately, CodeSignal is heavily biased towards that which is easy to measure, but rather than admitting these flaws, they make unsupported claims about the effectiveness of their measurement approach (just read the archived version of the brief for a bit of a laugh). Hacking timed tests can be at odds with habits that are needed to develop high-quality feature-rich software. Source: Martin Fowler’s Is High Quality Software Worth the Cost? Closing thoughts: Partial hackability doesn’t imply complete uselessness Hackability is a non-binary measurement. Even hackable tests can be reflective of the properties they’re supposed to measure. As CodeSignal says in their marketing materials, they offer a cost-effective approach to filtering out candidates, at least when compared to manual in-house recruitment. From a hiring perspective, cheap filters are valuable when a company is flooded with qualified candidates, even if such filters have a high false negative rate. The goal is achieved as long as the filter also decreases the false positive rate. Favouring test hackers is a small price to pay for an initial filter – even if you get candidates to optimise for the wrong metrics, this can be corrected with more thoughtful testing down the track. However, turning the application process into a series of games risks alienating some candidates, who won’t bother applying even if they can do the job well.\nAmong other factors, test scores are a function of the test taker’s skills, test design/hackability, and the test taker’s preparation for the specific test.5 I believe that take-home coding assessments and real-work simulations offer a better candidate experience and provide a better signal to companies than artificial time-limited tests like CodeSignal’s Industry Coding Assessments. This is supported by statements from CodeSignal: The brief discussed above explicitly says that “longer assessments allow more accurate measurement of candidate skills”, and they found in their 2023 survey that candidates prefer take-home coding challenges to CodeSignal assessments.6\nMy hope is that this post would help future users of automated coding assessments in general, and CodeSignal’s Industry Coding Framework in particular. Perhaps it’d also nudge CodeSignal to improve their platform. They can do better. I won’t be holding my breath, though – standardised assessments like CodeSignal and IELTS are a part of a massive industry. There’s little incentive for incumbents to change their ways, but it is possible that large language models excelling in test hacking would force their hand.\nSome comments from a Blind thread on coding assessments. Seeing it all as a somewhat-useful game is probably the way to go. Note: I reached out to CodeSignal for a comment on this post, but haven’t heard back after more than a week.\nAs with many Paul Graham essays, I find myself in agreement with some of his ideas and disagreement with others. But hackable tests are definitely a thing, e.g., see teaching to the test and Campbell’s law. ↩︎\nTaking a machine learning analogy, asking the same questions repeatedly is likely to lead to overfitting. Drawing new questions from the same distribution is akin to adding a validation set, while dealing with the sort of problems encountered outside standardised tests is indicative of the generalisation error of the test taker. ↩︎\nIt says a lot about the hackability of higher education that the Australian government requires a PhD graduate from a top Australian university to prove that their English skills haven’t deteriorated after four years in Australia. Similarly, companies that look at educational pedigree but put recent graduates through their own set of tests implicitly distrust the grades given by universities. ↩︎\nThe only time you’re likely to face ridiculous time pressures that are measured in minutes is when something breaks in production. Production issues can be minimised through investment in solid processes and quality over a project’s lifetime. That is, you go slow to go fast and avoid fire-fighting. Take-home exams and real-work simulations are more reflective of the sort of thinking that’s required from senior engineers because good ideas often manifest when you take the time to design a system and avoid jumping into code-like-hell mode. Going with the first thing that comes to mind is a habit that’s better left to chatbots. ↩︎\nPreparation is partly a function of motivation to pass the test, which is a positive indicator despite being unrelated to possessing the skills the test purports to measure. In my case, motivation to maximise the score was lacking, so the company got useful information out of my imperfect score. Why was my motivation lacking? Because the role seemed interesting enough to apply to, but not worth working too hard to get. The opportunity cost of neglecting my other endeavours in favour of test hacking seemed too high. ↩︎\nSee page 11 of the linked survey. Like other materials from CodeSignal, it’s somewhat comical. They state that “candidates view CodeSignal assessments more favorably than timed coding assessments in general (p = 0.034)”, but looking at the table, the mean score given to CodeSignal assessments is 3.41 / 5, while general timed coding assessments were given a mean score of 3.37. That is, a difference of 0.04 – it’s hard to call this practically significant, despite the p-value. Could it be that CodeSignal’s IO psychologists missed the many memos on p-value pitfalls, such as the one by the American Statistical Association? In any case, if they consider the 0.04 difference to be notable, why do they say nothing about the 0.06 difference in favour of take-home coding assignments or the 0.17 difference in favour of coding interviews? Personally, I’d also report the full distribution rather than just the means. It’s easy enough to visualise a five-point scale. ↩︎\n","wordCount":"3832","inLanguage":"en","image":"https://yanirseroussi.com/otter-coding-furiously.jpg","datePublished":"2023-05-26T00:03:00Z","dateModified":"2023-05-26T13:08:24+10:00","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Engineering Data Science \u0026 More","logo":{"@type":"ImageObject","url":"https://yanirseroussi.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Engineering Data Science & More (Alt + H)">Yanir Seroussi | Engineering Data Science & More</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yanirseroussi.com/about/ title=About><span>About</span></a></li><li><a href=https://yanirseroussi.com/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://yanirseroussi.com/fractional-chief-data-officer/#/ target=_blank title="Fractional Chief Data Officer slides">⚡ CDO</a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>How hackable are automated coding assessments?</h1><div class=post-meta><span title='2023-05-26 00:03:00 +0000 UTC'>May 26, 2023</span>&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2023-05-26-how-hackable-are-automated-coding-assessments/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a></div></header><figure class=entry-cover><img loading=lazy srcset="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_360x0_resize_q75_box.jpg 360w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_480x0_resize_q75_box.jpg 480w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously_hu6b7664f523075193f9f11d79c1c9dcfa_195397_720x0_resize_q75_box.jpg 720w ,https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg 1023w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/otter-coding-furiously.jpg alt="Bing's interpretation of _an otter coding furiously in an attempt to pass a coding test_" width=1023 height=914><p>Bing&rsquo;s interpretation of <em>an otter coding furiously in an attempt to pass a coding test</em></p></figure><div class=post-content><p>In the essay <a href=http://www.paulgraham.com/lesson.html target=_blank rel=noopener>The Lesson to Unlearn</a>, Paul Graham makes the claim that students are trained to win by hacking bad tests. That is, to get good grades, one has to avoid spending too much time on material that won&rsquo;t be turned into test questions. Instead, one&rsquo;s focus has to be on test-specific study. Students are taught that actual learning is less important than maximising grades. That is the lesson to unlearn.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>Even though the essay is a few years old, it&rsquo;s been on my mind recently for two reasons. The first reason is that <a href=https://openai.com/product/gpt-4 target=_blank rel=noopener>large language models are excelling in standardised tests</a>: <a href=https://yanirseroussi.com/2022/12/11/chatgpt-is-transformative-ai/>I&rsquo;m impressed by this progress</a>, but it&rsquo;s also a reminder of the hackability of such tests and <a href=https://yanirseroussi.com/2023/04/21/remaining-relevant-as-a-small-language-model/>the need to employ critical thinking to stay ahead of the AI automation wave</a>. The second reason is that I did a <a href=https://codesignal.com/ target=_blank rel=noopener>CodeSignal</a> test myself, which led me to think more deeply on the hackability of automated and timed coding assessments. This post discusses my thoughts on the topic, using CodeSignal&rsquo;s Industry Coding Framework as a case study. However, most of my observations should apply to similar tests.</p><h2 id=what-are-hackable-tests>What are hackable tests?<a hidden class=anchor aria-hidden=true href=#what-are-hackable-tests>#</a></h2><p>Hacking a test is different from cheating. Hacking entails following the test&rsquo;s rules, but optimising your work to exploit its weaknesses and increase your score. It doesn&rsquo;t necessarily entail changing the underlying properties that the test purports to measure. By contrast, cheating entails behaviours that are prohibited by the test&rsquo;s rules, such as letting someone else do the test for you, or consulting resources that are defined as off limits.</p><p>A test&rsquo;s hackability isn&rsquo;t a binary property. Hackability lies on a scale from unhackable to fully hackable, as demonstrated by the following examples and plot.</p><p>Say we take an adult and measure their height every day around the same time, over a period of a month. We can expect the measurements to have low variance. There&rsquo;s little the test taker can do to significantly increase their height without cheating. The test is a good representation of the property it aims to measure – <strong>an unhackable test.</strong></p><p>On the other end of the scale, say we take the same person and ask them the same set of questions over the course of a month. Our aim is to assess their skills in a subject area such as programming. Given that we&rsquo;re repeating the same questions, they can find the answers and try to memorise them after each attempt. Assuming they&rsquo;re sufficiently motivated, we can expect their scores to increase even if they know nothing about programming. <strong>This test is highly hackable.</strong> It&rsquo;s hard to say that it accurately reflects the property it purports to measure, i.e., programming skills. This is because scores are strongly influenced by motivation to succeed in the test, as well as short-term memorisation and retrieval abilities.</p><p>An improvement over the unchanged test is generating variations from a set of possible questions.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> While our test taker would benefit from deeper skills in the subject area, they can also improve their scores by learning to recognise patterns in test questions, managing their time well, and memorising recurring elements. Again, we can expect their scores to improve over time and fail to accurately reflect the skills we care about. This gets us into the familiar territory of standardised testing, a category that I believe <a href=https://codesignal.com/resource/industry-coding-data-sheet/ target=_blank rel=noopener>CodeSignal&rsquo;s Industry Coding Assessments</a> fall under. That is, tests that are not fully hackable, but still fall short of reflecting the properties they claim to measure.</p><figure><a href=test-hackability-plot.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_360x0_resize_box_3.png 360w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_480x0_resize_box_3.png 480w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_720x0_resize_box_3.png 720w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_1080x0_resize_box_3.png 1080w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_1500x0_resize_box_3.png 1500w," src=https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/test-hackability-plot_huc6cd7ee0ede95da30b0428b769a2cee3_186486_800x0_resize_box_3.png alt="Plot showing different hackability curves, based on f(t) = b + h * sqrt(t) + N(0, σ ** 2)" loading=lazy></a><figcaption><p>Visualising hackable test scores as a function of time: <code>f(t) = b + h * sqrt(t) + N(0, σ<sup>2</sup>)</code>. Starting from the same baseline <code>b</code>, scores increase with time <code>t</code> due to the hackability factor <code>h</code> that is multiplied by <code>sqrt(t)</code> (ability to improve decays with time). Each test attempt is affected by measurement noise, which comes from a normal distribution with mean zero and variance <code>σ<sup>2</sup></code>. I assume that variance and hackability are positively correlated. While this function is made up and missing an upper bound, the shape of the curves should be about right. See <a href=https://www.kaggle.com/code/yanirseroussi/test-hackability-plots/notebook target=_blank rel=noopener>notebook</a> for source code.</p></figcaption></figure><h2 id=confessions-of-a-test-hacker>Confessions of a test hacker<a hidden class=anchor aria-hidden=true href=#confessions-of-a-test-hacker>#</a></h2><p>Before diving into the hackability of CodeSignal&rsquo;s Industry Coding Framework, here&rsquo;s a bit of background on my history as a test hacker.</p><p>Back in the day, I got pretty good at hacking tests. I enjoyed learning, but I also enjoyed getting high grades. This goes back to primary and high school and to my undergraduate degree in computer science – I graduated summa cum laude from <a href=https://en.wikipedia.org/wiki/Technion_%E2%80%93_Israel_Institute_of_Technology target=_blank rel=noopener>a well-regarded university</a>. My undergraduate days included hacks such as spending nearly all my waking hours solving past test questions during exam periods, as well as avoiding electives that had a reputation for being excessively time-consuming.</p><p>Similar test hacking skills were useful when interviewing with big tech companies. Early in my career, I worked with Intel, Qualcomm, and Google, and successfully interviewed with a few other tech companies. On a conceptual level, tech company tests weren&rsquo;t that different from university tests, except that they were mostly oral (the dreaded whiteboard coding test), and could cover a wider breadth of topics. But even in 2005-2010, many questions leaked online, so I could follow the tried-and-tested hack of preparing by solving old test questions.</p><p>While I can do well in standardised timed tests, I never liked them. Despite being hackable, they are stressful, and maximising one&rsquo;s score requires adequate preparation that is different from learning deeply about the subject matter. Perhaps the most absurd example of this was when I had to take an IELTS exam (<a href=https://en.wikipedia.org/wiki/International_English_Language_Testing_System target=_blank rel=noopener>a standardised English test</a>) for the second time after completing my PhD, as part of my Australian permanent residency application.<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> This was four years after taking the IELTS exam for the first time (in Israel). I spent the intervening years in Australia, authored peer-reviewed papers and a thesis, and gave multiple conference talks. There&rsquo;s no doubt that my English skills improved over those years, and yet my second IELTS scores were lower.</p><p>Why were my second IELTS scores lower? Partly because I didn&rsquo;t prepare for the speaking part of the exam, so I didn&rsquo;t have much to say when the examiner asked me about my favourite colours and the favourite colours of my friends (yes, for real). I ended up paying the fee to contest the result, and it got bumped up to be closer to my pre-PhD scores. Still, this serves as a salient example of a hackable test. You can improve your IELTS score by getting better at doing IELTS exams, and without any change to your underlying English skills.</p><p>Once I became an Australian permanent resident, I had to do a driving test to convert my Israeli licence. This was also silly, as I was legally allowed to drive in Australia while I was on a student visa. Those years of driving weren&rsquo;t enough to automatically convert my licence to the Australian system, so I was subjected to the driving test. While a bit stressful, it wasn&rsquo;t too bad because driving tests are a close simulation of the skill they aim to measure – driving on streets and highways. As such, they&rsquo;re not too hackable, though I was careful to signal my intent to the tester in a way that&rsquo;s somewhat unnatural (e.g., braking and indicating earlier than necessary to avoid getting penalised). I had no issues passing the test.</p><p>Fortunately, I managed to avoid convoluted tests in the decade or so since that second IELTS exam. For job applications, I&rsquo;ve mostly had my skills assessed through custom take-home assignments and paid trial work, e.g., in <a href=https://yanirseroussi.com/2017/07/29/my-10-step-path-to-becoming-a-remote-data-scientist-with-automattic/>my long application process with Automattic</a> and <a href=https://yanirseroussi.com/2022/06/06/the-mission-matters-moving-to-climate-tech-as-a-data-scientist/>my last position with Orkestra, which started as a short-term contract</a>. Those evaluations were less hackable than the whiteboard engineering questions of my early career, and therefore felt like a better reflection of the skills they were assessing.</p><h2 id=on-the-hackability-of-codesignals-industry-coding-framework>On the hackability of CodeSignal&rsquo;s Industry Coding Framework<a hidden class=anchor aria-hidden=true href=#on-the-hackability-of-codesignals-industry-coding-framework>#</a></h2><p>Last week, I went through CodeSignal&rsquo;s Industry Coding Assessment as part of a job application. While I agreed not to share the content of the assessment, there&rsquo;s plenty I can discuss based on public information from CodeSignal&rsquo;s website.</p><p>The whole experience felt like an unpleasant throwback to my old test hacking days in the noughties, but with a shinier user interface. While I&rsquo;m rusty at standardised code tests, I did what any good test hacker would do: I started my preparation by searching for <em>&ldquo;Industry Coding Framework&rdquo;</em> on the web and on Blind, and reading through CodeSignal&rsquo;s blog and resources. My initial search didn&rsquo;t yield any unusual hacks, so I followed <a href=https://codesignal.com/blog/interview-prep/coding-assessment-checklist/ target=_blank rel=noopener>CodeSignal&rsquo;s advice</a> and did some of their practice questions. These turned out to be similar to the sort of questions I solved on whiteboards back in the day, except that these days, solutions are automatically scored in a web-based IDE.</p><p>Getting familiar with CodeSignal&rsquo;s environment and refreshing my speed-solving abilities was definitely helpful when I took the real assessment, <strong>and that is a prime indicator of hackability</strong>. CodeSignal states that their Industry Coding Framework is designed to evaluate the programming skills of mid-to-senior engineers. These are skills that accrue over years and decades, much like English language skills. The ideal test for such skills shouldn&rsquo;t be hackable, i.e., scores should be unaffected by repetition of similar tests over a short period. However, on the morning of the test I discovered that <strong>CodeSignal&rsquo;s Industry Coding Assessments are hackable by design</strong>.</p><p>What I discovered was in a technical brief I initially overlooked, titled <a href=https://discover.codesignal.com/rs/659-AFH-023/images/Industry-Coding-Skills-Evaluation-Framework-CodeSignal-Skills-Evaluation-Lab-Short.pdf target=_blank rel=noopener>Industry Coding Skills Evaluation Framework</a> (<a href=https://web.archive.org/web/20230321142915/https://discover.codesignal.com/rs/659-AFH-023/images/Industry-Coding-Skills-Evaluation-Framework-CodeSignal-Skills-Evaluation-Lab-Short.pdf target=_blank rel=noopener>a longer version is stored in the Internet Archive</a>). In the brief, they give the following breakdown of questions in their Industry Coding Assessments:</p><table style=width:fit-content;margin-left:auto;margin-right:auto><tr><th>Level</th><th>Expected time in minutes</th></tr><tr><td>1</td><td>10-15</td></tr><tr><td>2</td><td>20-30</td></tr><tr><td>3</td><td>30-60</td></tr><tr><td>4</td><td>30-60</td></tr></table><p>Adding up the time ranges gives us an estimate of 90-165 minutes to complete the assessment. But the time they give candidates to complete the test is&mldr; 90 minutes! In their own words:</p><blockquote><p>The maximum allowed completion time for the assessment is 90 minutes; however, candidates are not necessarily expected to complete all tasks within this time limit. While longer assessments allow more accurate measurement of candidate skills, the willingness to complete assessments decreases dramatically for tests longer than 2 hours. Moreover, a major factor in assessing candidates&rsquo; skill levels is to see how far they can progress within the given time frame.</p></blockquote><p>It makes sense that candidates don&rsquo;t want to spend too much time on artificial tests. But a better approach would be to design a test that can be completed within the allotted time by skilled candidates who don&rsquo;t engage in test hacking. Alternatively, they could allow more time and penalise candidates for going over the minimum of 90 minutes. This would make it easier to tell the difference between people who are slightly slower than the cut-off and those who are significantly slower. Implementation speed does matter in the real world, but it&rsquo;s rarely measured on the order of minutes.</p><p>As it stands, my opinion is that <strong>making speed a key factor in test success makes it hackable because test-specific practice can lead to dramatically better results.</strong> CodeSignal&rsquo;s decision to emphasise speed turns the test into a game like <a href=https://en.wikipedia.org/wiki/Speedcubing target=_blank rel=noopener>Speedcubing</a>, and a game can be defined as <a href=https://en.wikipedia.org/wiki/Lusory_attitude target=_blank rel=noopener>the overcoming of unnecessary obstacles</a>. Gamification may be in vogue, but I believe it&rsquo;s better to keep it out of the job application process.</p><p>Further evidence for hackability comes from the fact that <a href=https://support.codesignal.com/hc/en-us/articles/11635510785047-What-is-a-cooldown-period-and-how-does-it-impact-my-ability-to-take-an-assessment- target=_blank rel=noopener>CodeSignal limits test attempts over varying time windows</a>. If CodeSignal&rsquo;s assessments were more like measuring one&rsquo;s height or basic driving skills, this wouldn&rsquo;t be needed. Further, this somewhat favours people who are in better assessment shape, e.g., because they&rsquo;re applying to many jobs and are highly motivated to get them. Sadly, <a href=https://www.reddit.com/r/csMajors/comments/ighloy/can_i_retake_the_codesignal_test_within_14_days/ target=_blank rel=noopener>I found a thread on CodeSignal&rsquo;s General Coding Assessment</a> that says that the same CodeSignal results can be used by multiple companies, which means that people get locked out of opportunities for the time window that&rsquo;s determined by CodeSignal. Anecdotally, while researching this post, I also discovered that <a href=https://www.reddit.com/r/csMajors/comments/12uq2pc/psa_2023_codesignal_changes/ target=_blank rel=noopener>many people dislike CodeSignal</a> and <a href=https://www.reddit.com/r/cscareerquestions/comments/q0zle4/when_the_hell_did_leetcode_and_codesignal_become/ target=_blank rel=noopener>have made similar observations to mine about the validity of their evaluations</a>. Further, when it comes to General Coding Assessments, one can find many tips on test hacking (e.g., on <a href=https://www.reddit.com/r/cscareerquestions/comments/iqy99x/codesignal_tips_from_someone_with_844_843/ target=_blank rel=noopener>Reddit</a> and <a href=https://github.com/Leader-board/OA-and-Interviews/ target=_blank rel=noopener>GitHub</a>).</p><p>Another key issue is that the effective time given for the test isn&rsquo;t 90 minutes. It&rsquo;s typically <a href=https://support.codesignal.com/hc/en-us/articles/9539278064919-Quick-Start-Guide-Pre-Screen target=_blank rel=noopener>two weeks from the time of notification</a>, where one can&rsquo;t see the test, plus 90 minutes to do the test. The two weeks can be used for extensive test hacking, depending on the test taker&rsquo;s available time and motivation.</p><p>As both my available time and motivation were lacking, I didn&rsquo;t use the full two weeks. I quickly lost interest in solving the same kind of questions I solved around 2005. I also suspected that some of the practice questions provided by CodeSignal had little relevance to the Industry Coding Framework. In addition, I read on Glassdoor and Blind that the company that asked me to take the test had ghosted some candidates after they had passed it, so I figured that maximising my test preparation time wasn&rsquo;t worth it. With more than a week left before the deadline, I decided to take the test and move on.</p><h2 id=beyond-hackability-other-issues-with-codesignal-and-automated-assessments>Beyond hackability: Other issues with CodeSignal and automated assessments<a hidden class=anchor aria-hidden=true href=#beyond-hackability-other-issues-with-codesignal-and-automated-assessments>#</a></h2><p>To my surprise, when I clicked the <em>Take Test</em> button, I was given an option to do a demo test. Hiding the demo behind that button feels a bit unfair. I assume that candidates would click the button when they&rsquo;re ready to take the test, not when they want to do further preparation. But I finished the demo test in 15 out of the allotted 60 minutes, so I felt good enough about it and moved on to the real thing.</p><p>Unfortunately, I ran out of time on the real test and scored 800 / 1000. According to the distribution in the archived version of CodeSignal&rsquo;s Industry Coding Framework brief, this would have put me at the top 5% of test takers. But I&rsquo;m not pleased with the result. The code I wrote was horrible and followed practices I&rsquo;d never follow if I wasn&rsquo;t trying to optimise for speed. There were also technical issues with the platform that got in my way: The IDE refreshed multiple times and claimed that I had lost connection, and having to use their IDE rather than a notebook environment is also a bit of a pain given the strict time constraints.</p><p>It&rsquo;s likely I could have scored higher if I had maximised my test hacking efforts. Spending another week on preparation would have probably made a difference given that the hackability of the test is similar to that of an IELTS exam: Getting from zero to a perfect score is probably impossible over a short time span, but it is possible to nudge the score up by optimising the test-taking strategy and refreshing one&rsquo;s bag of tricks (the sort of tricks that you don&rsquo;t have to worry about retrieving quickly from memory under normal circumstances). For example, one relevant preparation step I could have followed was to attempt the sample questions from the Industry Coding Framework brief. I could have even taken it further and used ChatGPT (or another chatbot) to generate variations on the same theme. But as noted, I didn&rsquo;t feel like it was worth maximising my hacking efforts given the circumstances.</p><p>Regardless of hackability, I believe that the test fails to capture many of the skills it purports to measure. Specifically:</p><ul><li>No points are given for good design without code that passes the automated tests. This is unlike more manual testing with a human assessor, where partial credit is given for having good ideas but running out of time.</li><li>Not having to write any tests encourages lazy coding. Normally I&rsquo;d think through edge cases, but optimising for the test score means that the only edge cases that matter are those that get caught by automated tests. It&rsquo;s easier to deal with such issues if they get caught rather than spend precious time thinking about them. In real work, you need to spend time testing your code, which often requires more thinking than implementing the core logic.</li><li>While CodeSignal claims that they test refactoring skills, the test design doesn&rsquo;t even offer a caricature of real refactoring. In reality, new requirements are added over the course of days, weeks, months, and years – not minutes. And you need to refactor legacy code that runs in production and was written by many people of varying levels of proficiency and time pressures. This is nothing like tweaking throwaway code that you&rsquo;ve written minutes ago.</li><li>Putting a high emphasis on implementation speed when aiming to test mid-to-senior developers disadvantages those who have gotten into the habit of avoiding <a href=https://smallbusinessprogramming.com/steve-mcconnells-classic-software-mistakes-revisited/ target=_blank rel=noopener>software engineering classic mistakes</a> such as shortchanged quality assurance and code-like-hell programming.<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> As <a href=https://martinfowler.com/articles/is-quality-worth-cost.html target=_blank rel=noopener>noted by Martin Fowler</a>, ignoring internal quality increases the pace of feature delivery early in a project&rsquo;s life, but slows it down in the longer term (within weeks). Setting a 90-minute time limit on a test that&rsquo;s supposed to take a minimum of 90 minutes may filter out experienced engineers who have developed good habits and didn&rsquo;t bother unlearning them for test hacking purposes. This is an instance of <a href=https://en.wikipedia.org/wiki/McNamara_fallacy target=_blank rel=noopener>the McNamara fallacy</a> – time is easy to measure, but deep skills and good habits aren&rsquo;t. Unfortunately, CodeSignal is heavily biased towards that which is easy to measure, but rather than admitting these flaws, they make unsupported claims about the effectiveness of their measurement approach (just read the archived version of the brief for a bit of a laugh).</li></ul><figure><a href=internal-quality-functionality-over-time.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_360x0_resize_box_3.png 360w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_480x0_resize_box_3.png 480w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_720x0_resize_box_3.png 720w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time.png 857w," src=https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/internal-quality-functionality-over-time_hu3a5dc8c9eb095c36ff9d569aade36b5f_60581_800x0_resize_box_3.png alt="Graph showing how higher internal quality leads to more cumulative functionality" loading=lazy></a><figcaption><p>Hacking timed tests can be at odds with habits that are needed to develop high-quality feature-rich software. Source: <a href=https://martinfowler.com/articles/is-quality-worth-cost.html target=_blank rel=noopener>Martin Fowler&rsquo;s Is High Quality Software Worth the Cost?</a></p></figcaption></figure><h2 id=closing-thoughts-partial-hackability-doesnt-imply-complete-uselessness>Closing thoughts: Partial hackability doesn&rsquo;t imply complete uselessness<a hidden class=anchor aria-hidden=true href=#closing-thoughts-partial-hackability-doesnt-imply-complete-uselessness>#</a></h2><p>Hackability is a non-binary measurement. Even hackable tests can be reflective of the properties they&rsquo;re supposed to measure. As CodeSignal says in their marketing materials, they offer a cost-effective approach to filtering out candidates, at least when compared to manual in-house recruitment. From a hiring perspective, cheap filters are valuable when a company is flooded with qualified candidates, even if such filters have a high false negative rate. The goal is achieved as long as the filter also decreases the false positive rate. Favouring test hackers is a small price to pay for an initial filter – even if you get candidates to optimise for the wrong metrics, this can be corrected with more thoughtful testing down the track. However, turning the application process into a series of games risks alienating some candidates, who won&rsquo;t bother applying even if they can do the job well.</p><p>Among other factors, test scores are a function of the test taker&rsquo;s skills, test design/hackability, and the test taker&rsquo;s preparation for the specific test.<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> I believe that take-home coding assessments and real-work simulations offer a better candidate experience and provide a better signal to companies than artificial time-limited tests like CodeSignal&rsquo;s Industry Coding Assessments. This is supported by statements from CodeSignal: The brief discussed above explicitly says that <em>&ldquo;longer assessments allow more accurate measurement of candidate skills&rdquo;</em>, and they found in their <a href=https://discover.codesignal.com/rs/659-AFH-023/images/2023-State-of-Engineer-Hiring-Survey-CodeSignal.pdf target=_blank rel=noopener>2023 survey</a> that candidates prefer take-home coding challenges to CodeSignal assessments.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></p><p>My hope is that this post would help future users of automated coding assessments in general, and CodeSignal&rsquo;s Industry Coding Framework in particular. Perhaps it&rsquo;d also nudge CodeSignal to improve their platform. They can do better. I won&rsquo;t be holding my breath, though – standardised assessments like CodeSignal and IELTS are a part of a massive industry. There&rsquo;s little incentive for incumbents to change their ways, but it is possible that large language models excelling in test hacking would force their hand.</p><figure><a href=blind-code-assessment-game.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_360x0_resize_box_3.png 360w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_480x0_resize_box_3.png 480w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_720x0_resize_box_3.png 720w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_1080x0_resize_box_3.png 1080w,
https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game.png 1244w," src=https://yanirseroussi.com/2023/05/26/how-hackable-are-automated-coding-assessments/blind-code-assessment-game_hu4596bb32dd7a8ed7b3602d876d56970a_249362_800x0_resize_box_3.png alt="Screenshot from a Blind thread on coding assessments" loading=lazy></a><figcaption><p>Some comments from a <a href=https://www.teamblind.com/post/Thank-you-for-fcking-up-the-coding-industry-GchJZKmF target=_blank rel=noopener>Blind thread on coding assessments</a>. Seeing it all as a somewhat-useful game is probably the way to go.</p></figcaption></figure><p><small><em>Note: I reached out to CodeSignal for a comment on this post, but haven&rsquo;t heard back after more than a week.</em></small></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>As with many Paul Graham essays, I find myself in agreement with some of his ideas and disagreement with others. But hackable tests are definitely a thing, e.g., see <a href=https://en.wikipedia.org/wiki/Teaching_to_the_test target=_blank rel=noopener>teaching to the test</a> and <a href=https://en.wikipedia.org/wiki/Campbell%27s_law target=_blank rel=noopener>Campbell&rsquo;s law</a>.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Taking a machine learning analogy, asking the same questions repeatedly is likely to lead to <a href=https://en.wikipedia.org/wiki/Overfitting target=_blank rel=noopener>overfitting</a>. Drawing new questions from the same distribution is akin to adding a validation set, while dealing with the sort of problems encountered outside standardised tests is indicative of <a href=https://en.wikipedia.org/wiki/Generalization_error target=_blank rel=noopener>the generalisation error</a> of the test taker.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>It says a lot about the hackability of higher education that the Australian government requires a PhD graduate from a top Australian university to prove that their English skills haven&rsquo;t deteriorated after four years in Australia. Similarly, companies that look at educational pedigree but put recent graduates through their own set of tests implicitly distrust the grades given by universities.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>The only time you&rsquo;re likely to face ridiculous time pressures that are measured in minutes is when something breaks in production. Production issues can be minimised through investment in solid processes and quality over a project&rsquo;s lifetime. That is, you go slow to go fast and avoid fire-fighting. Take-home exams and real-work simulations are more reflective of the sort of thinking that&rsquo;s required from senior engineers because good ideas often manifest when you take the time to design a system and avoid jumping into code-like-hell mode. Going with the first thing that comes to mind is a habit that&rsquo;s better left to chatbots.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Preparation is partly a function of motivation to pass the test, which is a positive indicator despite being unrelated to possessing the skills the test purports to measure. In my case, motivation to maximise the score was lacking, so the company got useful information out of my imperfect score. Why was my motivation lacking? Because the role seemed interesting enough to apply to, but not worth working too hard to get. The opportunity cost of neglecting my other endeavours in favour of test hacking seemed too high.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>See page 11 of the linked survey. Like other materials from CodeSignal, it&rsquo;s somewhat comical. They state that <em>&ldquo;candidates view CodeSignal assessments more favorably than timed coding assessments in general (p = 0.034)&rdquo;</em>, but looking at the table, the mean score given to CodeSignal assessments is 3.41 / 5, while general timed coding assessments were given a mean score of 3.37. That is, a difference of 0.04 – it&rsquo;s hard to call this <a href=https://en.wikipedia.org/wiki/Clinical_significance target=_blank rel=noopener>practically significant</a>, despite the p-value. Could it be that CodeSignal&rsquo;s <a href=https://codesignal.com/solutions/io-psychologists/ target=_blank rel=noopener>IO psychologists</a> missed the many memos on p-value pitfalls, such as <a href=https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf target=_blank rel=noopener>the one by the American Statistical Association</a>? In any case, if they consider the 0.04 difference to be notable, why do they say nothing about the 0.06 difference in favour of take-home coding assignments or the 0.17 difference in favour of coding interviews? Personally, I&rsquo;d also report the full distribution rather than just the means. It&rsquo;s easy enough to visualise a five-point scale.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://yanirseroussi.com/tags/artificial-intelligence/>artificial intelligence</a></li><li><a href=https://yanirseroussi.com/tags/career/>career</a></li><li><a href=https://yanirseroussi.com/tags/hackers/>hackers</a></li><li><a href=https://yanirseroussi.com/tags/software-engineering/>software engineering</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on twitter" href="https://twitter.com/intent/tweet/?text=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&amp;hashtags=artificialintelligence%2ccareer%2chackers%2csoftwareengineering"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&amp;title=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;summary=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;source=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&title=How%20hackable%20are%20automated%20coding%20assessments%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on whatsapp" href="https://api.whatsapp.com/send?text=How%20hackable%20are%20automated%20coding%20assessments%3f%20-%20https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share How hackable are automated coding assessments? on telegram" href="https://telegram.me/share/url?text=How%20hackable%20are%20automated%20coding%20assessments%3f&amp;url=https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><section class=comment-section><strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirseroussi.com%2f2023%2f05%2f26%2fhow-hackable-are-automated-coding-assessments%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>Comment via GitHub issue</a></section></article></main><footer class=footer><span>Text and figures licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank rel=noopener>CC BY-NC-ND 4.0</a> by <a href=https://yanirseroussi.com/about/>Yanir Seroussi</a>, except where noted otherwise  |</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><div class=mailing-list-container><form class=mailing-list action="https://yanirseroussi.us17.list-manage.com/subscribe/post?u=3c08aa3ff27dd92978019febd&amp;id=bc3ab705af" method=post target=_blank novalidate><label for=mailing-list-email>Get new post notifications</label>
<input type=text name=EMAIL id=mailing-list-email placeholder="Email address"><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_3c08aa3ff27dd92978019febd_bc3ab705af tabindex=-1></div><input type=submit value=Subscribe></form><div class=footer>Alternatively, <a href=https://yanirseroussi.com/index.xml>subscribe to RSS feed</a>.</div></div><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>