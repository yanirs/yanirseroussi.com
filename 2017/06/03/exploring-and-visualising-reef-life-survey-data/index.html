<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Exploring and visualising reef life survey data | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="environment,javascript,marine science,reef life survey,software engineering,web development">
<meta name=description content="Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/>
<link crossorigin=anonymous href=/yanirseroussi.com/assets/css/stylesheet.min.7603165cb47dcda1f46a839ca379731b2f33098c043e75f680940e69a5d546a8.css integrity="sha256-dgMWXLR9zaH0aoOco3lzGy8zCYwEPnX2gJQOaaXVRqg=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/yanirseroussi.com/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirs.github.io/yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirs.github.io/yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirs.github.io/yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirs.github.io/yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirs.github.io/yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Exploring and visualising reef life survey data">
<meta property="og:description" content="Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/">
<meta property="og:image" content="https://yanirs.github.io/yanirseroussi.com/reef-life-survey-frequency-explorer-screenshot.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2017-06-03T00:49:05+00:00">
<meta property="article:modified_time" content="2017-06-03T00:49:05+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirs.github.io/yanirseroussi.com/reef-life-survey-frequency-explorer-screenshot.png">
<meta name=twitter:title content="Exploring and visualising reef life survey data">
<meta name=twitter:description content="Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirs.github.io/yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"Exploring and visualising reef life survey data","item":"https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Exploring and visualising reef life survey data","name":"Exploring and visualising reef life survey data","description":"Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website.","keywords":["environment","javascript","marine science","reef life survey","software engineering","web development"],"articleBody":"Last year, I wrote about the Reef Life Survey (RLS) project and my experience with offline data collection on the Great Barrier Reef. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website. This post describes the tools and their implementation, and outlines possible directions for future work.\nThe tools Each tool is fairly simple and focused on helping users achieve a small set of tasks. The best way to get familiar with the tools is to play with them by following the links below. If you’re only interested in using the tools, you can stop reading after this section. The rest of this post describes the data behind the tools, and some technical implementation details.\n  The Frequency Explorer tool lets users select RLS sites and view the species that have been recorded there (RLS website | full-screen version).     The Flashcards tool helps users memorise the names of marine species by showing random images of species from a chosen area (RLS website | full-screen version).   The data The RLS database includes data collected by volunteer scuba divers on the diversity and abundance of marine life in sites around the world. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef’s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are analysed later to classify the type of substrate or growth (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record all the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) targets invertebrates and cryptic animals, and requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line. The RLS manual includes all the details on how surveys are performed. The data collected in the surveys is available for download from a Data Portal hosted by the Institute for Marine and Antarctic Studies at the University of Tasmania. As of early June 2017, the downloadable dataset consists of over half a million data points from almost ten thousand surveys.\nWhen I first started studying marine species, I had to find a source for photos. Initially, I used Scrapy to build simple scrapers that downloaded photos from sites such as The Australian Museum, Fishbase, and Fishes of Australia. Last year, RLS made a large number of high-quality photos taken by volunteers available on their site (via the Species Search function). In addition to their high quality, an advantage of the RLS photos over images from other sources is that they were all taken in situ, i.e., in each animal’s natural habitat. On the other hand, other sites also include photos of dissections and hand-drawn illustrations, which aren’t as useful for divers who want to see marine animals as they appear in the wild. Working exclusively with the RLS image dataset has significantly improved the appearance and usefulness of the tools I built.\nThe raw RLS survey data comes in the form of over 100MB of CSV files. For the purpose of building the tools, I summarised the data into two JSON files with an overall size of less than 3MB (less than 1MB when compressed). This made it possible to implement both tools as single-page apps that don’t require any requests to the server after the initial fetching of the data. The two summary JSONs are:\n species.json – a mapping from species ID to an array of five elements: scientific name, common name, species page URL, survey method (0: method 1, 1: method 2, or 2: both), and images (array of URLs). site-surveys.json – a mapping from site code to an array of seven elements: realm, ecoregion, site name, longitude, latitude, number of surveys, and species counts (mapping from each observed species ID to the number of surveys on which it was seen).  Both files use mappings to arrays rather than nested objects to reduce the download size. I originally created the files myself by downloading the CSVs from the data portal and scraping the RLS website for images and common names. Static versions of those files from early June 2017 can be found on GitHub (species.json and site-surveys.json). As part of the integration with the RLS website, the RLS developers will implement live versions of the files, which will get updated automatically. I’ll add the links to the live versions when they become available. Please let me or the RLS team know if you find any issues with the data.\nThe approach I chose to produce the species counts in site-surveys.json doesn’t take abundance into account, i.e., each species is counted once per survey regardless of the number of times it was seen on the survey. Ignoring abundance means that for sites with few surveys, the species count may not be a good indicator of future likelihood of occurrence. For example, some fish are solitary and seen rarely, while others occur in schools and are likely to be seen on every survey. However, this is less of an issue for sites with many surveys. In addition, this simple counting approach is easier to explain than some approaches that do account for abundance.\nImplementation details The source code for the tools can be found in my GitHub Pages repository. Each tool is a simple single-page application, consisting of three files: index.jade, main.coffee, and style.less. In addition, the root source directory contains some common code in common.less and util.coffee, as well as configuration files for npm and Grunt. Grunt is used to compile the source files from Jade/Pug, CoffeeScript, and Less to HTML, JS, and CSS respectively. These files are then served statically by GitHub Pages.\nThe common CoffeeScript code loads the JSONs asynchronously, and processes them into nested mappings that are easier to work with than arrays. In addition, the common code contains a method to summarise counts from multiple sites, by aggregating them as simple sums. This means that sites that are surveyed more frequently get weighted more heavily. For example, if a certain fish X was seen once in site A, twice in site B, and never in site C, its count across A, B, and C is 1 + 2 + 0 = 3, but if A was surveyed once, B was surveyed twice, and C was surveyed seven times, X’s aggregate frequency is 3 / (1 + 2 + 7) = 30%. In the future, it may be worth normalising each site’s species counts by the number of times the site was surveyed (making X’s aggregate frequency (1 / 1 + 2 / 2 + 0 / 7) / 3 = 66.67%), but then rare species in rarely-surveyed sites may be overweighted.\nThe Frequency Explorer tool uses the Google Maps API to show a map with all the past survey sites. Users can select sites by drawing an area on the map, or by searching for site names in a Select2 box. The tool fails gracefully when Google Maps isn’t available, which makes it possible to run it offline (assuming you have local copies of the species images). This was very useful on my last trip to the Coral Sea, where I was away from mobile reception for weeks. When sites are selected, the code generates a summary table of the species frequencies, which can be exported to a dynamically-generated CSV. In addition, users can choose to display images of all the species in the table. As this can trigger the download of thousands of images, I used vanilla-lazyload to only load images when they enter the viewport. Finally, Frequency Explorer can also be used as a site selector for the Flashcards tool, as it contains a link to launch Flashcards with the set of selected sites (which is passed in the Flashcards query string).\nThe Flashcards tool relies on the excellent reveal.js library to dynamically generate a presentation with a random subset of images of species that were recorded at the selected sites. The presentation consists of pairs of image and name slides – each image slide is followed by a slide where the name of the previously-shown animal is revealed. As I found that trying to memorise all the species at once is too hard, I added the ability to adjust the difficulty level of the flashcards by setting a frequency threshold (e.g., show only species that were recorded on 25% of surveys), or by focusing on observations from a single survey method (e.g., method 2 surveys in the tropics tend to be much less diverse than method 1 surveys). To avoid reloading the entire page when the settings change, the slides are regenerated dynamically. Reveal isn’t really built to account for dynamic regeneration of slides, so I had to add a call to Reveal.toggleOverview(false) to get the cards to refresh correctly, but other than that it worked perfectly.\nFuture work There are several possible extensions to the work done so far.\nFirst, the integration of the tools into the RLS website is incomplete. They are still served in iframes from my GitHub Pages account, and the JSON data isn’t updated automatically. Completing the integration is dependent on the RLS developers, who also have other priorities. Other RLS-dependent items include better optimisation of images (they’re currently scaled down on the client side), and general performance improvements to the site.\nSecond, the tools themselves could be improved. For example, reliance on third-party libraries should be reduced (e.g., Frequency Explorer uses Bootstrap due to my limited design skills), and it’d be nice if site selections were stored and read from the URL of Frequency Explorer (this is already done for Flashcards). In addition, as the tools are used to train new RLS divers, it’d be useful to extend the Flashcards tool to run in test mode, where users would type in the names of the animals rather than just passively scroll through the presentation. This would make it possible to assess diver readiness to perform surveys based on their test scores.\nFinally, many other interesting things can be done with the RLS data (in addition to producing scientific papers and reports, which is the main focus of the researchers behind the project). Examples include using the images to automate species identification (as discussed more thoroughly in my previous post on the topic), and building models to predict survey output and detect anomalies (e.g., due to climate change or other unusual factors). If you have other ideas, or end up playing with the data and coming with interesting results, please share your findings in the comments section.\n","wordCount":"1825","inLanguage":"en","image":"https://yanirs.github.io/yanirseroussi.com/reef-life-survey-frequency-explorer-screenshot.png","datePublished":"2017-06-03T00:49:05Z","dateModified":"2017-06-03T00:49:05Z","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirs.github.io/yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirs.github.io/yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Exploring and visualising reef life survey data
</h1>
<div class=post-meta>June 3, 2017&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2017-06-03-exploring-and-visualising-reef-life-survey-data/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_360x0_resize_box_3.png 360w ,https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_480x0_resize_box_3.png 480w ,https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_720x0_resize_box_3.png 720w ,https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_1080x0_resize_box_3.png 1080w ,https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_1500x0_resize_box_3.png 1500w ,https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot.png 3035w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot.png alt width=3035 height=1442>
</figure>
<div class=post-content><p>Last year, I wrote about the <a href=http://reeflifesurvey.com target=_blank rel=noopener>Reef Life Survey</a> (RLS) project and <a href=http://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/>my experience with offline data collection on the Great Barrier Reef</a>. I found that using auto-generated flashcards with an increasing level of difficulty is a good way to memorise marine species. Since publishing that post, I have improved the flashcards and built a tool for exploring the aggregate survey data. Both tools are now publicly available on the RLS website. This post describes the tools and their implementation, and outlines possible directions for future work.</p>
<h2 id=the-tools>The tools<a hidden class=anchor aria-hidden=true href=#the-tools>#</a></h2>
<p>Each tool is fairly simple and focused on helping users achieve a small set of tasks. The best way to get familiar with the tools is to play with them by following the links below. If you&rsquo;re only interested in using the tools, you can stop reading after this section. The rest of this post describes the data behind the tools, and some technical implementation details.</p>
<figure>
<a href=reef-life-survey-frequency-explorer-screenshot.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_1080x0_resize_box_3.png 1080w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_1500x0_resize_box_3.png 1500w," src=https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-frequency-explorer-screenshot_hu373457bc2952799d7bbd8496305551d0_1306623_800x0_resize_box_3.png alt="Reef Life Survey Frequency Explorer screenshot" loading=lazy>
</a><figcaption>
<p>The <strong>Frequency Explorer</strong> tool lets users select RLS sites and view the species that have been recorded there (<a href=http://reeflifesurvey.com/frequency-explorer target=_blank rel=noopener>RLS website</a> | <a href=https://yanirs.github.io/tools/rls/frequency-explorer/ target=_blank rel=noopener>full-screen version</a>).
</p>
</figcaption>
</figure>
<figure>
<a href=reef-life-survey-flashcards-screenshot.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_1080x0_resize_box_3.png 1080w,
https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_1500x0_resize_box_3.png 1500w," src=https://yanirs.github.io/yanirseroussi.com/2017/06/03/exploring-and-visualising-reef-life-survey-data/reef-life-survey-flashcards-screenshot_hu0ecf79dd903f58a2cad6274428c21648_857114_800x0_resize_box_3.png alt="Reef Life Survey Flashcards screenshot" loading=lazy>
</a><figcaption>
<p>The <strong>Flashcards</strong> tool helps users memorise the names of marine species by showing random images of species from a chosen area (<a href=http://reeflifesurvey.com/flashcards target=_blank rel=noopener>RLS website</a> | <a href=https://yanirs.github.io/tools/rls/flashcards/ target=_blank rel=noopener>full-screen version</a>).
</p>
</figcaption>
</figure>
<h2 id=the-data>The data<a hidden class=anchor aria-hidden=true href=#the-data>#</a></h2>
<p>The RLS database includes data collected by volunteer scuba divers on the diversity and abundance of marine life in sites around the world. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef&rsquo;s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are analysed later to classify the type of substrate or growth (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record all the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) targets invertebrates and cryptic animals, and requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line. The <a href=http://reeflifesurvey.com/wp-content/uploads/2015/07/NEW-Methods-Manual_150815.pdf target=_blank rel=noopener>RLS manual</a> includes all the details on how surveys are performed. The data collected in the surveys is available for download from a <a href=http://reeflifesurvey.imas.utas.edu.au/static/landing.html target=_blank rel=noopener>Data Portal hosted by the Institute for Marine and Antarctic Studies at the University of Tasmania</a>. As of early June 2017, the downloadable dataset consists of over half a million data points from almost ten thousand surveys.</p>
<p>When I first started studying marine species, I had to find a source for photos. Initially, I used <a href=https://scrapy.org/ target=_blank rel=noopener>Scrapy</a> to build simple scrapers that downloaded photos from sites such as <a href=https://australianmuseum.net.au/animals target=_blank rel=noopener>The Australian Museum</a>, <a href=http://www.fishbase.org/ target=_blank rel=noopener>Fishbase</a>, and <a href=http://fishesofaustralia.net.au/ target=_blank rel=noopener>Fishes of Australia</a>. Last year, RLS made a large number of high-quality photos taken by volunteers available on their site (via the <a href=http://reeflifesurvey.com/species-search/ target=_blank rel=noopener>Species Search function</a>). In addition to their high quality, an advantage of the RLS photos over images from other sources is that they were all taken <em>in situ</em>, i.e., in each animal&rsquo;s natural habitat. On the other hand, other sites also include photos of dissections and hand-drawn illustrations, which aren&rsquo;t as useful for divers who want to see marine animals as they appear in the wild. Working exclusively with the RLS image dataset has significantly improved the appearance and usefulness of the tools I built.</p>
<p>The raw RLS survey data comes in the form of over 100MB of CSV files. For the purpose of building the tools, I summarised the data into two JSON files with an overall size of less than 3MB (less than 1MB when compressed). This made it possible to implement both tools as single-page apps that don&rsquo;t require any requests to the server after the initial fetching of the data. The two summary JSONs are:</p>
<ul>
<li><code>species.json</code> – a mapping from species ID to an array of five elements: scientific name, common name, species page URL, survey method (0: method 1, 1: method 2, or 2: both), and images (array of URLs).</li>
<li><code>site-surveys.json</code> – a mapping from site code to an array of seven elements: <a href=https://en.wikipedia.org/wiki/List_of_marine_ecoregions target=_blank rel=noopener>realm, ecoregion</a>, site name, longitude, latitude, number of surveys, and species counts (mapping from each observed species ID to the number of surveys on which it was seen).</li>
</ul>
<p>Both files use mappings to arrays rather than nested objects to reduce the download size. I originally created the files myself by downloading the CSVs from the data portal and scraping the RLS website for images and common names. Static versions of those files from early June 2017 can be found on GitHub (<a href=https://yanirs.github.io/tools/rls/api-species.json target=_blank rel=noopener>species.json</a> and <a href=https://yanirs.github.io/tools/rls/api-site-surveys.json target=_blank rel=noopener>site-surveys.json</a>). As part of the integration with the RLS website, the RLS developers will implement live versions of the files, which will get updated automatically. I&rsquo;ll add the links to the live versions when they become available. Please let me or the RLS team know if you find any issues with the data.</p>
<p>The approach I chose to produce the species counts in <code>site-surveys.json</code> doesn&rsquo;t take abundance into account, i.e., each species is counted once per survey regardless of the number of times it was seen on the survey. Ignoring abundance means that for sites with few surveys, the species count may not be a good indicator of future likelihood of occurrence. For example, some fish are solitary and seen rarely, while others occur in schools and are likely to be seen on every survey. However, this is less of an issue for sites with many surveys. In addition, this simple counting approach is easier to explain than some approaches that do account for abundance.</p>
<h2 id=implementation-details>Implementation details<a hidden class=anchor aria-hidden=true href=#implementation-details>#</a></h2>
<p>The source code for the tools can be found in my <a href=https://github.com/yanirs/yanirs.github.io/tree/master/tools/rls/src target=_blank rel=noopener>GitHub Pages repository</a>. Each tool is a simple single-page application, consisting of three files: <code>index.jade</code>, <code>main.coffee</code>, and <code>style.less</code>. In addition, the root source directory contains some common code in <code>common.less</code> and <code>util.coffee</code>, as well as configuration files for <a href=https://www.npmjs.com/ target=_blank rel=noopener>npm</a> and <a href=https://gruntjs.com/ target=_blank rel=noopener>Grunt</a>. Grunt is used to compile the source files from <a href=https://pugjs.org/ target=_blank rel=noopener>Jade/Pug</a>, <a href=http://coffeescript.org/ target=_blank rel=noopener>CoffeeScript</a>, and <a href=http://lesscss.org/ target=_blank rel=noopener>Less</a> to HTML, JS, and CSS respectively. These files are then served statically by <a href=https://pages.github.com/ target=_blank rel=noopener>GitHub Pages</a>.</p>
<p>The <a href=https://github.com/yanirs/yanirs.github.io/blob/master/tools/rls/src/util.coffee target=_blank rel=noopener>common CoffeeScript code</a> loads the JSONs asynchronously, and processes them into nested mappings that are easier to work with than arrays. In addition, the common code contains a method to summarise counts from multiple sites, by aggregating them as simple sums. This means that sites that are surveyed more frequently get weighted more heavily. For example, if a certain fish X was seen once in site A, twice in site B, and never in site C, its count across A, B, and C is <code>1 + 2 + 0 = 3</code>, but if A was surveyed once, B was surveyed twice, and C was surveyed seven times, X&rsquo;s aggregate frequency is <code>3 / (1 + 2 + 7) = 30%</code>. In the future, it may be worth normalising each site&rsquo;s species counts by the number of times the site was surveyed (making X&rsquo;s aggregate frequency <code>(1 / 1 + 2 / 2 + 0 / 7) / 3 = 66.67%</code>), but then rare species in rarely-surveyed sites may be overweighted.</p>
<p>The Frequency Explorer tool uses the Google Maps API to show a map with all the past survey sites. Users can select sites by drawing an area on the map, or by searching for site names in a <a href=https://select2.github.io/ target=_blank rel=noopener>Select2</a> box. The tool fails gracefully when Google Maps isn&rsquo;t available, which makes it possible to run it offline (assuming you have local copies of the species images). This was very useful on my last trip to the Coral Sea, where I was away from mobile reception for weeks. When sites are selected, the code generates a summary table of the species frequencies, which can be exported to a dynamically-generated CSV. In addition, users can choose to display images of all the species in the table. As this can trigger the download of thousands of images, I used <a href=https://www.npmjs.com/package/vanilla-lazyload target=_blank rel=noopener>vanilla-lazyload</a> to only load images when they enter the viewport. Finally, Frequency Explorer can also be used as a site selector for the Flashcards tool, as it contains a link to launch Flashcards with the set of selected sites (which is passed in the Flashcards query string).</p>
<p>The Flashcards tool relies on the excellent <a href=https://github.com/hakimel/reveal.js/ target=_blank rel=noopener>reveal.js</a> library to dynamically generate a presentation with a random subset of images of species that were recorded at the selected sites. The presentation consists of pairs of image and name slides – each image slide is followed by a slide where the name of the previously-shown animal is revealed. As I found that trying to memorise all the species at once is too hard, I added the ability to adjust the difficulty level of the flashcards by setting a frequency threshold (e.g., show only species that were recorded on 25% of surveys), or by focusing on observations from a single survey method (e.g., method 2 surveys in the tropics tend to be much less diverse than method 1 surveys). To avoid reloading the entire page when the settings change, the slides are regenerated dynamically. Reveal isn&rsquo;t really built to account for dynamic regeneration of slides, so I had to add a call to <code>Reveal.toggleOverview(false)</code> to get the cards to refresh correctly, but other than that it worked perfectly.</p>
<h2 id=future-work>Future work<a hidden class=anchor aria-hidden=true href=#future-work>#</a></h2>
<p>There are several possible extensions to the work done so far.</p>
<p>First, the integration of the tools into the RLS website is incomplete. They are still served in iframes from my GitHub Pages account, and the JSON data isn&rsquo;t updated automatically. Completing the integration is dependent on the RLS developers, who also have other priorities. Other RLS-dependent items include better optimisation of images (they&rsquo;re currently scaled down on the client side), and general performance improvements to the site.</p>
<p>Second, the tools themselves could be improved. For example, reliance on third-party libraries should be reduced (e.g., Frequency Explorer uses Bootstrap due to my limited design skills), and it&rsquo;d be nice if site selections were stored and read from the URL of Frequency Explorer (this is already done for Flashcards). In addition, as the tools are used to train new RLS divers, it&rsquo;d be useful to extend the Flashcards tool to run in test mode, where users would type in the names of the animals rather than just passively scroll through the presentation. This would make it possible to assess diver readiness to perform surveys based on their test scores.</p>
<p>Finally, many other interesting things can be done with the RLS data (in addition to producing <a href=http://reeflifesurvey.com/scientific-papers/ target=_blank rel=noopener>scientific papers and reports</a>, which is the main focus of the researchers behind the project). Examples include using the images to automate species identification (as discussed more thoroughly in my <a href=http://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/>previous post on the topic</a>), and building models to predict survey output and detect anomalies (e.g., due to climate change or other unusual factors). If you have other ideas, or end up playing with the data and coming with interesting results, please share your findings in the comments section.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/environment/>environment</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/javascript/>javascript</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/marine-science/>marine science</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/reef-life-survey/>reef life survey</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/software-engineering/>software engineering</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/web-development/>web development</a></li>
</ul>
</footer><section class=comment-section>
<strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirs.github.io%2fyanirseroussi.com%2f2017%2f06%2f03%2fexploring-and-visualising-reef-life-survey-data%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
</section>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://yanirs.github.io/yanirseroussi.com/>Yanir Seroussi | Data science and beyond</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><div class=mailing-list-container>
<form class=mailing-list action=https://tinyletter.com/yanir method=post target=popupwindow onsubmit="return window.open('https://tinyletter.com/yanir','popupwindow','scrollbars=yes,width=800,height=600'),!0">
<label for=mailing-list-email>Get new post notifications</label>
<input type=text name=email id=mailing-list-email placeholder="Email address">
<input type=hidden value=1 name=embed>
<input type=submit value=Subscribe>
</form>
</div>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>