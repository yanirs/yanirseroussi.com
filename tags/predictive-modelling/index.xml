<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Predictive Modelling on Yanir Seroussi – AI/ML Engineering Consultant</title><link>https://yanirseroussi.com/tags/predictive-modelling/</link><description>Recent content in Predictive Modelling on Yanir Seroussi – AI/ML Engineering Consultant</description><generator>Hugo -- 0.147.8</generator><language>en-au</language><copyright>Text and figures licensed under CC BY-NC-ND 4.0 by Yanir Seroussi, except where noted otherwise</copyright><lastBuildDate>Tue, 16 Jan 2024 09:56:03 +1000</lastBuildDate><atom:link href="https://yanirseroussi.com/tags/predictive-modelling/index.xml" rel="self" type="application/rss+xml"/><item><title>Customer lifetime value and the proliferation of misinformation on the internet</title><link>https://yanirseroussi.com/2017/01/08/customer-lifetime-value-and-the-proliferation-of-misinformation-on-the-internet/</link><pubDate>Sun, 08 Jan 2017 20:02:30 +0000</pubDate><guid>https://yanirseroussi.com/2017/01/08/customer-lifetime-value-and-the-proliferation-of-misinformation-on-the-internet/</guid><description>There&amp;rsquo;s a lot of misleading content on the estimation of customer lifetime value. Here&amp;rsquo;s what I learned about doing it well.</description></item><item><title>Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions</title><link>https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/</link><pubDate>Sat, 14 May 2016 19:57:03 +0000</pubDate><guid>https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/</guid><description>Discussing the need for untested assumptions and temporality in causal inference. Mostly based on Samantha Kleinberg&amp;rsquo;s Causality, Probability, and Time.</description></item><item><title>Why you should stop worrying about deep learning and deepen your understanding of causality instead</title><link>https://yanirseroussi.com/2016/02/14/why-you-should-stop-worrying-about-deep-learning-and-deepen-your-understanding-of-causality-instead/</link><pubDate>Sun, 14 Feb 2016 11:04:11 +0000</pubDate><guid>https://yanirseroussi.com/2016/02/14/why-you-should-stop-worrying-about-deep-learning-and-deepen-your-understanding-of-causality-instead/</guid><description>Causality is often overlooked but is of much higher relevance to most data scientists than deep learning.</description></item><item><title>The joys of offline data collection</title><link>https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/</link><pubDate>Sun, 24 Jan 2016 00:32:25 +0000</pubDate><guid>https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/</guid><description>Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey.</description></item><item><title>The hardest parts of data science</title><link>https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/</link><pubDate>Mon, 23 Nov 2015 04:14:21 +0000</pubDate><guid>https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/</guid><description>Defining feasible problems and coming up with reasonable ways of measuring solutions is harder than building accurate models or obtaining clean data.</description></item><item><title>Miscommunicating science: Simplistic models, nutritionism, and the art of storytelling</title><link>https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/</link><pubDate>Mon, 19 Oct 2015 00:02:32 +0000</pubDate><guid>https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/</guid><description>Nutritionism is a special case of misinterpretation and miscommunication of scientific results – something many data scientists encounter in their work.</description></item><item><title>The wonderful world of recommender systems</title><link>https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/</link><pubDate>Fri, 02 Oct 2015 05:25:57 +0000</pubDate><guid>https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/</guid><description>Giving an overview of the field and common paradigms, and debunking five common myths about recommender systems.</description></item><item><title>Learning about deep learning through album cover classification</title><link>https://yanirseroussi.com/2015/07/06/learning-about-deep-learning-through-album-cover-classification/</link><pubDate>Mon, 06 Jul 2015 22:21:42 +0000</pubDate><guid>https://yanirseroussi.com/2015/07/06/learning-about-deep-learning-through-album-cover-classification/</guid><description>Progress on my album cover classification project, highlighting lessons that would be useful to others who are getting started with deep learning.</description></item><item><title>Hopping on the deep learning bandwagon</title><link>https://yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/</link><pubDate>Sat, 06 Jun 2015 05:00:22 +0000</pubDate><guid>https://yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/</guid><description>To become proficient at solving data science problems, you need to get your hands dirty. Here, I used album cover classification to learn about deep learning.</description></item><item><title>First steps in data science: author-aware sentiment analysis</title><link>https://yanirseroussi.com/2015/05/02/first-steps-in-data-science-author-aware-sentiment-analysis/</link><pubDate>Sat, 02 May 2015 08:31:10 +0000</pubDate><guid>https://yanirseroussi.com/2015/05/02/first-steps-in-data-science-author-aware-sentiment-analysis/</guid><description>I became a data scientist by doing a PhD, but the same steps can be followed without a formal education program.</description></item><item><title>My PhD work</title><link>https://yanirseroussi.com/phd-work/</link><pubDate>Mon, 30 Mar 2015 03:23:33 +0000</pubDate><guid>https://yanirseroussi.com/phd-work/</guid><description>An overview of my PhD in data science / artificial intelligence. Thesis title: Text Mining and Rating Prediction with Topical User Models.</description></item><item><title>Learning to rank for personalised search (Yandex Search Personalisation – Kaggle Competition Summary – Part 2)</title><link>https://yanirseroussi.com/2015/02/11/learning-to-rank-for-personalised-search-yandex-search-personalisation-kaggle-competition-summary-part-2/</link><pubDate>Wed, 11 Feb 2015 06:34:17 +0000</pubDate><guid>https://yanirseroussi.com/2015/02/11/learning-to-rank-for-personalised-search-yandex-search-personalisation-kaggle-competition-summary-part-2/</guid><description>My team&amp;rsquo;s solution to the Yandex Search Personalisation competition (finished 9th out of 194 teams).</description></item><item><title>Is thinking like a search engine possible? (Yandex search personalisation – Kaggle competition summary – part 1)</title><link>https://yanirseroussi.com/2015/01/29/is-thinking-like-a-search-engine-possible-yandex-search-personalisation-kaggle-competition-summary-part-1/</link><pubDate>Thu, 29 Jan 2015 10:37:39 +0000</pubDate><guid>https://yanirseroussi.com/2015/01/29/is-thinking-like-a-search-engine-possible-yandex-search-personalisation-kaggle-competition-summary-part-1/</guid><description>Insights on search personalisation and SEO from participating in a Kaggle competition (finished 9th out of 194 teams).</description></item><item><title>Stochastic Gradient Boosting: Choosing the Best Number of Iterations</title><link>https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/</link><pubDate>Mon, 29 Dec 2014 02:30:06 +0000</pubDate><guid>https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/</guid><description>Exploring an approach to choosing the optimal number of iterations in stochastic gradient boosting, following a bug I found in scikit-learn.</description></item><item><title>Fitting noise: Forecasting the sale price of bulldozers (Kaggle competition summary)</title><link>https://yanirseroussi.com/2014/11/19/fitting-noise-forecasting-the-sale-price-of-bulldozers-kaggle-competition-summary/</link><pubDate>Wed, 19 Nov 2014 09:17:34 +0000</pubDate><guid>https://yanirseroussi.com/2014/11/19/fitting-noise-forecasting-the-sale-price-of-bulldozers-kaggle-competition-summary/</guid><description>Summary of a Kaggle competition to forecast bulldozer sale price, where I finished 9th out of 476 teams.</description></item><item><title>Greek Media Monitoring Kaggle competition: My approach</title><link>https://yanirseroussi.com/2014/10/07/greek-media-monitoring-kaggle-competition-my-approach/</link><pubDate>Tue, 07 Oct 2014 03:21:35 +0000</pubDate><guid>https://yanirseroussi.com/2014/10/07/greek-media-monitoring-kaggle-competition-my-approach/</guid><description>Summary of my approach to the Greek Media Monitoring Kaggle competition, where I finished 6th out of 120 teams.</description></item><item><title>Bandcamp recommendation and discovery algorithms</title><link>https://yanirseroussi.com/2014/09/19/bandcamp-recommendation-and-discovery-algorithms/</link><pubDate>Fri, 19 Sep 2014 14:26:55 +0000</pubDate><guid>https://yanirseroussi.com/2014/09/19/bandcamp-recommendation-and-discovery-algorithms/</guid><description>The recommendation backend for my BCRecommender service for personalised Bandcamp music discovery.</description></item><item><title>How to (almost) win Kaggle competitions</title><link>https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/</link><pubDate>Sun, 24 Aug 2014 12:40:53 +0000</pubDate><guid>https://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/</guid><description>Summary of a talk I gave at the Data Science Sydney meetup with ten tips on almost-winning Kaggle competitions.</description></item><item><title>Kaggle competition tips and summaries</title><link>https://yanirseroussi.com/kaggle/</link><pubDate>Sat, 05 Apr 2014 23:46:10 +0000</pubDate><guid>https://yanirseroussi.com/kaggle/</guid><description>Pointers to all my Kaggle advice posts and competition summaries.</description></item></channel></rss>