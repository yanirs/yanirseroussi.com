<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>a/b testing on Yanir Seroussi | Data science and beyond</title><link>https://yanirseroussi.com/tags/a/b-testing/</link><description>Recent content in a/b testing on Yanir Seroussi | Data science and beyond</description><generator>Hugo -- gohugo.io</generator><language>en-au</language><copyright>&amp;copy; [Yanir Seroussi](https://yanirseroussi.com/about/)&amp;nbsp;&amp;nbsp;|</copyright><atom:link href="https://yanirseroussi.com/tags/a/b-testing/index.xml" rel="self" type="application/rss+xml"/><item><title>Analysis strategies in online A/B experiments: Intention-to-treat, per-protocol, and other lessons from clinical trials</title><link>https://yanirseroussi.com/2022/01/14/analysis-strategies-in-online-a-b-experiments/</link><pubDate>Fri, 14 Jan 2022 00:05:40 +0000</pubDate><guid>https://yanirseroussi.com/2022/01/14/analysis-strategies-in-online-a-b-experiments/</guid><description>Epidemiologists analyse clinical trials to estimate the intention-to-treat and per-protocol effects. This post applies their strategies to online experiments.</description></item><item><title>Some highlights from 2020</title><link>https://yanirseroussi.com/2021/04/05/some-highlights-from-2020/</link><pubDate>Mon, 05 Apr 2021 06:41:48 +0000</pubDate><guid>https://yanirseroussi.com/2021/04/05/some-highlights-from-2020/</guid><description>My track record of posting here has been pretty poor in 2020, partly because of a bunch of content I&amp;rsquo;ve contributed elsewhere. In general, my guiding principle for posting is to only add stuff I&amp;rsquo;d want to read or cite, e.g., because I haven&amp;rsquo;t seen it discussed elsewhere. Well, no one has compiled a meta-post of my public work from 2020 (that I know of), so it&amp;rsquo;s finally time to publish it myself.</description></item><item><title>Making Bayesian A/B testing more accessible</title><link>https://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/</link><pubDate>Sun, 19 Jun 2016 10:32:15 +0000</pubDate><guid>https://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/</guid><description>Much has been written in recent years on the pitfalls of using traditional hypothesis testing with online A/B tests. A key issue is that you&amp;rsquo;re likely to end up with many false positives if you repeatedly check your results and stop as soon as you reach statistical significance. One way of dealing with this issue is by following a Bayesian approach to deciding when the experiment should be stopped. While I find the Bayesian view of statistics much more intuitive than the frequentist view, it can be quite challenging to explain Bayesian concepts to laypeople.</description></item></channel></rss>