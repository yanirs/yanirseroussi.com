<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Stochastic Gradient Boosting: Choosing the Best Number of Iterations | Yanir Seroussi | Engineering Data Science &amp; More</title>
<meta name="keywords" content="data science, gradient boosting, machine learning, predictive modelling, scikit-learn">
<meta name="description" content="Exploring an approach to choosing the optimal number of iterations in stochastic gradient boosting, following a bug I found in scikit-learn.">
<meta name="author" content="Yanir Seroussi">
<link rel="canonical" href="https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/">
<meta name="google-site-verification" content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU">
<link crossorigin="anonymous" href="/assets/css/stylesheet.6fb9fcf3671a76afec60509d26e3f0084405763b2a64fe4e9d447c94605f7822.css" integrity="sha256-b7n882cadq/sYFCdJuPwCEQFdjsqZP5OnUR8lGBfeCI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://yanirseroussi.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yanirseroussi.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yanirseroussi.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yanirseroussi.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://yanirseroussi.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Stochastic Gradient Boosting: Choosing the Best Number of Iterations" />
<meta property="og:description" content="Exploring an approach to choosing the optimal number of iterations in stochastic gradient boosting, following a bug I found in scikit-learn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2014-12-29T02:30:06+00:00" />
<meta property="article:modified_time" content="2023-07-06T09:28:02+10:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Stochastic Gradient Boosting: Choosing the Best Number of Iterations"/>
<meta name="twitter:description" content="Exploring an approach to choosing the optimal number of iterations in stochastic gradient boosting, following a bug I found in scikit-learn."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://yanirseroussi.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Stochastic Gradient Boosting: Choosing the Best Number of Iterations",
      "item": "https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Stochastic Gradient Boosting: Choosing the Best Number of Iterations",
  "name": "Stochastic Gradient Boosting: Choosing the Best Number of Iterations",
  "description": "Exploring an approach to choosing the optimal number of iterations in stochastic gradient boosting, following a bug I found in scikit-learn.",
  "keywords": [
    "data science", "gradient boosting", "machine learning", "predictive modelling", "scikit-learn"
  ],
  "articleBody": "In my summary of the Kaggle bulldozer price forecasting competition, I mentioned that part of my solution was based on stochastic gradient boosting. To reduce runtime, the number of boosting iterations was set by minimising the loss on the out-of-bag (OOB) samples, skipping trees where samples are in-bag. This approach was motivated by a bug in scikit-learn, where the OOB loss estimate was calculated on the in-bag samples, meaning that it always improved (and thus was useless for the purpose of setting the number of iterations).\nThe bug in scikit-learn was fixed by porting the solution used in R’s GBM package, where the number of iterations is estimated by minimising the improvement on the OOB samples in each boosting iteration. This approach is known to underestimate the number of required iterations, which means that it’s not very useful in practice. This underestimation may be due to the fact that the GBM method is partly estimated on in-bag samples, as the OOB samples for the Nth iteration are likely to have been in-bag in previous iterations.\nI was curious about how my approach compares to the GBM method. Preliminary results on the toy dataset from scikit-learn’s documentation looked promising:\nMy approach (TSO) beat both 5-fold cross-validation (CV) and the GBM/scikit-learn method (SKO), as TSO obtains its minimum at the closest number of iterations to the test set’s (T) optimal value.\nThe next step in testing TSO’s viability was to rerun Ridgeway’s experiments from Section 3.3 of the GBM documentation (R code here). I used the same 12 UCI datasets that Ridgeway used, running 5×2 cross-validation on each one. For each dataset, the score was obtained by dividing the mean loss of the best method on the dataset by the loss of each method. Hence, all scores are between 0.0 and 1.0, with the best score being 1.0. The following figure summarises the results on the 12 datasets.\nThe following table shows the raw data that was used to produce the figure.\nDataset CV SKO TSO creditrating 0.9962 0.9771 1 breastcancer 1 0.6675 0.4869 mushrooms 0.9588 0.9963 1 abalone 1 0.9754 0.9963 ionosphere 0.9919 1 0.8129 diabetes 1 0.9869 0.9985 autoprices 1 0.9565 0.5839 autompg 1 0.8753 0.9948 bostonhousing 1 0.8299 0.5412 haberman 1 0.9793 0.9266 cpuperformance 0.9934 0.9160 1 adult 1 0.9824 0.9991 The main finding is that CV remains the most reliable approach. Even when CV is not the best-performing method, it’s not much worse than the best method (this is in line with Ridgeway’s findings). TSO yielded the best results on 3/12 of the datasets, and beat SKO 7/12 times. However, TSO’s results are the most variant of the three methods: when it fails, it often yields very poor results.\nIn conclusion, stick to cross-validation for the best results. It’s more computationally intensive than SKO and TSO, but can be parallelised. I still think that there may be a way to avoid cross-validation, perhaps by extending SKO/TSO in more intelligent ways (see some interesting ideas by Eugene Dubossarsky here and here). Any comments/ideas are very welcome.\n",
  "wordCount" : "507",
  "inLanguage": "en",
  "datePublished": "2014-12-29T02:30:06Z",
  "dateModified": "2023-07-06T09:28:02+10:00",
  "author":{
    "@type": "Person",
    "name": "Yanir Seroussi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yanir Seroussi | Engineering Data Science \u0026 More",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yanirseroussi.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yanirseroussi.com/" accesskey="h" title="Yanir Seroussi | Engineering Data Science &amp; More (Alt + H)">Yanir Seroussi | Engineering Data Science &amp; More</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yanirseroussi.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Stochastic Gradient Boosting: Choosing the Best Number of Iterations
    </h1>
    <div class="post-meta"><span title='2014-12-29 02:30:06 +0000 UTC'>December 29, 2014</span>&nbsp;|&nbsp;<a href="https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2014-12-29-stochastic-gradient-boosting-choosing-the-best-number-of-iterations/index.md" rel="noopener noreferrer" target="_blank">Suggest changes</a>

</div>
  </header> 
  <div class="post-content"><p>In my <a href="https://yanirseroussi.com/2014/11/19/fitting-noise-forecasting-the-sale-price-of-bulldozers-kaggle-competition-summary/" title="Fitting noise: Forecasting the sale price of bulldozers (Kaggle competition summary)">summary of the Kaggle bulldozer price forecasting competition</a>, I mentioned that part of my solution was based on stochastic gradient boosting. To reduce runtime, the number of boosting iterations was set by minimising the loss on the out-of-bag (OOB) samples, skipping trees where samples are in-bag. This approach was motivated <a href="https://github.com/scikit-learn/scikit-learn/issues/1802" target="_blank" rel="noopener">by a bug in scikit-learn</a>, where the OOB loss estimate was calculated on the in-bag samples, meaning that it always improved (and thus was useless for the purpose of setting the number of iterations).</p>
<p>The bug in scikit-learn was <a href="https://github.com/scikit-learn/scikit-learn/pull/2188" target="_blank" rel="noopener">fixed</a> by porting the solution used in <a href="http://cran.r-project.org/web/packages/gbm/index.html" target="_blank" rel="noopener">R&rsquo;s GBM package</a>, where the number of iterations is estimated by minimising the improvement on the OOB samples in each boosting iteration. This approach is known to <a href="http://cran.open-source-solution.org/web/packages/gbm/vignettes/gbm.pdf" target="_blank" rel="noopener">underestimate the number of required iterations</a>, which means that it&rsquo;s not very useful in practice. This underestimation may be due to the fact that the GBM method is partly estimated on in-bag samples, as the OOB samples for the Nth iteration are likely to have been in-bag in previous iterations.</p>
<p>I was curious about how my approach compares to the GBM method. Preliminary results on the <a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_oob.html" target="_blank" rel="noopener">toy dataset from scikit-learn&rsquo;s documentation</a> looked promising:</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="gradient-boosting-out-of-bag-experiment-toy-dataset.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiment-toy-dataset_hu02dc1ebe47af12a7ec8f5877429b5dec_71277_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiment-toy-dataset_hu02dc1ebe47af12a7ec8f5877429b5dec_71277_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiment-toy-dataset_hu02dc1ebe47af12a7ec8f5877429b5dec_71277_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiment-toy-dataset.png 858w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiment-toy-dataset_hu02dc1ebe47af12a7ec8f5877429b5dec_71277_800x0_resize_box_3.png"
        
      
        alt="Gradient Boosting out of bag experiment (toy dataset)"loading="lazy"
    />
  </a>
</figure>

<p>My approach (TSO) beat both 5-fold cross-validation (CV) and the GBM/scikit-learn method (SKO), as TSO obtains its minimum at the closest number of iterations to the test set&rsquo;s (T) optimal value.</p>
<p>The next step in testing TSO&rsquo;s viability was to rerun <a href="http://cran.open-source-solution.org/web/packages/gbm/vignettes/gbm.pdf" target="_blank" rel="noopener">Ridgeway&rsquo;s experiments from Section 3.3 of the GBM documentation</a> (<a href="https://github.com/harrysouthworth/gbm/blob/master/demo/OOB-reps.R" target="_blank" rel="noopener">R code here</a>). I used the same 12 UCI datasets that Ridgeway used, running 5×2 cross-validation on each one. For each dataset, the score was obtained by dividing the mean loss of the best method on the dataset by the loss of each method. Hence, all scores are between 0.0 and 1.0, with the best score being 1.0. The following figure summarises the results on the 12 datasets.</p>













  
    
      
    
  
    
      
    
  
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="gradient-boosting-out-of-bag-experiments-uci-datasets" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 591px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiments-uci-datasets_hub650f2df69f9df4831910f3fa535d462_3872_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiments-uci-datasets_hub650f2df69f9df4831910f3fa535d462_3872_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiments-uci-datasets.png 591w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2014/12/29/stochastic-gradient-boosting-choosing-the-best-number-of-iterations/gradient-boosting-out-of-bag-experiments-uci-datasets.png"
        
      
        alt="Gradient Boosting out of bag experiment (UCI datasets)"loading="lazy"
    />
  </a>
</figure>

<p>The following table shows the raw data that was used to produce the figure.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>CV</th>
<th>SKO</th>
<th>TSO</th>
</tr>
</thead>
<tbody>
<tr>
<td>creditrating</td>
<td>0.9962</td>
<td>0.9771</td>
<td>1</td>
</tr>
<tr>
<td>breastcancer</td>
<td>1</td>
<td>0.6675</td>
<td>0.4869</td>
</tr>
<tr>
<td>mushrooms</td>
<td>0.9588</td>
<td>0.9963</td>
<td>1</td>
</tr>
<tr>
<td>abalone</td>
<td>1</td>
<td>0.9754</td>
<td>0.9963</td>
</tr>
<tr>
<td>ionosphere</td>
<td>0.9919</td>
<td>1</td>
<td>0.8129</td>
</tr>
<tr>
<td>diabetes</td>
<td>1</td>
<td>0.9869</td>
<td>0.9985</td>
</tr>
<tr>
<td>autoprices</td>
<td>1</td>
<td>0.9565</td>
<td>0.5839</td>
</tr>
<tr>
<td>autompg</td>
<td>1</td>
<td>0.8753</td>
<td>0.9948</td>
</tr>
<tr>
<td>bostonhousing</td>
<td>1</td>
<td>0.8299</td>
<td>0.5412</td>
</tr>
<tr>
<td>haberman</td>
<td>1</td>
<td>0.9793</td>
<td>0.9266</td>
</tr>
<tr>
<td>cpuperformance</td>
<td>0.9934</td>
<td>0.9160</td>
<td>1</td>
</tr>
<tr>
<td>adult</td>
<td>1</td>
<td>0.9824</td>
<td>0.9991</td>
</tr>
</tbody>
</table>
<p>The main finding is that CV remains the most reliable approach. Even when CV is not the best-performing method, it&rsquo;s not much worse than the best method (this is in line with Ridgeway&rsquo;s findings). TSO yielded the best results on 3/12 of the datasets, and beat SKO 7/12 times. However, TSO&rsquo;s results are the most variant of the three methods: when it fails, it often yields very poor results.</p>
<p>In conclusion, stick to cross-validation for the best results. It&rsquo;s more computationally intensive than SKO and TSO, but can be parallelised. I still think that there may be a way to avoid cross-validation, perhaps by extending SKO/TSO in more intelligent ways (see some interesting ideas by Eugene Dubossarsky <a href="http://cavemoosum.blogspot.com.au/2014/02/cross-validation-is-over-long-live.html" target="_blank" rel="noopener">here</a> and <a href="http://cavemoosum.blogspot.com.au/2014/03/cross-validation-is-not-quite-kaput-but.html" target="_blank" rel="noopener">here</a>). Any comments/ideas are very welcome.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://yanirseroussi.com/tags/data-science/">data science</a></li>
      <li><a href="https://yanirseroussi.com/tags/gradient-boosting/">gradient boosting</a></li>
      <li><a href="https://yanirseroussi.com/tags/machine-learning/">machine learning</a></li>
      <li><a href="https://yanirseroussi.com/tags/predictive-modelling/">predictive modelling</a></li>
      <li><a href="https://yanirseroussi.com/tags/scikit-learn/">scikit-learn</a></li>
    </ul>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on twitter"
        href="https://twitter.com/intent/tweet/?text=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations&amp;url=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f&amp;hashtags=datascience%2cgradientboosting%2cmachinelearning%2cpredictivemodelling%2cscikit-learn">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f&amp;title=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations&amp;summary=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations&amp;source=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f&title=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on whatsapp"
        href="https://api.whatsapp.com/send?text=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations%20-%20https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Stochastic Gradient Boosting: Choosing the Best Number of Iterations on telegram"
        href="https://telegram.me/share/url?text=Stochastic%20Gradient%20Boosting%3a%20Choosing%20the%20Best%20Number%20of%20Iterations&amp;url=https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer><section class="comment-section">
  

  <strong>No comments</strong>
  <a
    class="comment-button"
    href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirseroussi.com%2f2014%2f12%2f29%2fstochastic-gradient-boosting-choosing-the-best-number-of-iterations%2f&body=<!-- Post your comment here and it may get added to the site -->"
    rel="noopener noreferrer"
    target="_blank"
  >
    Comment via GitHub issue
  </a>

  
  
  
  

  
</section>



</article>
    </main>
    
<footer class="footer">
    <span>Text and figures licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener">CC BY-NC-ND 4.0</a> by <a href="https://yanirseroussi.com/about/">Yanir Seroussi</a>, except where noted otherwise  |</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer><div class="mailing-list-container">
  <form
      class="mailing-list"
      action="https://yanirseroussi.us17.list-manage.com/subscribe/post?u=3c08aa3ff27dd92978019febd&amp;id=bc3ab705af"
      method="post"
      target="_blank"
      novalidate
  >
    <label for="mailing-list-email">Get new post notifications</label>
    <input type="text" name="EMAIL" id="mailing-list-email" placeholder="Email address" />
    <div style="position: absolute; left: -5000px;" aria-hidden="true">
      <input type="text" name="b_3c08aa3ff27dd92978019febd_bc3ab705af" tabindex="-1" value="" />
    </div>
    <input type="submit" value="Subscribe" />
  </form>

  <div class="footer">
    Alternatively, <a href="https://github.com/yanirs/yanirseroussi.com" rel="noopener" target="_blank">watch on GitHub</a>
    or <a href="https://yanirseroussi.com/index.xml">subscribe to RSS feed</a>.
  </div>
</div>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
