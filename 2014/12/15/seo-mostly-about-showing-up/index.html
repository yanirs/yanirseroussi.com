<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>SEO: Mostly about showing up? | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="marketing,search engine optimisation,SEO,traction book">
<meta name=description content="In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender&rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/>
<link crossorigin=anonymous href=/yanirseroussi.com/assets/css/stylesheet.min.7603165cb47dcda1f46a839ca379731b2f33098c043e75f680940e69a5d546a8.css integrity="sha256-dgMWXLR9zaH0aoOco3lzGy8zCYwEPnX2gJQOaaXVRqg=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/yanirseroussi.com/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirs.github.io/yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirs.github.io/yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirs.github.io/yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirs.github.io/yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirs.github.io/yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="SEO: Mostly about showing up?">
<meta property="og:description" content="In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender&rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/">
<meta property="og:image" content="https://yanirs.github.io/yanirseroussi.com/bcrecommender-search-queries.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2014-12-15T04:25:25+00:00">
<meta property="article:modified_time" content="2014-12-15T04:25:25+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirs.github.io/yanirseroussi.com/bcrecommender-search-queries.png">
<meta name=twitter:title content="SEO: Mostly about showing up?">
<meta name=twitter:description content="In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender&rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirs.github.io/yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"SEO: Mostly about showing up?","item":"https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"SEO: Mostly about showing up?","name":"SEO: Mostly about showing up?","description":"In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender\u0026rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.","keywords":["marketing","search engine optimisation","SEO","traction book"],"articleBody":"In previous posts about getting traction for my Bandcamp recommendations project (BCRecommender), I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – most new visitors came from referrals from blogs and Twitter. It turns out that the problem was not showing up for the SEO game: most of BCRecommender’s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for thin/duplicate content.\nRecently, I beefed up most of the pages, created a sitemap, and removed most pages from robots.txt. This resulted in a significant increase in traffic, as illustrated by the above graph. The number of organic impressions went up from less than ten per day to over a thousand. This is expected to go up even further, as only about 10% of pages are indexed. In addition, some traffic went to my staging site because it wasn’t blocked from crawling (I had to set up a new staging site that is password-protected and add a redirect from the old site to the production site – a bit annoying but I couldn’t find a better solution).\nI hope Google won’t suddenly decide that BCRecommender content is not valuable or too thin. The content is automatically generated, which is “bad”, but it doesn’t “consist of paragraphs of random text that make no sense to the reader but which may contain search keywords”. As a (completely unbiased) user, I think it is valuable to find similar albums when searching for an album you like – an example that represents the majority of people that click through to BCRecommender. Judging from the main engagement measure I’m using (time spent on site), a good number of these people are happy with what they find.\nMore updates to come in the future. For now, my conclusion is: thin content is better than no content, as long as it’s relevant to what people are searching for and provides real value.\n","wordCount":"333","inLanguage":"en","image":"https://yanirs.github.io/yanirseroussi.com/bcrecommender-search-queries.png","datePublished":"2014-12-15T04:25:25Z","dateModified":"2014-12-15T04:25:25Z","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirs.github.io/yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirs.github.io/yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
SEO: Mostly about showing up?
</h1>
<div class=post-meta>December 15, 2014&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2014-12-15-seo-mostly-about-showing-up/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/bcrecommender-search-queries_hu97bce2d6c38a7ed1236b5abe2f40bfe4_11489_360x0_resize_box_3.png 360w ,https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/bcrecommender-search-queries.png 444w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirs.github.io/yanirseroussi.com/2014/12/15/seo-mostly-about-showing-up/bcrecommender-search-queries.png alt width=444 height=295>
</figure>
<div class=post-content><p>In previous posts about getting traction for my <a href=http://www.bcrecommender.com target=_blank rel=noopener>Bandcamp recommendations project (BCRecommender)</a>, I mentioned search engine optimisation (SEO) as one of the promising traction channels. Unfortunately, early efforts yielded negligible traffic – <a href=http://yanirseroussi.com/2014/11/05/bcrecommender-traction-update/ title="BCRecommender Traction Update">most new visitors came from referrals from blogs and Twitter</a>. It turns out that the problem was <strong>not showing up for the SEO game</strong>: most of BCRecommender&rsquo;s pages were blocked for crawling via robots.txt because I was worried that search engines (=Google) would penalise the website for <a href="https://support.google.com/webmasters/answer/2604719?hl=en" target=_blank rel=noopener>thin/duplicate content</a>.</p>
<p>Recently, I beefed up most of the pages, created a sitemap, and removed most pages from robots.txt. This resulted in a significant increase in traffic, as illustrated by the above graph. The number of organic impressions went up from less than ten per day to over a thousand. This is expected to go up even further, as only about 10% of pages are indexed. In addition, some traffic went to my staging site because it wasn&rsquo;t blocked from crawling (I had to set up a new staging site that is password-protected and add a redirect from the old site to the production site – a bit annoying but I couldn&rsquo;t find a better solution).</p>
<p>I hope Google won&rsquo;t suddenly decide that BCRecommender content is not valuable or too thin. The content is automatically generated, which is <a href=https://support.google.com/webmasters/answer/2721306 target=_blank rel=noopener>&ldquo;bad&rdquo;</a>, but it doesn&rsquo;t &ldquo;consist of paragraphs of random text that make no sense to the reader but which may contain search keywords&rdquo;. As a (completely unbiased) user, I think it is valuable to find similar albums when searching for an album you like – an example that represents the majority of people that click through to BCRecommender. Judging from the main engagement measure I&rsquo;m using (time spent on site), a good number of these people are happy with what they find.</p>
<p>More updates to come in the future. For now, my conclusion is: thin content is better than no content, as long as it&rsquo;s relevant to what people are searching for and provides real value.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/marketing/>marketing</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/search-engine-optimisation/>search engine optimisation</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/seo/>SEO</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/traction-book/>traction book</a></li>
</ul>
</footer><section class=comment-section>
<strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirs.github.io%2fyanirseroussi.com%2f2014%2f12%2f15%2fseo-mostly-about-showing-up%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
</section>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://yanirs.github.io/yanirseroussi.com/>Yanir Seroussi | Data science and beyond</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><div class=mailing-list-container>
<form class=mailing-list action=https://tinyletter.com/yanir method=post target=popupwindow onsubmit="return window.open('https://tinyletter.com/yanir','popupwindow','scrollbars=yes,width=800,height=600'),!0">
<label for=mailing-list-email>Get new post notifications</label>
<input type=text name=email id=mailing-list-email placeholder="Email address">
<input type=hidden value=1 name=embed>
<input type=submit value=Subscribe>
</form>
</div>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>