---
title: 'Miscommunicating science: Simplistic models, nutritionism, and the art of storytelling'
author: Yanir Seroussi
type: post
date: 2015-10-19T00:02:32+00:00
url: /2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/
cover:
  image: health-star-dish.jpg
summary: Nutritionism is a special case of misinterpretation and miscommunication of scientific results &ndash; something many data scientists encounter in their work.
tags:
  - data business
  - data science
  - health
  - machine learning
  - nutrition
  - nutritionism
  - predictive modelling

---
I recently finished reading the book <a href="http://michaelpollan.com/books/in-defense-of-food/" target="_blank" rel="noopener">In Defense of Food: An Eater's Manifesto</a> by Michael Pollan. The book criticises <a href="https://en.wikipedia.org/wiki/Nutritionism" target="_blank" rel="noopener">nutritionism</a> &ndash; the idea that one should eat according to the sum of measured nutrients while ignoring the food that contains these nutrients. The key argument of the book is that since the knowledge derived using food science is still very limited, completely relying on the partial findings and tools provided by this science is likely to lead to health issues. Instead, the author says we should "_Eat food. Not too much. Mostly plants._" One of the reasons I found the book interesting is that nutritionism is a special case of misinterpretation and miscommunication of scientific results. This is something many data scientists encounter in their everyday work &ndash; finding the balance between simple and complex models, the need to "sell" models and their results to non-technical stakeholders, and the requirement for well-performing models. This post explores these issues through the example of predicting human health based on diet.

As an aside, I generally agree with the book's message, which is backed by fairly thorough research (though it is a bit dated, as the book was released in 2008). There are many commercial interests invested in persuading us to eat things that may be edible, but shouldn't really be considered food. These food-like products tend to rely on health claims that dumb down the science. A common example can be found in various fat-free products, where healthy fat is replaced with unhealthy amounts of sugar to compensate for the loss of flavour. These products are then marketed as healthy due to their lack of fat. The book is full of such examples, and is definitely worth reading, especially if you live in the US or in a country that's heavily influenced by American food culture.

### Running example: Predicting a person's health based on their diet

Predicting health based on diet isn't an easy problem. First, how do you quantify and measure health? You could use proxies like longevity and occurrence/duration of disease, but these are imperfect measures because you can have a long unhealthy life (thanks to modern medicine) and some diseases are more unbearable than others. Another issue is that there are many factors other than diet that contribute to health, such as genetics, age, lifestyle, access to healthcare, etc. Finally, even if you could reliably study the effect of diet in isolation from other factors, there's the question of measuring the diet. Do you measure each nutrient separately or do you look at foods and consumption patterns? Do you group foods by time (e.g., looking at overall daily or monthly patterns)? If you just looked at the raw data of foods and nutrients consumed at certain points in time, every studied subject is likely to be an outlier (due to the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank" rel="noopener">curse of dimensionality</a>). The raw data on foods consumed by individuals has to be grouped in some way to build a generalisable model, but groupings necessitate removal of some data.

Modelling real-world data is rarely straightforward. Many assumptions are embedded in the measurements and models. Good scientific papers are explicit about the shortcomings and limitations of the presented work. However, by the time scientific studies make it to the real world, shortcomings and limitations are removed to present palatable (and often wrong) conclusions to a general audience. This is illustrated nicely by the following comic:

{{< figure src="phd-comics-science-news-cycle.gif" alt="PHD Comics: Science News Cycle" link="http://www.phdcomics.com/comics.php?n=1174" >}}

### Selling your model with simple explanations

People like simple explanations for complex phenomena. If you work as a data scientist, or if you are planning to become/hire one, you've probably seen **storytelling** listed as one of the key skills that data scientists should have. Unlike "real" scientists that work in academia and have to explain their results mostly to peers who can handle technical complexities, data scientists in industry have to deal with non-technical stakeholders who want to understand how the models work. However, these stakeholders rarely have the time or patience to understand how things truly work. What they want is a simple hand-wavy explanation to make them _feel_ as if they understand the matter &ndash; they want a _story_, not a technical report (an aside: don't feel too smug, there is a lot of knowledge out there and in matters that fall outside of our main interests we are all non-technical stakeholders who get fed simple stories).

One of the simplest stories that most people can understand is the story of **correlation**. Going back to the running example of predicting health based on diet, it is well-known that excessive consumption of certain fats under certain conditions is correlated with an increase in likelihood of certain diseases. This is simplified in some stories to "consuming more fat increases your chance of disease", which leads to the conclusion that consuming no fat at all decreases the chance of disease to zero. While this may sound ridiculous, it's the sad reality. According to <a href="http://www.foodinsight.org/2015-food-health-survey-consumer-research" target="_blank" rel="noopener">a recent survey</a>, while the image of fat has improved over the past few years, 42% of Americans still try to limit or avoid all fats.

A slightly more involved story is that of **linear models** &ndash; looking at the effect of the most important factors, rather than presenting a single factor's contribution. This storytelling technique is commonly used even with non-linear models, where the most important features are identified using various techniques. The problem is that people still tend to interpret this form of presentation as a simple linear relationship. Expanding on the previous example, this approach goes from a single-minded focus on fat to the need to consume less fat and sugar, but more calcium, protein and vitamin D. Unfortunately, even linear models with tens of variables are hard for people to use and follow. In the case of nutrition, few people really track the intake of all the nutrients covered by recommended daily intakes.

### Few interesting relationships are linear

Complex phenomena tend to be explained by complex non-linear models. For example, it's not enough to consume the "right" amount of calcium &ndash; <a href="https://en.wikipedia.org/wiki/Calcium#Nutrition" target="_blank" rel="noopener">you also need vitamin D to absorb it</a>, but <a href="http://www.medicaldaily.com/vitamin-d-benefits-are-enhanced-if-meal-contains-fat-absorbing-more-supplements-311248" target="_blank" rel="noopener">popping a few vitamin D pills isn't going to work well if you don't consume them with fat</a>, though <a href="https://en.wikipedia.org/wiki/Trans_fat#Health_risks" target="_blank" rel="noopener">over-consumption of certain fats is likely to lead to health issues</a>. This list of human-friendly rules can go on and on, but reality is much more complex. It is naive to think that it is possible to predict something as complex as human health with a simple linear model that is based on daily nutrient intake. That being said, some relationships do lend themselves to simple rules of thumb. For example, if you don't have enough vitamin C, you're very likely to get <a href="https://en.wikipedia.org/wiki/Scurvy" target="_blank" rel="noopener">scurvy</a>, and people who don't consume enough vitamin B1 may contract <a href="https://en.wikipedia.org/wiki/Beriberi" target="_blank" rel="noopener">beriberi</a>. However, when it comes to cancers and other diseases that take years to develop, linear models are inadequate.

An accurate model to predict human health based on diet would be based on thousands to millions of variables, and would consider many non-linear relationships. It is fairly safe to assume that there is no magic bullet that simply explains how diet affects our health, and no <a href="https://en.wikipedia.org/wiki/Superfood" target="_blank" rel="noopener">superfood</a> is going to save us from the complexity of our nutritional needs. It is likely that even if we had such a model, it would not be completely accurate. All models are wrong, but some models are useful. For example, the vitamin C versus scurvy model is very useful, but it is often wrong when it comes to predicting overall health. Predictions made by useful complex models can be very hard to reason about and explain, but it doesn't mean we shouldn't use them.

### The ongoing quest for sellable complex models

All of the above should be pretty obvious to any modern data scientist. The culture of preferring complex models with high predictive accuracy to simplistic models with questionable predictive power is now prevalent (see <a href="http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726" target="_blank" rel="noopener">Leo Breiman's 2001 paper for a discussion of these two cultures of statistical modelling</a>). This is illustrated by the focus of many <a href="https://www.kaggle.com/" target="_blank" rel="noopener">Kaggle</a> competitions on producing accurate models and the recent successes of <a href="https://en.wikipedia.org/wiki/Deep_learning#Image_recognition" target="_blank" rel="noopener">deep learning for computer vision</a>. Especially with deep learning for vision, no one expects a handful of variables (pixels) to be predictive, so traditional explanations of variable importance are useless. This does lead to a general suspicion of such models, as they are too complex for us to reason about or fully explain. However, it is very hard to argue with the empirical success of accurate modelling techniques.

Nonetheless, many data scientists still work in environments that require simple explanations. This may lead some data scientists to settle for simple models that are easier to sell. In my opinion, it is better to make up a simple explanation for an accurate complex model than settle for a simple model that doesn't really work. That being said, some situations do call for simple or inflexible models due to a lack of data or the need to enforce strong prior assumptions. In Albert Einstein's words, "it can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience". Make things as simple as possible, but not simpler, and always consider the interests of people who try to sell you simplistic (or unnecessarily complex) explanations.
