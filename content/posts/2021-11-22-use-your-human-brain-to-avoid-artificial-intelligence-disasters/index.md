---
title: Use your human brain to avoid artificial intelligence disasters
author: Yanir Seroussi
type: post
date: 2021-11-22T03:45:00+00:00
url: /2021/11/22/use-your-human-brain-to-avoid-artificial-intelligence-disasters/
cover:
  image: think-about-your-modelling-context.png
  alt: If you don't think about your modelling context, you're gonna have a bad time.
  responsiveImages: false
summary: Overview of a talk I gave at a deep learning course, focusing on AI ethics as the need for humans to think on the context and consequences of applying AI.
tags:
  - artificial intelligence
  - data science
  - deep learning
  - ethics
  - fast.ai
  - machine learning

---

Earlier this year, I helped mentor a local edition of [fast.ai's _Practical Deep Learning for Coders_](https://course.fast.ai/). Each mentor gave a brief talk on a given week's subject, adding to the material covered in the recorded lectures. My talk (embedded below) supplemented [the data ethics lesson](https://www.youtube.com/watch?v=krIVOb23EH8). While the mere mention of the word _ethics_ can elicit instant yawns from some people, the main message for me is that **it's critical for humans to think about the context and consequences of deploying machine learning models**.

Unfortunately, this message sometimes gets muddied amidst the outrage about specific applications that conflict with the values of the outraged parties. But I believe it's possible to transcend narrow moralities and agree that better outcomes arise when humans think deeply about their deep learning systems. Or to put it more bluntly, **any fool can build machine learning models, but it takes thoughtful humans to build _good_ artificial intelligence applications.**

{{< figure src="dog-philosophy.png" alt="Dog Philosophy by Three Panel Soul" caption="Source: <a href=\"http://www.threepanelsoul.com/comic/dog-philosophy\" target=\"_blank\" rel=\"noopener\">Three Panel Soul - dog philosophy</a>" >}}

Of course, what constitutes _good_ is an open question, which I touched on in the talk. Other key points include:

  * The modelling context is much broader than any machine learning model. Considering context is where human brains shine.
  * Thoughtlessness can have a negative impact on society and on your career.
  * Moral values vary across time, space, cultures, and individuals, e.g., along [five moral foundations](https://moralfoundations.org/).
  * Any data scientist, machine learning engineer, or modern human should develop their critical thinking skills. [The Calling Bullshit course](https://www.callingbullshit.org/) from the University of Washington is a great starting point &ndash; essentially Data Literacy 101.
  * Bullshit is easier to detect than call. Deciding on a level of bullshit calling is like tuning a model's learning rate.

A good chunk of the talk was spent on [the case study on criminal machine learning from the Calling Bullshit website](https://www.callingbullshit.org/case_studies/case_study_criminal_machine_learning.html). I was pleased with the level of engagement on this segment, especially since a lockdown forced us to deliver the class online at short notice. You can watch the full talk below (my part ends after 24 minutes), view the slides [here](https://docs.google.com/presentation/d/1vi0YKxmevanE8zA6u2ZuA835boSXKMa-Su8LZmLA7EA/edit), and check out [supplementary materials from all mentors on GitHub](https://github.com/michaeltremeer/queensland-ai-fastai-course-resources).

<p>
  {{< youtube id="P1ebqJ4ZIEI" >}}
</p>
