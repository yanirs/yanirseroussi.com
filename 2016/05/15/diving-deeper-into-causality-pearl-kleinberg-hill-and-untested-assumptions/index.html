<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions | Yanir Seroussi | Data & AI for Startup Impact</title>
<meta name=keywords content="causal inference,data science,insights,predictive modelling"><meta name=description content="Discussing the need for untested assumptions and temporality in causal inference. Mostly based on Samantha Kleinberg&rsquo;s Causality, Probability, and Time."><meta name=author content="Yanir Seroussi"><link rel=canonical href=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/><meta name=google-site-verification content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU"><link crossorigin=anonymous href=/assets/css/stylesheet.aae7b8d6eabaa881f37800d50b4d8604e83f1b3aa14069aaa7e0db30a27839d7.css integrity="sha256-que41uq6qIHzeADVC02GBOg/GzqhQGmqp+DbMKJ4Odc=" rel="preload stylesheet" as=style><link rel=icon href=https://yanirseroussi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yanirseroussi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yanirseroussi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://yanirseroussi.com/apple-touch-icon.png><link rel=mask-icon href=https://yanirseroussi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions"><meta property="og:description" content="Discussing the need for untested assumptions and temporality in causal inference. Mostly based on Samantha Kleinberg&rsquo;s Causality, Probability, and Time."><meta property="og:type" content="article"><meta property="og:url" content="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/"><meta property="og:image" content="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-05-14T19:57:03+00:00"><meta property="article:modified_time" content="2024-01-16T09:56:03+10:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving.jpg"><meta name=twitter:title content="Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions"><meta name=twitter:description content="Discussing the need for untested assumptions and temporality in causal inference. Mostly based on Samantha Kleinberg&rsquo;s Causality, Probability, and Time."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Browse Posts","item":"https://yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions","item":"https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions","name":"Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions","description":"Discussing the need for untested assumptions and temporality in causal inference. Mostly based on Samantha Kleinberg\u0026rsquo;s Causality, Probability, and Time.","keywords":["causal inference","data science","insights","predictive modelling"],"articleBody":"Background: I have previously written about the need for real insights that address the why behind events, not only the what and how. This was followed by a fairly popular post on causality, which was heavily influenced by Samantha Kleinberg's book Why: A Guide to Finding and Using Causes. This post continues my exploration of the field, and is primarily based on Kleinberg's previous book: Causality, Probability, and Time.\nThe study of causality and causal inference is central to science in general and data science in particular. Being able to distinguish between correlation and causation is key to designing effective interventions in business, public policy, medicine, and many other fields. There are quite a few approaches to inferring causal relationships from data. In this post, I discuss some aspects of Judea Pearl’s graphical modelling approach, and how its limitations are addressed in recent work by Samantha Kleinberg. I then finish with a brief survey of the Bradford Hill criteria and their applicability to a key limitation of all causal inference methods: The need for untested assumptions.\nJudea Pearl Overcoming my Pearl bias First, I must disclose that I have a personal bias in favour of Pearl’s work. While I’ve never met him, Pearl is my academic grandfather – he was the PhD advisor of my main PhD supervisor (Ingrid Zukerman). My first serious exposure to his work was through a Sydney reading group, where we discussed parts of Pearl’s approach to causal inference. Recently, I refreshed my knowledge of Pearl causality by reading Causal inference in statistics: An overview. I am by no means an expert in Pearl’s huge body of work, but I think I understand enough of it to write something of use.\nPearl’s theory of causality employs Bayesian networks to represent causal structures. These are directed acyclic graphs, where each vertex represents a variable, and an edge from X to Y implies that X causes Y. Pearl also introduces the do(X) operator, which simulates interventions by removing all the causes of X, setting it to a constant. There is much more to this theory, but two of its main contributions are the formalisation of causal concepts that are often given only a verbal treatment, and the explicit encoding of causal assumptions. These assumptions must be made by the modeller based on background knowledge, and are encoded in the graph’s structure – a missing edge between two vertices indicates that there is no direct causal relationship between the two variables.\nMy main issue with Pearl’s treatment of causality is that he doesn’t explicitly handle time. While time can be encoded into Pearl’s models (e.g., via dynamic Bayesian networks), there is nothing that prevents creation of models where the future causes changes in the past. A closely-related issue is that Pearl’s causal models must be directed acyclic graphs, making it hard to model feedback loops. For example, Pearl says that “mud does not cause rain”, but this isn’t true – water from mud evaporates, causing rain (which causes mud). What’s true is that “mud now doesn’t cause rain now” or something along these lines, which is something that must be accounted for by adding temporal information to the models.\nNonetheless, Pearl’s theory is an important step forward in the study of causality. In his words, “in the bulk of the statistical literature before 2000, causal claims rarely appear in the mathematics. They surface only in the verbal interpretation that investigators occasionally attach to certain associations, and in the verbal description with which investigators justify assumptions.” The importance of formal causal analysis cannot be overstated, as it underlies many decisions that affect our lives. However, it seems to me like there’s still plenty of work to be done before causal analysis becomes as established as other statistical tools.\nSamantha Kleinberg Kleinberg: Addressing gaps in Pearl’s work I recently finished reading Samantha Kleinberg’s Causality, Probability, and Time. Kleinberg dedicates a good portion of the book to presenting the history of causality and discussing its many definitions. As hinted by the book’s title, Kleinberg believes that one cannot discuss causality without considering time. In her words: “One of the most critical pieces of information about causality, though – the time it takes for the cause to produce its effect – has been largely ignored by both philosophical theories and computational methods. If we do not know when the effect will occur, we have little hope of being able to act successfully using the causal relationship.” Following this assertion, Kleinberg presents a new approach to causal inference that is based on probabilistic computation tree logic (PCTL). With PCTL, one can concisely express probabilistic temporal statements. For example, if we observe a potential cause c occurring at time t, and a possible effect e occurring at time t’, we can use PCTL to state the hypothesis that in general, after c becomes true, it takes between one and |t’ – t| time units for e to become true with probability at least p, i.e., c leads to e:\nIt is obvious why PCTL may be a better fit than Bayesian networks for expressing causal statements. For example, with a Bayesian network, we can easily express the statement that smoking causes lung cancer with probability 0.3, but this isn’t that useful, as it doesn’t tell us how long it’ll take for cancer to develop. With PCTL, we can state that smoking causes lung cancer in 5-30 years with probability at least 0.3. This matches our knowledge that cancer doesn’t develop immediately – one cigarette won’t kill you.\nOne of the key concepts introduced by Kleinberg is that of causal significance. Calculating the causal significance of a cause c to an effect e relies on first identifying the set X of potential (or prima facie) causes of e. The set X contains all discrete variables x such that E[e|x]≠E[e] and x occurs earlier than e. Given the set X, the causal significance of c to e is the mean of E[e|c∧x] – E[e|¬c∧x] for all x≠c. The intuition is that if a cause c is significant, its causal significance value will be high when other potential causes are held fixed. For example, if c is heavy smoking and e is severity of lung cancer (with e=0 meaning no cancer), the expected value of e given c is likely to be higher than the expected value of e given ¬c, when conditioned on any other potential cause. Once causal significance has been measured, we can separate significant causes from insignificant causes by setting a threshold on causal significance values (this threshold can be inferred from the data). Significant causes are considered to be genuine if the data is stationary and the common causes of all pairs of variables have been included, which is a very strong condition that may be hard to fulfil in realistic scenarios. However, causal significance is an evolving concept – last year, Huang and Kleinberg introduced a new definition of causal significance that can be inferred faster and yield more accurate results. My general feeling is that this line of research will continue to yield many interesting and useful results in coming years.\nKleinberg’s work is not without its limitations. In addition to the assumptions that causal relationships are stationary and the requirement to identify all potential causes, the recently-introduced definition of causal significance also requires the relationships to be linear and additive (though this limitation may be relaxed in future work). Another issue is that most of the evaluation in the studies I’ve read was done on synthetic datasets. While there are some results on real-life health and finance data, I find it hard to judge the practicality of utilising Kleinberg’s methods without applying them to problems that I’m more familiar with. Finally, as with other work in the field of causal inference, we need to have some degree of belief in untested assumptions to reach useful conclusions. In Kleinberg’s words:\nThus, a just so cause is genuine in the case where all of the outlined assumptions hold (namely that all common causes are included, the structure is representative of the system and, when data is used, a formula satisfied by the data will be satisfied by the structure). Our belief in whether a cause is genuine, in the case where it is not certain that the assumptions hold, should be proportional to how much we believe that the assumptions are true.\nAustin Bradford Hill Hill: Testing untested assumptions To the best of my knowledge, all causal inference methods rely on untested assumptions. Specifically, we can never include all the variables in the universe in our models. Therefore, any conclusions drawn are reliant on deciding what, when, and how to measure potential causes and effects. Another issue is that no matter how good and believable our modelling is, we cannot use causal inference to convince unreasonable people. For example, some people may cite divine intervention as an unmeasurable cause of anything and everything. In addition, people with certain commercial interests often try to raise doubt about well-established causal mechanisms by making unreasonable claims for evidence of various hidden factors. For example, tobacco companies used to claim that both smoking and lung cancer were caused by a common hidden factor, making the link between smoking and lung cancer a mere association.\nAssuming that we are dealing with reasonable people, there’s still the question of where we should get our untested assumptions from. This question is fairly old, and has been partly answered in 1965 by Austin Bradford Hill, with nine criteria that he recommended should be considered before calling an association causal:\nStrength: How strong is the association? For example, lung cancer deaths of heavy smokers are 20-30 times greater than those of non-smokers. Consistency: Has the association been repeatedly observed in various circumstances? For example, many different populations have exhibited an association between smoking rates and cancer. Specificity: Can we pin down specific instances of the effect to specific instances of the cause? Hill sees this as a nice-to-have condition rather than a must-have – cases with multiple possible causes may not fulfil the specificity requirement. Temporality: Do we know that c leads to e or are we observing them together? This is a condition that isn’t always easy to fulfil, especially when dealing with feedback loops and slow processes. Biological gradient: Hill’s focus was on medicine, and this condition refers to the association exhibiting some dose-response curve. This can be generalised to other fields, as we can expect some regularity in the effect if it is a function of the cause (though it doesn’t have to be a linear function). Plausibility: Do we know of a mechanism that can explain how the cause brings about the effect? Coherence: Does the association conflict with our current knowledge? Even if it does, it isn’t enough to rule out causality, as our current knowledge may be incomplete or wrong. Experiment: If possible, running controlled experiments may yield very powerful evidence in favour of causation. Analogy: Do we know of any similar cause-and-effect relationships? Hill summarises the list of criteria (or viewpoints) with the following statements.\nHere then are nine different viewpoints from all of which we should study association before we cry causation. What I do not believe – and this has been suggested – is that we can usefully lay down some hard-and-fast rules of evidence that must be obeyed before we accept cause and effect. None of my nine viewpoints can bring indisputable evidence for or against the cause-and-effect hypothesis and none can be required as a sine qua non. What they can do, with greater or less strength, is to help us to make up our minds on the fundamental question – is there any other way of explaining the set of facts before us, is there any other answer equally, or more, likely than cause and effect?\nNo formal tests of significance can answer those questions. Such tests can, and should, remind us of the effects that the play of chance can create, and they will instruct us in the likely magnitude of those effects. Beyond that they contribute nothing to the ‘proof’ of our hypothesis.\nHill then goes on to criticise the increased focus on statistical significance as a condition for accepting scientific papers for publication. Remembering that this was over 50 years ago, it is a bit worrying that it has taken so long for the statistical community to formally acknowledge the fact that statistical significance does not imply scientific importance, or constitutes enough evidence to support a causal hypothesis.\nClosing thoughts This post has only scratched the surface of the vast field of study of causality. At this point, I feel like I’ve read quite a bit, and it is time to apply what I learned to real problems. I encounter questions of causality in my everyday work, but haven’t fully applied formal causal inference to any problem yet. My view is that everyone needs to at least be aware of the need to consider causality, and of what it’d take to truly prove causal impact. A large proportion of what many people need in practice may be addressed by Hill’s criteria, rather than by formal methods for causal analysis. Nonetheless, I will report back when I get a chance to apply formal causal inference to real datasets. Stay tuned!\n","wordCount":"2223","inLanguage":"en","image":"https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving.jpg","datePublished":"2016-05-14T19:57:03Z","dateModified":"2024-01-16T09:56:03+10:00","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data \u0026 AI for Startup Impact","logo":{"@type":"ImageObject","url":"https://yanirseroussi.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data & AI for Startup Impact (Alt + H)">Yanir Seroussi | Data & AI for Startup Impact</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><button id=menu-trigger aria-haspopup=menu aria-label="Menu Button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><ul class="menu hidden"><li><a href=https://yanirseroussi.com/about/ title=About><span>About</span></a></li><li><a href=https://yanirseroussi.com/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://yanirseroussi.com/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://yanirseroussi.com/consult/ title=Consulting><span>Consulting</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions</h1><div class=post-meta><span title='2016-05-14 19:57:03 +0000 UTC'>May 14, 2016</span></div></header><figure class=entry-cover><img loading=eager srcset="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving_hub5d72e3c45cdff9da93ca2e12cce16a2_673766_360x0_resize_q75_box.jpg 360w ,https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving_hub5d72e3c45cdff9da93ca2e12cce16a2_673766_480x0_resize_q75_box.jpg 480w ,https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving_hub5d72e3c45cdff9da93ca2e12cce16a2_673766_720x0_resize_q75_box.jpg 720w ,https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving_hub5d72e3c45cdff9da93ca2e12cce16a2_673766_1080x0_resize_q75_box.jpg 1080w ,https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving_hub5d72e3c45cdff9da93ca2e12cce16a2_673766_1500x0_resize_q75_box.jpg 1500w ,https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving.jpg 1920w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/freediving.jpg alt width=1920 height=672></figure><div class=post-content><p class=intro-note>Background: I have previously written about <a href=https://yanirseroussi.com/2015/12/08/this-holiday-season-give-me-real-insights/>the need for real insights that address the why behind events, not only the what and how</a>. This was followed by a <a href=https://yanirseroussi.com/2016/02/14/why-you-should-stop-worrying-about-deep-learning-and-deepen-your-understanding-of-causality-instead/>fairly popular post on causality</a>, which was heavily influenced by Samantha Kleinberg's book <a href=http://www.skleinberg.org/why/ target=_blank rel=noopener>Why: A Guide to Finding and Using Causes</a>. This post continues my exploration of the field, and is primarily based on Kleinberg's previous book: <a href=http://www.skleinberg.org/causality_book/index.html target=_blank rel=noopener>Causality, Probability, and Time</a>.</p><p>The study of causality and causal inference is central to science in general and data science in particular. Being able to distinguish between correlation and causation is key to designing effective interventions in business, public policy, medicine, and many other fields. There are quite a few approaches to inferring causal relationships from data. In this post, I discuss some aspects of <a href=https://en.wikipedia.org/wiki/Judea_Pearl target=_blank rel=noopener>Judea Pearl&rsquo;s</a> graphical modelling approach, and how its limitations are addressed in recent work by <a href=http://www.skleinberg.org/ target=_blank rel=noopener>Samantha Kleinberg</a>. I then finish with a brief survey of the <a href=https://en.wikipedia.org/wiki/Bradford_Hill_criteria target=_blank rel=noopener>Bradford Hill criteria</a> and their applicability to a key limitation of all causal inference methods: The need for untested assumptions.</p><h2 id=hahahugoshortcode42s0hbhb-overcoming-my-pearl-bias><figure class=float-right><a href=judea-pearl.jpg target=_blank rel=noopener><img sizes="(min-width: 768px) 435px,
100vw" srcset="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/judea-pearl_hu9a8d9dce36ef378faf19e0843274044e_79154_360x0_resize_q75_box.jpg 360w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/judea-pearl.jpg 435w," src=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/judea-pearl.jpg alt="Judea Pearl" width=150 loading=lazy></a><figcaption><p>Judea Pearl</p></figcaption></figure>Overcoming my Pearl bias</h2><p>First, I must disclose that I have a personal bias in favour of Pearl&rsquo;s work. While I&rsquo;ve never met him, Pearl is my academic grandfather – he was the PhD advisor of my main PhD supervisor (Ingrid Zukerman). My first serious exposure to his work was through a Sydney reading group, where we discussed parts of Pearl&rsquo;s approach to causal inference. Recently, I refreshed my knowledge of Pearl causality by reading <a href=http://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf target=_blank rel=noopener>Causal inference in statistics: An overview</a>. I am by no means an expert in Pearl&rsquo;s huge body of work, but I think I understand enough of it to write something of use.</p><p>Pearl&rsquo;s theory of causality employs Bayesian networks to represent causal structures. These are directed acyclic graphs, where each vertex represents a variable, and an edge from X to Y implies that X causes Y. Pearl also introduces the <code>do(X)</code> operator, which simulates interventions by removing all the causes of X, setting it to a constant. There is much more to this theory, but two of its main contributions are the formalisation of causal concepts that are often given only a verbal treatment, and the explicit encoding of causal assumptions. These assumptions must be made by the modeller based on background knowledge, and are encoded in the graph&rsquo;s structure – a missing edge between two vertices indicates that there is no direct causal relationship between the two variables.</p><p>My main issue with Pearl&rsquo;s treatment of causality is that he doesn&rsquo;t explicitly handle time. While time can be encoded into Pearl&rsquo;s models (e.g., via dynamic Bayesian networks), there is nothing that prevents creation of models where the future causes changes in the past. A closely-related issue is that Pearl&rsquo;s causal models must be directed <em>acyclic</em> graphs, making it hard to model feedback loops. For example, Pearl says that &ldquo;mud does not cause rain&rdquo;, but this isn&rsquo;t true – water from mud evaporates, causing rain (which causes mud). What&rsquo;s true is that &ldquo;mud now doesn&rsquo;t cause rain now&rdquo; or something along these lines, which is something that must be accounted for by adding temporal information to the models.</p><p>Nonetheless, Pearl&rsquo;s theory is an important step forward in the study of causality. In his words, &ldquo;<em>in the bulk of the statistical literature before 2000, causal claims rarely appear in the mathematics. They surface only in the verbal interpretation that investigators occasionally attach to certain associations, and in the verbal description with which investigators justify assumptions.</em>&rdquo; The importance of formal causal analysis cannot be overstated, as it underlies many decisions that affect our lives. However, it seems to me like there&rsquo;s still plenty of work to be done before causal analysis becomes as established as other statistical tools.</p><h2 id=hahahugoshortcode42s1hbhb-kleinberg-addressing-gaps-in-pearls-work><figure class=float-right><a href=samantha-kleinberg.jpg target=_blank rel=noopener><img sizes="(min-width: 768px) 586px,
100vw" srcset="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/samantha-kleinberg_hu3d03a01dcc18bc5be0e67db3d8d209a6_52017_360x0_resize_q75_box.jpg 360w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/samantha-kleinberg_hu3d03a01dcc18bc5be0e67db3d8d209a6_52017_480x0_resize_q75_box.jpg 480w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/samantha-kleinberg.jpg 586w," src=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/samantha-kleinberg.jpg alt="Samantha Kleinberg" width=150 loading=lazy></a><figcaption><p>Samantha Kleinberg</p></figcaption></figure>Kleinberg: Addressing gaps in Pearl&rsquo;s work</h2><p>I recently finished reading Samantha Kleinberg&rsquo;s <a href=http://www.skleinberg.org/causality_book/index.html target=_blank rel=noopener>Causality, Probability, and Time</a>. Kleinberg dedicates a good portion of the book to presenting the history of causality and discussing its many definitions. As hinted by the book&rsquo;s title, Kleinberg believes that one cannot discuss causality without considering time. In her words: &ldquo;<em>One of the most critical pieces of information about causality, though – the time it takes for the cause to produce its effect – has been largely ignored by both philosophical theories and computational methods. If we do not know when the effect will occur, we have little hope of being able to act successfully using the causal relationship.</em>&rdquo; Following this assertion, Kleinberg presents a new approach to causal inference that is based on <a href=https://en.wikipedia.org/wiki/Probabilistic_CTL target=_blank rel=noopener>probabilistic computation tree logic (PCTL)</a>. With PCTL, one can concisely express probabilistic temporal statements. For example, if we observe a potential cause <em>c</em> occurring at time <em>t</em>, and a possible effect <em>e</em> occurring at time <em>t&rsquo;</em>, we can use PCTL to state the hypothesis that in general, after <em>c</em> becomes true, it takes between one and <em>|t&rsquo; – t|</em> time units for <em>e</em> to become true with probability at least <em>p</em>, i.e., <em>c</em> leads to <em>e</em>:</p><figure><a href=pctl-cause-leads-to-effect.png target=_blank rel=noopener><img sizes="(min-width: 768px) 175px,
100vw" srcset="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/pctl-cause-leads-to-effect.png 175w," src=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/pctl-cause-leads-to-effect.png alt="PCTL cause leads to effect" loading=lazy></a></figure><p>It is obvious why PCTL may be a better fit than Bayesian networks for expressing causal statements. For example, with a Bayesian network, we can easily express the statement that smoking causes lung cancer with probability 0.3, but this isn&rsquo;t that useful, as it doesn&rsquo;t tell us how long it&rsquo;ll take for cancer to develop. With PCTL, we can state that smoking causes lung cancer in 5-30 years with probability at least 0.3. This matches our knowledge that cancer doesn&rsquo;t develop immediately – one cigarette won&rsquo;t kill you.</p><p>One of the key concepts introduced by Kleinberg is that of <strong>causal significance</strong>. Calculating the causal significance of a cause <em>c</em> to an effect <em>e</em> relies on first identifying the set <em>X</em> of <em>potential</em> (or <em>prima facie</em>) causes of <em>e</em>. The set <em>X</em> contains all discrete variables <em>x</em> such that <em>E[e|x]≠E[e]</em> and <em>x</em> occurs earlier than <em>e</em>. Given the set <em>X</em>, the causal significance of <em>c</em> to <em>e</em> is the mean of <em>E[e|c∧x] – E[e|¬c∧x]</em> for all <em>x≠c</em>. The intuition is that if a cause <em>c</em> is significant, its causal significance value will be high when other potential causes are held fixed. For example, if <em>c</em> is heavy smoking and <em>e</em> is severity of lung cancer (with <em>e=0</em> meaning no cancer), the expected value of <em>e</em> given <em>c</em> is likely to be higher than the expected value of <em>e</em> given <em>¬c</em>, when conditioned on any other potential cause. Once causal significance has been measured, we can separate significant causes from insignificant causes by setting a threshold on causal significance values (this threshold can be inferred from the data). Significant causes are considered to be genuine if the data is stationary and the common causes of all pairs of variables have been included, which is a very strong condition that may be hard to fulfil in realistic scenarios. However, causal significance is an evolving concept – last year, Huang and Kleinberg <a href=http://www.skleinberg.org/papers/huang_flairs15.pdf target=_blank rel=noopener>introduced a new definition of causal significance that can be inferred faster and yield more accurate results</a>. My general feeling is that this line of research will continue to yield many interesting and useful results in coming years.</p><p>Kleinberg&rsquo;s work is not without its limitations. In addition to the assumptions that causal relationships are stationary and the requirement to identify all potential causes, the recently-introduced definition of causal significance also requires the relationships to be linear and additive (though this limitation may be relaxed in future work). Another issue is that most of the evaluation in the studies I&rsquo;ve read was done on synthetic datasets. While there are some results on real-life health and finance data, I find it hard to judge the practicality of utilising Kleinberg&rsquo;s methods without applying them to problems that I&rsquo;m more familiar with. Finally, as with other work in the field of causal inference, we need to have some degree of belief in untested assumptions to reach useful conclusions. In Kleinberg&rsquo;s words:</p><blockquote><p>Thus, a just so cause <em>is</em> genuine in the case where all of the outlined assumptions hold (namely that all common causes are included, the structure is representative of the system and, when data is used, a formula satisfied by the data will be satisfied by the structure). Our <em>belief</em> in whether a cause is genuine, in the case where it is not certain that the assumptions hold, should be proportional to how much we believe that the assumptions are true.</p></blockquote><h2 id=hahahugoshortcode42s3hbhb-hill-testing-untested-assumptions><figure class=float-right><a href=austin-bradford-hill.jpg target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill_huf628c6f0f9f49f20b40d6213fb032a87_561648_360x0_resize_q75_box.jpg 360w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill_huf628c6f0f9f49f20b40d6213fb032a87_561648_480x0_resize_q75_box.jpg 480w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill_huf628c6f0f9f49f20b40d6213fb032a87_561648_720x0_resize_q75_box.jpg 720w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill_huf628c6f0f9f49f20b40d6213fb032a87_561648_1080x0_resize_q75_box.jpg 1080w,
https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill.jpg 1131w," src=https://yanirseroussi.com/2016/05/15/diving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions/austin-bradford-hill_huf628c6f0f9f49f20b40d6213fb032a87_561648_800x0_resize_q75_box.jpg alt="Austin Bradford Hill" width=150 loading=lazy></a><figcaption><p>Austin Bradford Hill</p></figcaption></figure>Hill: Testing untested assumptions</h2><p>To the best of my knowledge, all causal inference methods rely on untested assumptions. Specifically, we can never include all the variables in the universe in our models. Therefore, any conclusions drawn are reliant on deciding what, when, and how to measure potential causes and effects. Another issue is that no matter how good and believable our modelling is, we cannot use causal inference to convince unreasonable people. For example, some people may cite divine intervention as an unmeasurable cause of anything and everything. In addition, <a href=https://en.wikipedia.org/wiki/Merchants_of_Doubt target=_blank rel=noopener>people with certain commercial interests</a> often try to raise doubt about well-established causal mechanisms by making unreasonable claims for evidence of various hidden factors. For example, tobacco companies used to claim that both smoking and lung cancer were caused by a common hidden factor, making the link between smoking and lung cancer a mere association.</p><p>Assuming that we are dealing with reasonable people, there&rsquo;s still the question of where we should get our untested assumptions from. This question is fairly old, and has been <a href=https://www.edwardtufte.com/tufte/hill target=_blank rel=noopener>partly answered in 1965 by Austin Bradford Hill</a>, with nine criteria that he recommended should be considered before calling an association causal:</p><ol><li><em>Strength</em>: How strong is the association? For example, lung cancer deaths of heavy smokers are 20-30 times greater than those of non-smokers.</li><li><em>Consistency</em>: Has the association been repeatedly observed in various circumstances? For example, many different populations have exhibited an association between smoking rates and cancer.</li><li><em>Specificity</em>: Can we pin down specific instances of the effect to specific instances of the cause? Hill sees this as a nice-to-have condition rather than a must-have – cases with multiple possible causes may not fulfil the specificity requirement.</li><li><em>Temporality</em>: Do we know that <em>c</em> leads to <em>e</em> or are we observing them together? This is a condition that isn&rsquo;t always easy to fulfil, especially when dealing with feedback loops and slow processes.</li><li><em>Biological gradient</em>: Hill&rsquo;s focus was on medicine, and this condition refers to the association exhibiting some dose-response curve. This can be generalised to other fields, as we can expect some regularity in the effect if it is a function of the cause (though it doesn&rsquo;t have to be a linear function).</li><li><em>Plausibility</em>: Do we know of a mechanism that can explain how the cause brings about the effect?</li><li><em>Coherence</em>: Does the association conflict with our current knowledge? Even if it does, it isn&rsquo;t enough to rule out causality, as our current knowledge may be incomplete or wrong.</li><li><em>Experiment</em>: If possible, running controlled experiments may yield very powerful evidence in favour of causation.</li><li><em>Analogy</em>: Do we know of any similar cause-and-effect relationships?</li></ol><p>Hill summarises the list of criteria (or viewpoints) with the following statements.</p><blockquote><p>Here then are nine different viewpoints from all of which we should study association before we cry causation. What I do not believe – and this has been suggested – is that we can usefully lay down some hard-and-fast rules of evidence that <em>must</em> be obeyed before we accept cause and effect. None of my nine viewpoints can bring indisputable evidence for or against the cause-and-effect hypothesis and none can be required as a <em>sine qua non</em>. What they can do, with greater or less strength, is to help us to make up our minds on the fundamental question – is there any other way of explaining the set of facts before us, is there any other answer equally, or more, likely than cause and effect?</p><p>No formal tests of significance can answer those questions. Such tests can, and should, remind us of the effects that the play of chance can create, and they will instruct us in the likely magnitude of those effects. Beyond that they contribute nothing to the ‘proof&rsquo; of our hypothesis.</p></blockquote><p>Hill then goes on to criticise the increased focus on statistical significance as a condition for accepting scientific papers for publication. Remembering that this was over 50 years ago, it is a bit worrying that it has taken so long for the statistical community to <a href=https://www.amstat.org/newsroom/pressreleases/P-ValueStatement.pdf target=_blank rel=noopener>formally acknowledge the fact that statistical significance does not imply scientific importance, or constitutes enough evidence to support a causal hypothesis</a>.</p><h2 id=closing-thoughts>Closing thoughts<a hidden class=anchor aria-hidden=true href=#closing-thoughts>#</a></h2><p>This post has only scratched the surface of the vast field of study of causality. At this point, I feel like I&rsquo;ve read quite a bit, and it is time to apply what I learned to real problems. I encounter questions of causality in my everyday work, but haven&rsquo;t fully applied formal causal inference to any problem yet. My view is that everyone needs to at least be aware of the need to consider causality, and of what it&rsquo;d take to truly prove causal impact. A large proportion of what many people need in practice may be addressed by Hill&rsquo;s criteria, rather than by formal methods for causal analysis. Nonetheless, I will report back when I get a chance to apply formal causal inference to real datasets. Stay tuned!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yanirseroussi.com/tags/causal-inference/>Causal Inference</a></li><li><a href=https://yanirseroussi.com/tags/data-science/>Data Science</a></li><li><a href=https://yanirseroussi.com/tags/insights/>Insights</a></li><li><a href=https://yanirseroussi.com/tags/predictive-modelling/>Predictive Modelling</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on x" href="https://x.com/intent/tweet/?text=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f&amp;hashtags=causalinference%2cdatascience%2cinsights%2cpredictivemodelling"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f&amp;title=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions&amp;summary=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions&amp;source=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f&title=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on whatsapp" href="https://api.whatsapp.com/send?text=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions%20-%20https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on telegram" href="https://telegram.me/share/url?text=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Diving deeper into causality: Pearl, Kleinberg, Hill, and untested assumptions on ycombinator" href="https://news.ycombinator.com/submitlink?t=Diving%20deeper%20into%20causality%3a%20Pearl%2c%20Kleinberg%2c%20Hill%2c%20and%20untested%20assumptions&u=https%3a%2f%2fyanirseroussi.com%2f2016%2f05%2f15%2fdiving-deeper-into-causality-pearl-kleinberg-hill-and-untested-assumptions%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><a href=/contact/#mailing-list-email target=_blank aria-label="subscribe to mailing list" class=mailing-list-link id=mailing-list-link>Subscribe
</a><script>const mailingListButton=document.getElementById("mailing-list-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mailingListButton.style.visibility="visible",mailingListButton.style.opacity="1"):(mailingListButton.style.visibility="hidden",mailingListButton.style.opacity="0")}</script><div class=mailing-list-container><script src=https://f.convertkit.com/ckjs/ck.5.js></script><form class="mailing-list seva-form formkit-form" action=https://app.convertkit.com/forms/6549537/subscriptions method=post data-sv-form=6549537 data-uid=9157759fce data-format=inline data-version=5 data-options='{"settings":{"after_subscribe":{"action":"message","redirect_url":"","success_message":"Success! Now check your email to confirm your subscription."},"recaptcha":{"enabled":false},"return_visitor":{"action":"show","custom_content":""}},"version":"5"}'><div data-style=clean><ul class="formkit-alert formkit-alert-error" data-element=errors data-group=alert></ul><div data-element=fields data-stacked=false><label for=mailing-list-email>Get weekly posts in your mailbox</label>
<input id=mailing-list-email name=email_address aria-label="Email address" placeholder="Email address" required type=email>
<button data-element=submit>Subscribe</button></div></div></form><div class=footer>Join hundreds of subscribers. No spam or AI-generated slop. Unsubscribe any time.</div></div><section class=comment-section><p class="post-content contact-cta">Public comments are closed, but I love hearing from readers. Feel free to
<a href=/contact/ target=_blank>contact me</a> with your thoughts.</p><div class=comment-level-0 id=comment-1198><div class=comment-header><a href=#comment-1198><img class=comment-avatar src="https://www.gravatar.com/avatar/3a974c8365594f5920b6b20ac70c9da9?s=50"><p class=comment-info><strong>James Savage</strong><br><small>2016-05-15 21:49:50</small></p></a></div><div class="comment-body post-content"><p>Interesting point on the causal significance. How does this work when you have confounders in x? I&rsquo;d have thought that x must contain the set of prima facie causes <em>for which we have true exogenous variation</em>.</p><p>Also, how does it work when you have bad controls in x (where x includes post-treatment causes that are plausibly varied by c)?</p></div></div><div class=comment-level-1 id=comment-1200><div class=comment-header><a href=#comment-1200><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2016-05-16 21:29:51</small></p></a></div><div class="comment-body post-content"><p>Good questions :)</p><p>To be honest, I&rsquo;m not completely sure it works in all these cases, as there is always a need for interpretation to decide whether the identified causes are genuine. I tried playing a bit with the toy data from <a href=http://bayes.cs.ucla.edu/R264.pdf target=_blank rel=nofollow>Pearl&rsquo;s report on Simpson&rsquo;s Paradox</a>, but the results are not entirely convincing. However, I&rsquo;m also not fully convinced that Pearl&rsquo;s solution fully resolves Simpson&rsquo;s Paradox, and Kleinberg does go through a few scenarios where her approach doesn&rsquo;t work in her book, so I&rsquo;d say that there are still quite a few open problems in the area.</p><p>Post-treatment causes are partly addressed by the definition in <a href=http://www.skleinberg.org/papers/huang_flairs15.pdf target=_blank rel=nofollow>Huang and Kleinberg (2015)</a>, where significance is weighted by the number of timepoints where <i>e</i> follows <i>c</i>. Again, that definition doesn&rsquo;t handle all cases, but I think it&rsquo;s an interesting line of research. I would definitely like to see their results reproduced by other researchers and expanded to other datasets, though.</p></div></div><div class=comment-level-0 id=comment-1201><div class=comment-header><a href=#comment-1201><img class=comment-avatar src="https://www.gravatar.com/avatar/6c7d9b2bba16f79b1900c5098386c383?s=50"><p class=comment-info><strong>Jose Magana</strong><br><small>2016-05-17 01:19:40</small></p></a></div><div class="comment-body post-content">Excellent article! It has been very useful to understand what the topic of causality is about and triggered my interest to continue learning more!</div></div><div class=comment-level-0 id=comment-1369><div class=comment-header><a href=#comment-1369><img class=comment-avatar src="https://www.gravatar.com/avatar/e7778c88395a420fcff68a1a31afedab?s=50"><p class=comment-info><strong>Rachel Lynne Wilkerson</strong><br><small>2016-12-08 11:26:40</small></p></a></div><div class="comment-body post-content">Thanks for this post! I share your troubles over Pearl/time/feedback loops!</div></div><div class=comment-level-0 id=comment-1480><div class=comment-header><a href=#comment-1480><img class=comment-avatar src="https://www.gravatar.com/avatar/3cbe692e74c8824a7db554f18efbccad?s=50"><p class=comment-info><strong>rs</strong><br><small>2017-03-23 06:57:16</small></p></a></div><div class="comment-body post-content">Nice post. have you had any chance to apply them on real datasets. Please share those results</div></div><div class=comment-level-0 id=comment-3185><div class=comment-header><a href=#comment-3185><img class=comment-avatar src="https://www.gravatar.com/avatar/c076c646b1ac8cebfbf9ebabf4362bed?s=50"><p class=comment-info><strong>ingorohlfing</strong><br><small>2018-12-30 19:33:12</small></p></a></div><div class="comment-body post-content">Great post. I did not know about Kleinberg and Hill&rsquo;s work. I knew a similar list of criteria from this article, which is much younger <a href=https://doi.org/10.1177%2F0951629805050859 target=_blank rel=noopener>https://doi.org/10.1177%2F0951629805050859</a>
Regarding Kleinberg: Adding time certainly is valuable, but doesn&rsquo;t the smoking example change the research question from whether smoking causes lung cancer to when it causes lung cancer? The latter question is more informative and implies the former, but I&rsquo;d say it is fine to ask the first question when one is not interested in the time of occurrence of cancer.</div></div><div class=comment-level-1 id=comment-3189><div class=comment-header><a href=#comment-3189><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2018-12-31 01:25:05</small></p></a></div><div class="comment-body post-content">Thank you! I agree that the latter question is more informative, but I now think that saying that &ldquo;smoking causes cancer&rdquo; isn&rsquo;t particularly meaningful, as it ignores both timing and dosage. A good summary of the case for well-defined interventions was provided by Miguel Hernán in this paper: <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5207342/ target=_blank rel=noopener>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5207342/</a></div></div><div class=comment-level-0 id=comment-21812><div class=comment-header><a href=#comment-21812><img class=comment-avatar src="https://www.gravatar.com/avatar/c19ebbee91d2fd5351fbc11cbb77c26e?s=50"><p class=comment-info><strong>locksley1</strong><br><small>2021-01-02 11:44:23</small></p></a></div><div class="comment-body post-content">The limits of Pearl&rsquo;s theory on feedback loops bothers me too. However, have you studied much Control Theory? Or dynamical systems in general? It explicitly deals with feedback loops. I&rsquo;d be keen to get your thoughts on the comparison of Control Theory vs Pearl&rsquo;s Causal Inference.</div></div><div class=comment-level-1 id=comment-21816><div class=comment-header><a href=#comment-21816><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2021-01-03 01:07:36</small></p></a></div><div class="comment-body post-content">Thanks for the comment! No, I haven&rsquo;t studied Control Theory. Maybe I&rsquo;ll look into it one day. :)</div></div></section></article></main><div class=global-footer><div class=footer><span>Text and figures licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank rel=noopener>CC BY-NC-ND 4.0</a> by <a href=https://yanirseroussi.com/about/>Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
      <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></div></div><script>const menuTrigger=document.querySelector("#menu-trigger"),menuElem=document.querySelector(".menu");menuTrigger.addEventListener("click",function(){menuElem.classList.toggle("hidden")}),document.body.addEventListener("click",function(e){menuTrigger.contains(e.target)||menuElem.classList.add("hidden")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>