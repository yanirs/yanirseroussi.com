<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>The joys of offline data collection | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="data science,deep learning,environment,marine science,personal,predictive modelling,scuba diving">
<meta name=description content="Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.
The Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/>
<link crossorigin=anonymous href=/yanirseroussi.com/assets/css/stylesheet.min.7603165cb47dcda1f46a839ca379731b2f33098c043e75f680940e69a5d546a8.css integrity="sha256-dgMWXLR9zaH0aoOco3lzGy8zCYwEPnX2gJQOaaXVRqg=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/yanirseroussi.com/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirs.github.io/yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirs.github.io/yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirs.github.io/yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirs.github.io/yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirs.github.io/yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.0">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="The joys of offline data collection">
<meta property="og:description" content="Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.
The Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/">
<meta property="og:image" content="https://yanirs.github.io/yanirseroussi.com/triaenodon-obesus-whitetip-reef-shark.jpg"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2016-01-24T00:32:25+00:00">
<meta property="article:modified_time" content="2016-01-24T00:32:25+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirs.github.io/yanirseroussi.com/triaenodon-obesus-whitetip-reef-shark.jpg">
<meta name=twitter:title content="The joys of offline data collection">
<meta name=twitter:description content="Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.
The Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirs.github.io/yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"The joys of offline data collection","item":"https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The joys of offline data collection","name":"The joys of offline data collection","description":"Many modern data scientists don\u0026rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.\nThe Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania.","keywords":["data science","deep learning","environment","marine science","personal","predictive modelling","scuba diving"],"articleBody":"Many modern data scientists don’t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.\nThe Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The data collected by RLS volunteers is freely available on the RLS website, and has been used for producing various reports and scientific publications. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef’s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to classify the type of substrate or growth (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record all the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The RLS manual includes all the details on how surveys are performed.\nPerforming RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee’s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).\nRLS requires a lot of hard work, but there are many reasons why it’s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.\nPre-training and thoughts on supervised learning Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.\nTraining the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using reveal.js, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It’d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please let me know if you know of anyone who has experimented with this idea (update: gwern from Reddit pointed me to the paper Curriculum Learning by Bengio et al., which discusses this idea).\n  RLS flashcard example (Chaetodon lunulatus)   While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as Reef Fish Identification: Tropical Pacific provide concise descriptions of the identifying physical features of each fish (see the image below for the book’s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to those used for generating image descriptions, except that the goal would be to use descriptions of the classes to improve classification accuracy.\n  Fish ID example (Chaetodon lunulatus). Source: Reef Fish Identification: Tropical Pacific   Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.\nOne similarity to supervised machine learning that I encountered was the danger of overfitting. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!\nCan’t this be automated? While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to deep learning, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.\nIf the results of the LifeCLEF 2015 Fish Task are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It’s usually the case that it’s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.\nDealing with high diversity isn’t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn’t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.\n  Chlorurus sordidus variations. Source: Tropical Marine Fishes of Australia   Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an active research area, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there’s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver’s home, where there is no cost to RLS). Further, RLS’s mission is “to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health”. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.\nSmall data is valuable When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn’t be surveyed if it wasn’t for RLS volunteers. For example, in a recent Nature article, the authors used RLS data to assess the vulnerability of marine fauna to global warming.\n  RLS surveys by Australian financial year (July-June). Source: RLS Foundation Annual Report 2015   Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef’s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.\n  In summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn’t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I’ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science collecting data is time-consuming, and coming up with appropriate research questions is hard. It is a lot of fun, though.\n","wordCount":"2207","inLanguage":"en","image":"https://yanirs.github.io/yanirseroussi.com/triaenodon-obesus-whitetip-reef-shark.jpg","datePublished":"2016-01-24T00:32:25Z","dateModified":"2016-01-24T00:32:25Z","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirs.github.io/yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirs.github.io/yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
The joys of offline data collection
</h1>
<div class=post-meta>January 24, 2016&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2016-01-24-the-joys-of-offline-data-collection/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_360x0_resize_q75_box.jpg 360w ,https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_480x0_resize_q75_box.jpg 480w ,https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_720x0_resize_q75_box.jpg 720w ,https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_1080x0_resize_q75_box.jpg 1080w ,https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_1500x0_resize_q75_box.jpg 1500w ,https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg 3220w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg alt width=3220 height=1310>
</figure>
<div class=post-content><p>Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the <a href=http://reeflifesurvey.com/ target=_blank rel=noopener>Reef Life Survey project</a>. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.</p>
<h2 id=the-reef-life-survey-project>The Reef Life Survey project<a hidden class=anchor aria-hidden=true href=#the-reef-life-survey-project>#</a></h2>
<p>Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The <a href=http://reeflifesurvey.com/reef-life-survey/survey-data/ target=_blank rel=noopener>data collected by RLS volunteers is freely available on the RLS website</a>, and has been used for producing <a href=http://reeflifesurvey.com/scientific-papers/ target=_blank rel=noopener>various reports and scientific publications</a>. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef&rsquo;s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to <a href=https://drive.google.com/file/d/0B9XQg8_HWQVPU2NweEFmcEJYQTQ/view target=_blank rel=noopener>classify the type of substrate or growth</a> (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record <strong>all</strong> the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The <a href=http://reeflifesurvey.com/wp-content/uploads/2015/07/NEW-Methods-Manual_150815.pdf target=_blank rel=noopener>RLS manual</a> includes all the details on how surveys are performed.</p>
<p>Performing RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee&rsquo;s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).</p>
<p>RLS requires a lot of hard work, but there are many reasons why it&rsquo;s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.</p>
<h2 id=pre-training-and-thoughts-on-supervised-learning>Pre-training and thoughts on supervised learning<a hidden class=anchor aria-hidden=true href=#pre-training-and-thoughts-on-supervised-learning>#</a></h2>
<p>Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.</p>
<p>Training the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using <a href=http://lab.hakim.se/reveal-js/ target=_blank rel=noopener>reveal.js</a>, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It&rsquo;d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please <a href=http://yanirseroussi.com/about/>let me know</a> if you know of anyone who has experimented with this idea (<strong>update:</strong> <a href=https://www.reddit.com/r/MachineLearning/comments/42dp7l/the_joys_of_offline_data_collection_including/cz9jqev target=_blank rel=noopener>gwern from Reddit</a> pointed me to the paper <a href=http://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf target=_blank rel=noopener>Curriculum Learning</a> by Bengio et al., which discusses this idea).</p>
<figure>
<a href=rls-flashcard.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_1080x0_resize_box_3.png 1080w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_1500x0_resize_box_3.png 1500w," src=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_800x0_resize_box_3.png alt="RLS flashcard example (Chaetodon lunulatus)" loading=lazy>
</a><figcaption>
<p>RLS flashcard example (Chaetodon lunulatus)
</p>
</figcaption>
</figure>
<p>While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target=_blank rel=noopener>Reef Fish Identification: Tropical Pacific</a> provide concise descriptions of the identifying physical features of each fish (see the image below for the book&rsquo;s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to <a href=https://cs.stanford.edu/people/karpathy/cvpr2015.pdf target=_blank rel=noopener>those used for generating image descriptions</a>, except that the goal would be to use descriptions <em>of the classes</em> to improve classification accuracy.</p>
<figure>
<a href=rls-fish-id-sample.jpg target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_360x0_resize_q75_box.jpg 360w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_480x0_resize_q75_box.jpg 480w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_720x0_resize_q75_box.jpg 720w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_1080x0_resize_q75_box.jpg 1080w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_1500x0_resize_q75_box.jpg 1500w," src=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_800x0_resize_q75_box.jpg alt="Fish ID example (Chaetodon lunulatus)" loading=lazy>
</a><figcaption>
<p>Fish ID example (Chaetodon lunulatus). Source: <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target=_blank rel=noopener>Reef Fish Identification: Tropical Pacific</a>
</p>
</figcaption>
</figure>
<p>Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.</p>
<p>One similarity to supervised machine learning that I encountered was the danger of <a href=https://en.wikipedia.org/wiki/Overfitting target=_blank rel=noopener>overfitting</a>. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!</p>
<h2 id=cant-this-be-automated>Can&rsquo;t this be automated?<a hidden class=anchor aria-hidden=true href=#cant-this-be-automated>#</a></h2>
<p>While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to <a href=https://en.wikipedia.org/wiki/Deep_learning target=_blank rel=noopener>deep learning</a>, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.</p>
<p>If the results of the <a href=http://www.imageclef.org/lifeclef/2015/fish target=_blank rel=noopener>LifeCLEF 2015 Fish Task</a> are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It&rsquo;s usually the case that it&rsquo;s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.</p>
<p>Dealing with high diversity isn&rsquo;t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn&rsquo;t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.</p>
<figure>
<a href=rls-chlorurus-sordidus-life-phases.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 404px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases_hu8876a6e9da35211b0afbcd81c1bbf6ab_280512_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png 404w," src=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png alt="Chlorurus sordidus variations" loading=lazy>
</a><figcaption>
<p>Chlorurus sordidus variations. Source: <a href=http://newhollandpublishers.com/au/natural-history/2285-field-guide-to-the-tropical-fish-of-australia-9781921517617.html target=_blank rel=noopener>Tropical Marine Fishes of Australia</a>
</p>
</figcaption>
</figure>
<p>Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an <a href=http://www.acfr.usyd.edu.au/research/subsea.shtml target=_blank rel=noopener>active research area</a>, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there&rsquo;s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver&rsquo;s home, where there is no cost to RLS). Further, RLS&rsquo;s mission is &ldquo;to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health&rdquo;. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.</p>
<h2 id=small-data-is-valuable>Small data is valuable<a hidden class=anchor aria-hidden=true href=#small-data-is-valuable>#</a></h2>
<p>When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn&rsquo;t be surveyed if it wasn&rsquo;t for RLS volunteers. For example, in a <a href="https://drive.google.com/file/d/0B9XQg8_HWQVPYkNidDFLWHBmUEE/view?usp=sharing" target=_blank rel=noopener>recent Nature article</a>, the authors used RLS data to assess the vulnerability of marine fauna to global warming.</p>
<figure>
<a href=rls-survey-counts.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png 777w," src=https://yanirs.github.io/yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png alt="RLS surveys by Australian financial year (July-June)" loading=lazy>
</a><figcaption>
<p>RLS surveys by Australian financial year (July-June). Source: <a href=http://reeflifesurvey.com/wp-content/uploads/2015/11/RLSF_AnnualReport_2015_FINAL_301115.pdf target=_blank rel=noopener>RLS Foundation Annual Report 2015</a>
</p>
</figcaption>
</figure>
<p>Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef&rsquo;s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.</p>
<div style=text-align:center>
<iframe src="https://www.google.com/maps/d/embed?mid=1mpBSDQyF12FUh497KuFfYa0lHIk" width=640 height=480></iframe>
</div>
<p>In summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn&rsquo;t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I&rsquo;ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science <a href=http://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/>collecting data is time-consuming, and coming up with appropriate research questions is hard</a>. It is a lot of fun, though.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/data-science/>data science</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/deep-learning/>deep learning</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/environment/>environment</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/marine-science/>marine science</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/personal/>personal</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/predictive-modelling/>predictive modelling</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/scuba-diving/>scuba diving</a></li>
</ul>
</footer><section class=comment-section>
<strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirs.github.io%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
</section>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://yanirs.github.io/yanirseroussi.com/>Yanir Seroussi | Data science and beyond</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><div class=mailing-list-container>
<form class=mailing-list action=https://tinyletter.com/yanir method=post target=popupwindow onsubmit="return window.open('https://tinyletter.com/yanir','popupwindow','scrollbars=yes,width=800,height=600'),!0">
<label for=mailing-list-email>Get new post notifications</label>
<input type=text name=email id=mailing-list-email placeholder="Email address">
<input type=hidden value=1 name=embed>
<input type=submit value=Subscribe>
</form>
</div>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>