<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The joys of offline data collection | Yanir Seroussi | Data & AI for Startup Impact</title><meta name=keywords content="data science,deep learning,environment,marine science,personal,predictive modelling,Reef Life Survey,scuba diving"><meta name=description content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey."><meta name=author content="Yanir Seroussi"><link rel=canonical href=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/><meta name=google-site-verification content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU"><link crossorigin=anonymous href=/assets/css/stylesheet.d9b9873b5f5f328a87bad89f89301b8212fc8c8f1d4421d468cc7148aa2fcc2f.css integrity="sha256-2bmHO19fMoqHutifiTAbghL8jI8dRCHUaMxxSKovzC8=" rel="preload stylesheet" as=style><link rel=icon href=https://yanirseroussi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yanirseroussi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yanirseroussi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://yanirseroussi.com/apple-touch-icon.png><link rel=mask-icon href=https://yanirseroussi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"><meta property="og:site_name" content="Yanir Seroussi | Data & AI for Startup Impact"><meta property="og:title" content="The joys of offline data collection"><meta property="og:description" content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey."><meta property="og:locale" content="en-au"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-01-24T00:32:25+00:00"><meta property="article:modified_time" content="2024-01-16T09:56:03+10:00"><meta property="article:tag" content="Data Science"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Environment"><meta property="article:tag" content="Marine Science"><meta property="article:tag" content="Personal"><meta property="article:tag" content="Predictive Modelling"><meta property="og:image" content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg"><meta name=twitter:title content="The joys of offline data collection"><meta name=twitter:description content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Browse Posts","item":"https://yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"The joys of offline data collection","item":"https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The joys of offline data collection","name":"The joys of offline data collection","description":"Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey.","keywords":["data science","deep learning","environment","marine science","personal","predictive modelling","Reef Life Survey","scuba diving"],"articleBody":"Many modern data scientists don’t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.\nThe Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The data collected by RLS volunteers is freely available on the RLS website, and has been used for producing various reports and scientific publications. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef’s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to classify the type of substrate or growth (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record all the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The RLS manual includes all the details on how surveys are performed.\nPerforming RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee’s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).\nRLS requires a lot of hard work, but there are many reasons why it’s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.\nPre-training and thoughts on supervised learning Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.\nTraining the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using reveal.js, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It’d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please let me know if you know of anyone who has experimented with this idea (update: gwern from Reddit pointed me to the paper Curriculum Learning by Bengio et al., which discusses this idea).\nRLS flashcard example (Chaetodon lunulatus) While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as Reef Fish Identification: Tropical Pacific provide concise descriptions of the identifying physical features of each fish (see the image below for the book’s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to those used for generating image descriptions, except that the goal would be to use descriptions of the classes to improve classification accuracy.\nFish ID example (Chaetodon lunulatus). Source: Reef Fish Identification: Tropical Pacific Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.\nOne similarity to supervised machine learning that I encountered was the danger of overfitting. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!\nCan’t this be automated? While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to deep learning, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.\nIf the results of the LifeCLEF 2015 Fish Task are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It’s usually the case that it’s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.\nDealing with high diversity isn’t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn’t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.\nChlorurus sordidus variations. Source: Tropical Marine Fishes of Australia Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an active research area, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there’s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver’s home, where there is no cost to RLS). Further, RLS’s mission is “to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health”. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.\nSmall data is valuable When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn’t be surveyed if it wasn’t for RLS volunteers. For example, in a recent Nature article, the authors used RLS data to assess the vulnerability of marine fauna to global warming.\nRLS surveys by Australian financial year (July-June). Source: RLS Foundation Annual Report 2015 Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef’s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.\nIn summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn’t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I’ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science collecting data is time-consuming, and coming up with appropriate research questions is hard. It is a lot of fun, though.\n","wordCount":"2207","inLanguage":"en","image":"https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg","datePublished":"2016-01-24T00:32:25Z","dateModified":"2024-01-16T09:56:03+10:00","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data \u0026 AI for Startup Impact","logo":{"@type":"ImageObject","url":"https://yanirseroussi.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data & AI for Startup Impact (Alt + H)">Yanir Seroussi | Data & AI for Startup Impact</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><button id=menu-trigger aria-haspopup=menu aria-label="Menu Button">
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><ul class="menu hidden"><li><a href=https://yanirseroussi.com/about/ title=About><span>About</span></a></li><li><a href=https://yanirseroussi.com/posts/ title=Writing><span>Writing</span></a></li><li><a href=https://yanirseroussi.com/talks/ title=Speaking><span>Speaking</span></a></li><li><a href=https://yanirseroussi.com/consult/ title=Consulting><span>Consulting</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">The joys of offline data collection</h1><div class=post-meta><span title='2016-01-24 00:32:25 +0000 UTC'>January 24, 2016</span></div></header><figure class=entry-cover><img loading=eager srcset='https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu_2c7d6ffe16ccb803.jpg 360w,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu_76a2611ed122a52d.jpg 480w,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu_e66a61637464c2f1.jpg 720w,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu_4dad4b0e1dd33561.jpg 1080w,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu_82c80e6a789922c4.jpg 1500w,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg 3220w' src=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg sizes="(min-width: 768px) 720px, 100vw" width=3220 height=1310 alt></figure><div class=post-content><p>Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the <a href=http://reeflifesurvey.com/ target=_blank rel=noopener>Reef Life Survey project</a>. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.</p><h2 id=the-reef-life-survey-project>The Reef Life Survey project<a hidden class=anchor aria-hidden=true href=#the-reef-life-survey-project>#</a></h2><p>Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The <a href=http://reeflifesurvey.com/reef-life-survey/survey-data/ target=_blank rel=noopener>data collected by RLS volunteers is freely available on the RLS website</a>, and has been used for producing <a href=http://reeflifesurvey.com/scientific-papers/ target=_blank rel=noopener>various reports and scientific publications</a>. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef&rsquo;s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to <a href=https://drive.google.com/file/d/0B9XQg8_HWQVPU2NweEFmcEJYQTQ/view target=_blank rel=noopener>classify the type of substrate or growth</a> (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record <strong>all</strong> the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The <a href=http://reeflifesurvey.com/wp-content/uploads/2015/07/NEW-Methods-Manual_150815.pdf target=_blank rel=noopener>RLS manual</a> includes all the details on how surveys are performed.</p><p>Performing RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee&rsquo;s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).</p><p>RLS requires a lot of hard work, but there are many reasons why it&rsquo;s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.</p><h2 id=pre-training-and-thoughts-on-supervised-learning>Pre-training and thoughts on supervised learning<a hidden class=anchor aria-hidden=true href=#pre-training-and-thoughts-on-supervised-learning>#</a></h2><p>Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.</p><p>Training the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using <a href=http://lab.hakim.se/reveal-js/ target=_blank rel=noopener>reveal.js</a>, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It&rsquo;d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please <a href=https://yanirseroussi.com/about/>let me know</a> if you know of anyone who has experimented with this idea (<strong>update:</strong> <a href=https://www.reddit.com/r/MachineLearning/comments/42dp7l/the_joys_of_offline_data_collection_including/cz9jqev target=_blank rel=noopener>gwern from Reddit</a> pointed me to the paper <a href=http://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf target=_blank rel=noopener>Curriculum Learning</a> by Bengio et al., which discusses this idea).</p><figure><a href=rls-flashcard.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_f5a1e543bf9fcac7.png 360w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_2e0c85b2ecb23669.png 480w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_11544e2edf46d18d.png 720w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_3b688e3bd3e7d804.png 1080w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_61f761aadffff558.png 1500w," src=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu_82f1d04429d079e9.png alt="RLS flashcard example (Chaetodon lunulatus)" loading=lazy></a><figcaption><p>RLS flashcard example (Chaetodon lunulatus)</p></figcaption></figure><p>While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target=_blank rel=noopener>Reef Fish Identification: Tropical Pacific</a> provide concise descriptions of the identifying physical features of each fish (see the image below for the book&rsquo;s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to <a href=https://cs.stanford.edu/people/karpathy/cvpr2015.pdf target=_blank rel=noopener>those used for generating image descriptions</a>, except that the goal would be to use descriptions <em>of the classes</em> to improve classification accuracy.</p><figure><a href=rls-fish-id-sample.jpg target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_3485545bc01efc76.jpg 360w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_15c57e9e48ff810c.jpg 480w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_aa29a215d8595f7.jpg 720w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_8d4086c8a5456fea.jpg 1080w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_c2fcfd9a73285982.jpg 1500w," src=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu_5997259b4fce9091.jpg alt="Fish ID example (Chaetodon lunulatus)" loading=lazy></a><figcaption><p>Fish ID example (Chaetodon lunulatus). Source: <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target=_blank rel=noopener>Reef Fish Identification: Tropical Pacific</a></p></figcaption></figure><p>Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.</p><p>One similarity to supervised machine learning that I encountered was the danger of <a href=https://en.wikipedia.org/wiki/Overfitting target=_blank rel=noopener>overfitting</a>. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!</p><h2 id=cant-this-be-automated>Can&rsquo;t this be automated?<a hidden class=anchor aria-hidden=true href=#cant-this-be-automated>#</a></h2><p>While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to <a href=https://en.wikipedia.org/wiki/Deep_learning target=_blank rel=noopener>deep learning</a>, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.</p><p>If the results of the <a href=http://www.imageclef.org/lifeclef/2015/fish target=_blank rel=noopener>LifeCLEF 2015 Fish Task</a> are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It&rsquo;s usually the case that it&rsquo;s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.</p><p>Dealing with high diversity isn&rsquo;t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn&rsquo;t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.</p><figure><a href=rls-chlorurus-sordidus-life-phases.png target=_blank rel=noopener><img sizes="(min-width: 768px) 404px,
100vw" srcset="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases_hu_dba6fb9e1f948c39.png 360w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png 404w," src=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png alt="Chlorurus sordidus variations" loading=lazy></a><figcaption><p>Chlorurus sordidus variations. Source: <a href=http://newhollandpublishers.com/au/natural-history/2285-field-guide-to-the-tropical-fish-of-australia-9781921517617.html target=_blank rel=noopener>Tropical Marine Fishes of Australia</a></p></figcaption></figure><p>Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an <a href=http://www.acfr.usyd.edu.au/research/subsea.shtml target=_blank rel=noopener>active research area</a>, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there&rsquo;s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver&rsquo;s home, where there is no cost to RLS). Further, RLS&rsquo;s mission is &ldquo;to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health&rdquo;. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.</p><h2 id=small-data-is-valuable>Small data is valuable<a hidden class=anchor aria-hidden=true href=#small-data-is-valuable>#</a></h2><p>When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn&rsquo;t be surveyed if it wasn&rsquo;t for RLS volunteers. For example, in a <a href="https://drive.google.com/file/d/0B9XQg8_HWQVPYkNidDFLWHBmUEE/view?usp=sharing" target=_blank rel=noopener>recent Nature article</a>, the authors used RLS data to assess the vulnerability of marine fauna to global warming.</p><figure><a href=rls-survey-counts.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu_56b2fe7c0e0916eb.png 360w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu_f6b00af330935806.png 480w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu_f7f2b1cfbca6934a.png 720w,
https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png 777w," src=https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png alt="RLS surveys by Australian financial year (July-June)" loading=lazy></a><figcaption><p>RLS surveys by Australian financial year (July-June). Source: <a href=http://reeflifesurvey.com/wp-content/uploads/2015/11/RLSF_AnnualReport_2015_FINAL_301115.pdf target=_blank rel=noopener>RLS Foundation Annual Report 2015</a></p></figcaption></figure><p>Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef&rsquo;s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.</p><div style=text-align:center><iframe src="https://www.google.com/maps/d/embed?mid=1mpBSDQyF12FUh497KuFfYa0lHIk" width=640 height=480></iframe></div><p>In summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn&rsquo;t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I&rsquo;ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science <a href=https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/>collecting data is time-consuming, and coming up with appropriate research questions is hard</a>. It is a lot of fun, though.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yanirseroussi.com/tags/data-science/>Data Science</a></li><li><a href=https://yanirseroussi.com/tags/deep-learning/>Deep Learning</a></li><li><a href=https://yanirseroussi.com/tags/environment/>Environment</a></li><li><a href=https://yanirseroussi.com/tags/marine-science/>Marine Science</a></li><li><a href=https://yanirseroussi.com/tags/personal/>Personal</a></li><li><a href=https://yanirseroussi.com/tags/predictive-modelling/>Predictive Modelling</a></li><li><a href=https://yanirseroussi.com/tags/reef-life-survey/>Reef Life Survey</a></li><li><a href=https://yanirseroussi.com/tags/scuba-diving/>Scuba Diving</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on x" href="https://x.com/intent/tweet/?text=The%20joys%20of%20offline%20data%20collection&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&amp;hashtags=datascience%2cdeeplearning%2cenvironment%2cmarinescience%2cpersonal%2cpredictivemodelling%2cReefLifeSurvey%2cscubadiving"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&amp;title=The%20joys%20of%20offline%20data%20collection&amp;summary=The%20joys%20of%20offline%20data%20collection&amp;source=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&title=The%20joys%20of%20offline%20data%20collection"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on whatsapp" href="https://api.whatsapp.com/send?text=The%20joys%20of%20offline%20data%20collection%20-%20https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on telegram" href="https://telegram.me/share/url?text=The%20joys%20of%20offline%20data%20collection&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The joys of offline data collection on ycombinator" href="https://news.ycombinator.com/submitlink?t=The%20joys%20of%20offline%20data%20collection&u=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><a href=/contact/#mailing-list-email target=_blank aria-label="subscribe to mailing list" class=mailing-list-link id=mailing-list-link>Subscribe
</a><script>const mailingListButton=document.getElementById("mailing-list-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mailingListButton.style.visibility="visible",mailingListButton.style.opacity="1"):(mailingListButton.style.visibility="hidden",mailingListButton.style.opacity="0")}</script><div class=mailing-list-container><script src=https://f.convertkit.com/ckjs/ck.5.js></script><form class="mailing-list seva-form formkit-form" action=https://app.convertkit.com/forms/6549537/subscriptions method=post data-sv-form=6549537 data-uid=9157759fce data-format=inline data-version=5 data-options='{"settings":{"after_subscribe":{"action":"message","redirect_url":"","success_message":"Success! Now check your email to confirm your subscription."},"recaptcha":{"enabled":false},"return_visitor":{"action":"show","custom_content":""}},"version":"5"}'><div data-style=clean><ul class="formkit-alert formkit-alert-error" data-element=errors data-group=alert></ul><div data-element=fields data-stacked=false><label for=mailing-list-email>Get new posts in your mailbox</label>
<input id=mailing-list-email name=email_address aria-label="Email address" placeholder="Email address" required type=email>
<button data-element=submit>Subscribe</button></div></div></form><div class=footer>Join hundreds of subscribers. No spam or AI-generated slop. Unsubscribe any time.</div></div><section class=comment-section><p class="post-content contact-cta">Public comments are closed, but I love hearing from readers. Feel free to
<a href=/contact/ target=_blank>contact me</a> with your thoughts.</p></section><p class="post-content data-webring">This site is a part of the <a href=https://randyau.github.io/datawebring/index.html target=_blank rel=noopener>Data People Writing Stuff</a> webring.<br><a class=data-webring-previous-link target=_blank rel=noopener>← previous site</a>
&nbsp; | &nbsp;
<a class=data-webring-next-link target=_blank rel=noopener>next site →</a></p><script>function populateDataWebringLinks(){const e=["https://www.randyau.com/","https://vickiboykis.com/","https://www.counting-stuff.com/","https://gecky.me/","https://qethanm.cc/datawebring/","https://mlops.systems/","https://e2eml.school/","https://blog.harterrt.com/","https://www.jessemostipak.com/","https://elliotgunn.github.io/","https://radbrt.com","https://simon.podhajsky.net/blog/","https://www.heltweg.org/","https://emilyriederer.com/","https://kylestratis.com","https://www.eamoncaddigan.net/","https://karnwong.me/","https://aino-spring.com/"];function t(e){let n,s,t;for(t=e.length-1;t>0;t--)n=Math.floor(Math.random()*(t+1)),s=e[t],e[t]=e[n],e[n]=s}t(e),document.querySelector(".data-webring-previous-link").href=e[0],document.querySelector(".data-webring-next-link").href=e[1]}populateDataWebringLinks()</script></article></main><div class=global-footer><div class=footer><span>Text and figures licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank rel=noopener>CC BY-NC-ND 4.0</a> by <a href=https://yanirseroussi.com/about/>Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></div></div><script>const menuTrigger=document.querySelector("#menu-trigger"),menuElem=document.querySelector(".menu");menuTrigger.addEventListener("click",function(){menuElem.classList.toggle("hidden")}),document.body.addEventListener("click",function(e){menuTrigger.contains(e.target)||menuElem.classList.add("hidden")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>