<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The joys of offline data collection | Yanir Seroussi | Data &amp; AI for Nature</title>
<meta name="keywords" content="data science, deep learning, environment, marine science, personal, predictive modelling, Reef Life Survey, scuba diving">
<meta name="description" content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey.">
<meta name="author" content="Yanir Seroussi">
<link rel="canonical" href="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/">
<meta name="google-site-verification" content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5f211a7f85c56ecff5cf5804b46f4b44d608a174ce494c0395670acf45df9d19.css" integrity="sha256-XyEaf4XFbs/1z1gEtG9LRNYIoXTOSUwDlWcKz0XfnRk=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yanirseroussi.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yanirseroussi.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yanirseroussi.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yanirseroussi.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://yanirseroussi.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="The joys of offline data collection" />
<meta property="og:description" content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/" />
<meta property="og:image" content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-01-24T00:32:25+00:00" />
<meta property="article:modified_time" content="2024-01-16T09:56:03+10:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg" />
<meta name="twitter:title" content="The joys of offline data collection"/>
<meta name="twitter:description" content="Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://yanirseroussi.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "The joys of offline data collection",
      "item": "https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The joys of offline data collection",
  "name": "The joys of offline data collection",
  "description": "Insights on data collection and machine learning from spending a month sailing, diving, and counting fish with Reef Life Survey.",
  "keywords": [
    "data science", "deep learning", "environment", "marine science", "personal", "predictive modelling", "Reef Life Survey", "scuba diving"
  ],
  "articleBody": "Many modern data scientists don’t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the Reef Life Survey project. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.\nThe Reef Life Survey project Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The data collected by RLS volunteers is freely available on the RLS website, and has been used for producing various reports and scientific publications. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef’s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to classify the type of substrate or growth (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record all the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The RLS manual includes all the details on how surveys are performed.\nPerforming RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee’s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).\nRLS requires a lot of hard work, but there are many reasons why it’s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.\nPre-training and thoughts on supervised learning Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.\nTraining the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using reveal.js, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It’d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please let me know if you know of anyone who has experimented with this idea (update: gwern from Reddit pointed me to the paper Curriculum Learning by Bengio et al., which discusses this idea).\nRLS flashcard example (Chaetodon lunulatus) While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as Reef Fish Identification: Tropical Pacific provide concise descriptions of the identifying physical features of each fish (see the image below for the book’s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to those used for generating image descriptions, except that the goal would be to use descriptions of the classes to improve classification accuracy.\nFish ID example (Chaetodon lunulatus). Source: Reef Fish Identification: Tropical Pacific Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.\nOne similarity to supervised machine learning that I encountered was the danger of overfitting. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!\nCan’t this be automated? While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to deep learning, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.\nIf the results of the LifeCLEF 2015 Fish Task are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It’s usually the case that it’s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.\nDealing with high diversity isn’t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn’t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.\nChlorurus sordidus variations. Source: Tropical Marine Fishes of Australia Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an active research area, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there’s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver’s home, where there is no cost to RLS). Further, RLS’s mission is “to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health”. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.\nSmall data is valuable When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn’t be surveyed if it wasn’t for RLS volunteers. For example, in a recent Nature article, the authors used RLS data to assess the vulnerability of marine fauna to global warming.\nRLS surveys by Australian financial year (July-June). Source: RLS Foundation Annual Report 2015 Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef’s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.\nIn summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn’t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I’ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science collecting data is time-consuming, and coming up with appropriate research questions is hard. It is a lot of fun, though.\n",
  "wordCount" : "2207",
  "inLanguage": "en",
  "image":"https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg","datePublished": "2016-01-24T00:32:25Z",
  "dateModified": "2024-01-16T09:56:03+10:00",
  "author":{
    "@type": "Person",
    "name": "Yanir Seroussi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yanir Seroussi | Data \u0026 AI for Nature",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yanirseroussi.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yanirseroussi.com/" accesskey="h" title="Yanir Seroussi | Data &amp; AI for Nature (Alt + H)">Yanir Seroussi | Data &amp; AI for Nature</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yanirseroussi.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/talks/" title="Talks">
                    <span>Talks</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/consult/" title="Consult">
                    <span>Consult</span>
                </a>
            </li>
            
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      The joys of offline data collection
    </h1>
    <div class="post-meta"><span title='2016-01-24 00:32:25 +0000 UTC'>January 24, 2016</span>&nbsp;|&nbsp;<a href="https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2016-01-24-the-joys-of-offline-data-collection/index.md" rel="noopener noreferrer" target="_blank">Suggest changes</a>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" srcset="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_360x0_resize_q75_box.jpg 360w ,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_480x0_resize_q75_box.jpg 480w ,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_720x0_resize_q75_box.jpg 720w ,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_1080x0_resize_q75_box.jpg 1080w ,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark_hu5b48ea845b0512937c3ac1259641b3e3_859311_1500x0_resize_q75_box.jpg 1500w ,https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg 3220w" 
            sizes="(min-width: 768px) 720px, 100vw" src="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/triaenodon-obesus-whitetip-reef-shark.jpg" alt="" 
            width="3220" height="1310">
        
</figure>
  <div class="post-content"><p>Many modern data scientists don&rsquo;t get to experience data collection in the offline world. Recently, I spent a month sailing down the northern Great Barrier Reef, collecting data for the <a href="http://reeflifesurvey.com/" target="_blank" rel="noopener">Reef Life Survey project</a>. In addition to being a great diving experience, the trip helped me obtain general insights on data collection and machine learning, which are shared in this article.</p>
<h2 id="the-reef-life-survey-project">The Reef Life Survey project<a hidden class="anchor" aria-hidden="true" href="#the-reef-life-survey-project">#</a></h2>
<p>Reef Life Survey (RLS) is a citizen scientist project, led by a team from the University of Tasmania. The <a href="http://reeflifesurvey.com/reef-life-survey/survey-data/" target="_blank" rel="noopener">data collected by RLS volunteers is freely available on the RLS website</a>, and has been used for producing <a href="http://reeflifesurvey.com/scientific-papers/" target="_blank" rel="noopener">various reports and scientific publications</a>. An RLS survey is performed along a 50 metre tape, which is laid at a constant depth following a reef&rsquo;s contour. After laying the tape, one diver takes photos of the bottom at 2.5 metre intervals along the transect line. These photos are automatically analysed to <a href="https://drive.google.com/file/d/0B9XQg8_HWQVPU2NweEFmcEJYQTQ/view" target="_blank" rel="noopener">classify the type of substrate or growth</a> (e.g., hard coral or sand). Divers then complete two swims along each side of the transect. On the first swim (method 1), divers record <strong>all</strong> the fish species and large swimming animals found in a 5 metre corridor from the line. The second swim (method 2) requires keeping closer to the bottom and looking under ledges and vegetation in a 1 metre corridor from the line, targeting invertebrates and cryptic animals. The <a href="http://reeflifesurvey.com/wp-content/uploads/2015/07/NEW-Methods-Manual_150815.pdf" target="_blank" rel="noopener">RLS manual</a> includes all the details on how surveys are performed.</p>
<p>Performing RLS surveys is not a trivial task. In the tropics, it is not uncommon to record around 100 fish species on method 1. The scientists running the project are very conscious of the importance of obtaining high-quality data, so training to become an RLS volunteer takes considerable effort and dedication. The process generally consists of doing surveys together with an experienced RLS diver, and comparing the data after each dive. Once the trainee&rsquo;s data matches that of the experienced RLSer, they are considered good enough to perform surveys independently. However, retraining is often required when surveying new ecoregions (e.g., an RLSer trained in Sydney needs further training to survey the Great Barrier Reef).</p>
<p>RLS requires a lot of hard work, but there are many reasons why it&rsquo;s worth the effort. As someone who cares about marine conservation, I like the fact that RLS dives yield useful data that is used to drive environmental management decisions. As a scuba diver, I enjoy the opportunity to dive places that are rarely dived and the enhanced knowledge of the marine environment – doing surveys makes me notice things that I would otherwise overlook. Finally, as a data scientist, I find the exposure to the work of marine scientists very educational.</p>
<h2 id="pre-training-and-thoughts-on-supervised-learning">Pre-training and thoughts on supervised learning<a hidden class="anchor" aria-hidden="true" href="#pre-training-and-thoughts-on-supervised-learning">#</a></h2>
<p>Doing surveys in the tropics is a completely different story from surveying temperate reefs, due to the substantially higher diversity and abundance of marine creatures. Producing high-quality results requires being able to identify most creatures underwater, while doing the survey. It is possible to write down descriptions and take photos of unidentified species, but doing this for a large number of species is impractical.</p>
<p>Training the neural network in my head to classify tropical fish by species was an interesting experience. The approach that worked best was making flashcards using <a href="http://lab.hakim.se/reveal-js/" target="_blank" rel="noopener">reveal.js</a>, photos scraped from various sources, and past survey data. As the image below shows, each flashcard consists of a single photo, and pressing the down arrow reveals the name of the creature. With some basic JavaScript, I made the presentation select a different subset of photos on each load. Originally, I tried to learn all the 1000+ species that were previously recorded in the northern Great Barrier Reef, but this proved to be too hard – I realised that a better strategy was needed. The strategy that I chose was to focus on the most frequently-recorded species: I started by memorising the most frequent ones (e.g., those recorded on more than 50% of surveys), and gradually made it more challenging by decreasing the frequency threshold (e.g., to 25% in 5% steps). This proved to be pretty effective – by the time I started diving I could identify about 50-100 species underwater, even though I had mostly been using static images. It&rsquo;d be interesting to know whether this kind of approach would be effective in training neural networks (or other batch-trained models) in certain scenarios – spend a few epochs training with instances from a subset of the classes, and gradually increase the number of considered classes. This may be effective when errors on certain classes are more important than others, and may yield different results from simply weighting classes or instances. Please <a href="https://yanirseroussi.com/about/">let me know</a> if you know of anyone who has experimented with this idea (<strong>update:</strong> <a href="https://www.reddit.com/r/MachineLearning/comments/42dp7l/the_joys_of_offline_data_collection_including/cz9jqev" target="_blank" rel="noopener">gwern from Reddit</a> pointed me to the paper <a href="http://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf" target="_blank" rel="noopener">Curriculum Learning</a> by Bengio et al., which discusses this idea).</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
  
  
  



<figure>
  <a href="rls-flashcard.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_1080x0_resize_box_3.png 1080w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_1500x0_resize_box_3.png 1500w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-flashcard_hu3a07a6eda7f0dd6656303f37c93114ae_407004_800x0_resize_box_3.png"
        
      
        alt="RLS flashcard example (Chaetodon lunulatus)"loading="lazy"
    />
  </a><figcaption>
        <p>RLS flashcard example (Chaetodon lunulatus)
          </p>
      </figcaption>
</figure>

<p>While repeatedly looking at photos and their labels felt a lot like training an artificial neural network, as a human I have the advantage of being able to easily use information from multiple sources. For example, fish ID books such as <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target="_blank" rel="noopener">Reef Fish Identification: Tropical Pacific</a> provide concise descriptions of the identifying physical features of each fish (see the image below for the book&rsquo;s entry for Chaetodon lunulatus – the butterflyfish from the flashcard above). Reading those descriptions made me learn more effectively, by helping me focus my attention on the parts that matter for classification. Learning only from static images can be hard when classifying creatures with highly variable colour schemes – using extraneous knowledge about what actually matters when it comes to classification is the way to go in practice. Further, features that are hard to decode from photos – like behaviour and habitat – are sometimes crucial to distinguishing different species. One interesting thought is that while photos can be seen as raw data, natural language descriptions are essentially models. Utilising such models is likely to be of benefit in many areas. For example, being able to tell a classifier what to look for in an image would make training a supervised classifier more similar to the way humans learn. This may be achieved using similar techniques to <a href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf" target="_blank" rel="noopener">those used for generating image descriptions</a>, except that the goal would be to use descriptions <em>of the classes</em> to improve classification accuracy.</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
  
  
  



<figure>
  <a href="rls-fish-id-sample.jpg" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_360x0_resize_q75_box.jpg 360w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_480x0_resize_q75_box.jpg 480w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_720x0_resize_q75_box.jpg 720w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_1080x0_resize_q75_box.jpg 1080w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_1500x0_resize_q75_box.jpg 1500w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-fish-id-sample_hu81bc07515959c0114557245105561936_595169_800x0_resize_q75_box.jpg"
        
      
        alt="Fish ID example (Chaetodon lunulatus)"loading="lazy"
    />
  </a><figcaption>
        <p>Fish ID example (Chaetodon lunulatus). Source: <a href="http://www.fishid.com/nwp/index.php?main_page=product_info&cPath=1&products_id=10" target="_blank" rel="noopener">Reef Fish Identification: Tropical Pacific</a>
          </p>
      </figcaption>
</figure>

<p>Another difference between my learning and supervised machine learning is that if I found a creature hard to identify, I would go and look for more photos or videos of them. Videos were especially valuable, because in practice I rarely had to identify static creatures. This approach may be applicable in situations where labelled data is abundant. Sometimes, using all the labelled data makes model training too slow to be practical. An approach I used in the past to overcome this issue is to randomly sample the data, but it often makes sense to sample in a way that yields the best model, e.g., by sampling more instances from classes that are harder to classify.</p>
<p>One similarity to supervised machine learning that I encountered was the danger of <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="noopener">overfitting</a>. Due to the relatively small number of photos and the fact that I had to view each one of them multiple times, I found that in some cases I memorised the entire photo rather than the creature. This was especially the case with low-quality photos or ones that were missing key features. My regularisation approach consisted of trying to memorise the descriptions from the book, and collecting more photos. I wish more algorithms were this self-conscious about overfitting!</p>
<h2 id="cant-this-be-automated">Can&rsquo;t this be automated?<a hidden class="anchor" aria-hidden="true" href="#cant-this-be-automated">#</a></h2>
<p>While doing surveys and studying species, I kept asking myself whether the whole thing can be automated. Thanks to <a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank" rel="noopener">deep learning</a>, computers have recently gotten very good at classifying images, sometimes outperforming humans. It seems likely that at some point the survey methodology would be changed to just taking a video of the dive, and letting an algorithm do the hard job of identifying the creatures. Analysis of the bottom photos is automated, so it is reasonable to automate the other survey methods as well. However, there are quite a few challenges that need to be overcome before full automation can be implemented.</p>
<p>If the results of the <a href="http://www.imageclef.org/lifeclef/2015/fish" target="_blank" rel="noopener">LifeCLEF 2015 Fish Task</a> are any indication, we are quite far from automating fish identification. The precision of the top methods in that challenge was around 80% for identifying 15 fish species from underwater videos, where the chosen species are quite distinct from each other. In tropical surveys it is not uncommon to record around 100 fish species along the 50 metre transect, with many species being similar to each other. It&rsquo;s usually the case that it&rsquo;s not same species on every dive (even at the same site), so replacing humans would require training a highly accurate classifier on thousands of species.</p>
<p>Dealing with high diversity isn&rsquo;t the only challenge in automating RLS. The appearance of many species varies by gender and age, so the classifier would have to learn all those variations (see image below for an example). Getting good training data can be very challenging, since the labelling process is labour-intensive, and elements like colour and backscatter are highly dependent on dive site conditions and the quality of the camera. Another complication is that RLS data includes size estimates, which can be hard to obtain from videos and photos without knowing how far the camera was from the subject and the type of lens used. In addition, accounting for side information (geolocation, behaviour, depth, etc.) can make a huge difference in accurately identifying species, but it isn&rsquo;t easy to integrate with some learning models. Finally, it is likely that some species will be missed when videos are taken without any identification done underwater, because RLSers tend to get good photos of species that they know will be hard to identify, even if it means spending more time at one spot or shining strobes under ledges.</p>













  
    
      
    
  
    
  
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="rls-chlorurus-sordidus-life-phases.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 404px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases_hu8876a6e9da35211b0afbcd81c1bbf6ab_280512_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png 404w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-chlorurus-sordidus-life-phases.png"
        
      
        alt="Chlorurus sordidus variations"loading="lazy"
    />
  </a><figcaption>
        <p>Chlorurus sordidus variations. Source: <a href="http://newhollandpublishers.com/au/natural-history/2285-field-guide-to-the-tropical-fish-of-australia-9781921517617.html" target="_blank" rel="noopener">Tropical Marine Fishes of Australia</a>
          </p>
      </figcaption>
</figure>

<p>Another aspect of automating surveys is completely removing the need for human divers by sending robots down. This is an <a href="http://www.acfr.usyd.edu.au/research/subsea.shtml" target="_blank" rel="noopener">active research area</a>, and is the only way of surveying deep waters. However, this approach still requires a boat-based crew to deploy the robots. It may also yield different data from RLS for cryptic species, though this depends on the type of robots used. In addition, there&rsquo;s the issue of cost – RLS relies on volunteer scuba divers who are diving anyway, so the cost of getting RLSers to do surveys is rather low (especially for shore dives near a diver&rsquo;s home, where there is no cost to RLS). Further, RLS&rsquo;s mission is &ldquo;to inspire and engage a global volunteer community to survey reefs using scientific methods and share knowledge about marine ecosystem health&rdquo;. Engaging the community is a crucial part of RLS because robots do not care about the environment. Humans do.</p>
<h2 id="small-data-is-valuable">Small data is valuable<a hidden class="anchor" aria-hidden="true" href="#small-data-is-valuable">#</a></h2>
<p>When compared to datasets commonly encountered online, RLS data is small. As the image below shows, fewer than 10,000 surveys have been conducted to date. However, this data is still valuable, as it provides a high-quality snapshot of the state of marine ecosystems in areas that wouldn&rsquo;t be surveyed if it wasn&rsquo;t for RLS volunteers. For example, in a <a href="https://drive.google.com/file/d/0B9XQg8_HWQVPYkNidDFLWHBmUEE/view?usp=sharing" target="_blank" rel="noopener">recent Nature article</a>, the authors used RLS data to assess the vulnerability of marine fauna to global warming.</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="rls-survey-counts.png" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_360x0_resize_box_3.png 360w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_480x0_resize_box_3.png 480w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts_hu15ec9ab10a70cdaa32005f3e1f6b4e41_38960_720x0_resize_box_3.png 720w,
            
          
            
              https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png 777w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2016/01/24/the-joys-of-offline-data-collection/rls-survey-counts.png"
        
      
        alt="RLS surveys by Australian financial year (July-June)"loading="lazy"
    />
  </a><figcaption>
        <p>RLS surveys by Australian financial year (July-June). Source: <a href="http://reeflifesurvey.com/wp-content/uploads/2015/11/RLSF_AnnualReport_2015_FINAL_301115.pdf" target="_blank" rel="noopener">RLS Foundation Annual Report 2015</a>
          </p>
      </figcaption>
</figure>

<p>Each RLS survey requires several hours of work. In addition to performing the survey itself, a lot of work goes into entering the data and verifying its quality. Getting to the survey sites is not always a trivial task, especially for remote sites such as some of those we dived on my recent trip. Spending a month diving the Great Barrier Reef is a good way of appreciating its greatness. As the map shows, the surveys we did covered only the top part of the reef&rsquo;s 2300 kilometres, and we only sampled a few sites within that part. The Great Barrier Reef is very vast, and it is hard to convey its vastness with just words or a map. You have to be there to understand – it is quite humbling.</p>
<div style="text-align:center;">
  <iframe src="https://www.google.com/maps/d/embed?mid=1mpBSDQyF12FUh497KuFfYa0lHIk" width="640" height="480"></iframe>
</div>
<p>In summary, the RLS experience has given me a new appreciation for small data in the offline world. Offline data collection is often expensive and labour-intensive – you need to work hard to produce a few high-quality data points. But the size of your data doesn&rsquo;t matter (though having more quality data is always good). What really matters is what you do with the data – and the RLS team and their collaborators have been doing quite a lot. The RLS experience also illustrates the importance of domain expertise: I&rsquo;ve looked at the RLS datasets, but I have no idea what questions are worth asking and answering using those datasets. The RLS project is yet another example of how in science <a href="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/">collecting data is time-consuming, and coming up with appropriate research questions is hard</a>. It is a lot of fun, though.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://yanirseroussi.com/tags/data-science/">data science</a></li>
      <li><a href="https://yanirseroussi.com/tags/deep-learning/">deep learning</a></li>
      <li><a href="https://yanirseroussi.com/tags/environment/">environment</a></li>
      <li><a href="https://yanirseroussi.com/tags/marine-science/">marine science</a></li>
      <li><a href="https://yanirseroussi.com/tags/personal/">personal</a></li>
      <li><a href="https://yanirseroussi.com/tags/predictive-modelling/">predictive modelling</a></li>
      <li><a href="https://yanirseroussi.com/tags/reef-life-survey/">Reef Life Survey</a></li>
      <li><a href="https://yanirseroussi.com/tags/scuba-diving/">scuba diving</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on x"
            href="https://x.com/intent/tweet/?text=The%20joys%20of%20offline%20data%20collection&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&amp;hashtags=datascience%2cdeeplearning%2cenvironment%2cmarinescience%2cpersonal%2cpredictivemodelling%2cReefLifeSurvey%2cscubadiving">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&amp;title=The%20joys%20of%20offline%20data%20collection&amp;summary=The%20joys%20of%20offline%20data%20collection&amp;source=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f&title=The%20joys%20of%20offline%20data%20collection">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on whatsapp"
            href="https://api.whatsapp.com/send?text=The%20joys%20of%20offline%20data%20collection%20-%20https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on telegram"
            href="https://telegram.me/share/url?text=The%20joys%20of%20offline%20data%20collection&amp;url=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The joys of offline data collection on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=The%20joys%20of%20offline%20data%20collection&u=https%3a%2f%2fyanirseroussi.com%2f2016%2f01%2f24%2fthe-joys-of-offline-data-collection%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer><section class="comment-section">
  

  <p class="post-content contact-cta">
    Public comments are closed, but I love hearing from readers. Feel free to
    <a href="/about/#contact-me" target="_blank">contact me</a> with your thoughts.
  </p>

  
  
  
  

  
</section>



</article>
    </main>
    <div class="mailing-list-container">
  <form
          class="mailing-list"
          action="https://yanirseroussi.us17.list-manage.com/subscribe/post?u=3c08aa3ff27dd92978019febd&amp;id=bc3ab705af"
          method="post"
          target="_blank"
          novalidate
  >
    <label for="mailing-list-email">Get new posts in your mailbox</label>
    <input type="text" name="EMAIL" id="mailing-list-email" placeholder="Email address" />
    <div style="position: absolute; left: -5000px;" aria-hidden="true">
      <input type="text" name="b_3c08aa3ff27dd92978019febd_bc3ab705af" tabindex="-1" value="" />
    </div>
    <input type="submit" value="Subscribe" />
  </form>

  <div class="footer">
    Alternatively, <a href="https://yanirseroussi.com/index.xml">subscribe to RSS feed</a>.
  </div>

  <div class="footer">
    <span>Text and figures licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener">CC BY-NC-ND 4.0</a> by <a href="https://yanirseroussi.com/about/">Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
    <span>
      Powered by
      <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
      <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
  </div>
</div>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
