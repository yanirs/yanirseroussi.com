<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Hackers beware: Bootstrap sampling may be harmful | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="bootstrapping,data science,hackers,software engineering,statistics">
<meta name=description content="Bootstrap sampling techniques are very appealing, as they don&rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don&rsquo;t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: &ldquo;If you can write a for-loop, you can do statistics&rdquo;.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/>
<link crossorigin=anonymous href=/yanirseroussi.com/assets/css/stylesheet.min.51e68192da3381c9040a063242bafad56d6d28666fff1f9e523f9eaad0207a83.css integrity="sha256-UeaBktozgckECgYyQrr61W1tKGZv/x+eUj+eqtAgeoM=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/yanirseroussi.com/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirs.github.io/yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirs.github.io/yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirs.github.io/yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirs.github.io/yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirs.github.io/yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.88.1">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Hackers beware: Bootstrap sampling may be harmful">
<meta property="og:description" content="Bootstrap sampling techniques are very appealing, as they don&rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don&rsquo;t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: &ldquo;If you can write a for-loop, you can do statistics&rdquo;.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/">
<meta property="og:image" content="https://yanirs.github.io/yanirseroussi.com/warning-signs.jpg"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2019-01-07T21:07:56+00:00">
<meta property="article:modified_time" content="2019-01-07T21:07:56+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirs.github.io/yanirseroussi.com/warning-signs.jpg">
<meta name=twitter:title content="Hackers beware: Bootstrap sampling may be harmful">
<meta name=twitter:description content="Bootstrap sampling techniques are very appealing, as they don&rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don&rsquo;t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: &ldquo;If you can write a for-loop, you can do statistics&rdquo;.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirs.github.io/yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"Hackers beware: Bootstrap sampling may be harmful","item":"https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hackers beware: Bootstrap sampling may be harmful","name":"Hackers beware: Bootstrap sampling may be harmful","description":"Bootstrap sampling techniques are very appealing, as they don\u0026rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don\u0026rsquo;t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: \u0026ldquo;If you can write a for-loop, you can do statistics\u0026rdquo;.","keywords":["bootstrapping","data science","hackers","software engineering","statistics"],"articleBody":"Bootstrap sampling techniques are very appealing, as they don’t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don’t have much statistical knowledge. For example, the main thesis of the excellent Statistics for Hackers talk by Jake VanderPlas is: “If you can write a for-loop, you can do statistics”. Similar ground was covered by Erik Bernhardsson in The Hacker’s Guide to Uncertainty Estimates, which provides more use cases for bootstrapping (with code examples). However, I’ve learned in the past few weeks that there are quite a few pitfalls in bootstrapping. Much of what I’ve learned is summarised in a paper titled What Teachers Should Know about the Bootstrap: Resampling in the Undergraduate Statistics Curriculum by Tim Hesterberg. I doubt that many hackers would be motivated to read a paper with such a title, so my goal with this post is to make some of my discoveries more accessible to a wider audience. To learn more about the issues raised in this post, it’s worth reading Hesterberg’s paper and other linked resources.\nFor quick reference, here’s a summary of the advice in this post:\n Use an accurate method for estimating confidence intervals Use enough resamples – at least 10-15K Don’t compare confidence intervals visually Ensure that the basic assumptions apply to your situation  Pitfall #1: Inaccurate confidence intervals Confidence intervals are a common way of quantifying the uncertainty in an estimate of a population parameter. The percentile method is one of the simplest bootstrapping approaches for generating confidence intervals. For example, let’s say we have a data sample of size n and we want to estimate a 95% confidence interval for the population mean. We take r bootstrap resamples from the original data sample, where each resample is a sample with replacement of size n. We calculate the mean of each resample and store the means in a sorted array. We then return the 95% confidence interval as the values that fall at the 0.025r and 0.975r indices of the sorted array (i.e., the 2.5% and 97.5% percentiles). The following table shows what the first two resamples may look like for a data sample of size n=5.\n    Original sample Resample #1 Resample #2 …     Values 10 30 20 …    12 20 20     20 12 30     30 12 30     45 45 30           Mean 23.4 23.8 26 …    The percentile method is nice and simple. Any programmer should be able to easily implement it in their favourite programming language, assuming they can actually program. Unfortunately, this method is just not accurate enough for small sample sizes. Quoting Hesterberg (emphasis mine):\n The sample sizes needed for different intervals to satisfy the “reasonably accurate” (off by no more than 10% on each side) criterion are: n ≥ 101 for the bootstrap t, 220 for the skewness-adjusted t statistic, 2,235 for expanded percentile, 2,383 for percentile, 4,815 for ordinary t (which I have rounded up to 5,000 above), 5,063 for t with bootstrap standard errors and something over 8,000 for the reverse percentile method.\n In a shorter version of the paper cited above, Hesterberg concludes that:\n In practice, implementing some of the more accurate bootstrap methods is difficult (especially those not described here), and people should use a package rather than attempt this themselves.\n In short, make sure you’re using an accurate method for estimating confidence intervals when dealing with sample sizes of less than a few thousand values. Using a package is a great idea, but unfortunately I don’t know of any Python bootstrapping package that is feature-complete: ARCH and scikits-bootstrap support advanced confidence interval methods but don’t support analysis of two samples of uneven sizes, while bootstrapped works with samples of uneven sizes but only supports the percentile and the reverse percentile method (which Hesterberg found to be even less accurate). If you know of any better Python packages, please let me know! (I don’t use R, but I suspect the situation is better there). Update: ARCH now supports analysis of samples of uneven sizes following an issue I reported. It seems to be the best Python bootstrapping package, so I recommend using it.\nPitfall #2: Not enough resamples Accurate bootstrap estimates require a large number of resamples. Many code snippets use 1,000 resamples, probably because it looks like a large number. However, seeming large isn’t enough. Quoting Hesterberg again:\n For both the bootstrap and permutation tests, the number of resamples needs to be 15,000 or more, for 95% probability that simulation-based one-sided levels fall within 10% of the true values, for 95% intervals and 5% tests. I recommend r = 10,000 for routine use, and more when accuracy matters.\n[…]\nWe want decisions to depend on the data, not random variation in the Monte Carlo implementation. We used r = 500,000 in the Verizon project.\n That’s right, half a million resamples! Accuracy mattered in the Verizon case, as the results of the analysis determined whether large penalties were paid or not. In short, use at least 10-15,000 resamples to be safe. Don’t use 1,000.\nPitfall #3: Comparison of single-sample confidence intervals Confidence intervals are commonly used to decide if the difference between two samples is statistically significant. Bootstrapping provides a straightforward way of estimating confidence intervals without making assumptions about the way the data was generated. For example, given two samples, we can obtain confidence intervals for the mean of each sample and end up with a plot like this:\n   When looking at this plot, some people may conclude that the difference between the groups isn’t statistically significant because the confidence intervals overlap. However, overlapping confidence intervals don’t imply a lack of statistical significance because it is possible for the confidence interval of the difference between the sample means to not contain zero. Prasanna Parasurama explained why this happens in this post. While this issue isn’t unique to bootstrapping, it’s worth remembering that when comparing two groups, we need to obtain the confidence interval for the difference in the parameter we’re comparing, not compare single-sample confidence intervals.\nFor a concrete example, consider a case where we’re looking at a binary outcomes (yes/no or 1/0), which occur in coin flips or online A/B tests. Sample A consists of 2,150 zeroes and 350 ones, while sample B consists of 2,250 zeroes and 440 ones. As these are fairly large samples, we can use the bootstrap percentile method to obtain 95% confidence intervals for the mean of each sample. As the following figure shows, these intervals overlap. If we use the same method to also obtain a 95% confidence interval for the difference in means between B and A, we see that it doesn’t include zero. Therefore, we can say that the difference between B and A is statistically significant, despite the overlap between the single-sample confidence intervals.\n   It’s worth noting that when analysing binary outcomes, we can make stronger assumptions about the data rather than use bootstrapping to obtain confidence intervals. Erik Bernhardsson suggests using the Beta distribution to obtain single-sample confidence intervals, but as we’ve seen, they don’t tell us enough about the differences between samples. I suggested using a Bayesian approach in the past, which makes explicit modelling assumptions that allow us to encode our prior knowledge on the specific environment where the data was generated. For example, when running online A/B tests, we often have a ballpark figure for reasonable results, which can be used in the Bayesian A/B testing calculator I built.\nPitfall #4: Unrepresentative and dependent samples While the basic bootstrap makes no assumption about the underlying distribution of the data, it is not assumption-free. For example, when dealing with correlated data points from a time series, using the basic bootstrapping approach is wrong because it assumes that the data points are independent. Instead, a block bootstrap should be used – see the ARCH package for some implementation examples. In addition, bootstrapping doesn’t solve problems with the underlying sampling approach. For example, the data sample may not be representative of the population because of its small size, or there may be selection biases and measurement errors. No amount of bootstrapping is going to help with such issues. In general, it always helps to be aware of the data’s generation process, e.g., different considerations apply when dealing with data from online experiments versus observational studies.\nConclusion and next steps While bootstrapping is a powerful method, its initial impression of simplicity is misleading. To draw valid conclusions, it’s a good idea to use a package and be aware of considerations that are specific to the analysed data sample. However, if you’re already increasing your awareness of the data and its generation process, it may make sense to explicitly encode your assumptions in the model. This is where another hacker resource would come in handy: Probabilistic Programming \u0026 Bayesian Methods for Hackers by Cam Davidson-Pilon. Admittedly, it’s a bit longer than the average blog post or conference talk, but it is worth reading.\nGoing down the bootstrapping rabbit hole has reminded me of an important lesson: Blog posts and talks – especially ones with the word hacker in the title – may be a good starting point, but they shouldn’t be relied on for serious work. Instead, it is better to consult peer-reviewed resources and textbooks, such as the references listed in ARCH’s documentation. In my future explorations of bootstrapping and other methods, I will heed Abraham Lincoln’s timeless advice to not trust everything I read on the internet.\n   Update (Oct 2019): I published a post summarising a talk I gave on the topic, complete with simulation code that illustrates the issues with some bootstrapping algorithms.\n","wordCount":"1625","inLanguage":"en","image":"https://yanirs.github.io/yanirseroussi.com/warning-signs.jpg","datePublished":"2019-01-07T21:07:56Z","dateModified":"2019-01-07T21:07:56Z","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirs.github.io/yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirs.github.io/yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Hackers beware: Bootstrap sampling may be harmful
</h1>
<div class=post-meta>January 7, 2019&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2019-01-08-hackers-beware-bootstrap-sampling-may-be-harmful/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs_hu66da5e7e5a432a77b79afd3fa924437e_1490615_360x0_resize_q75_box.jpg 360w ,https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs_hu66da5e7e5a432a77b79afd3fa924437e_1490615_480x0_resize_q75_box.jpg 480w ,https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs_hu66da5e7e5a432a77b79afd3fa924437e_1490615_720x0_resize_q75_box.jpg 720w ,https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs_hu66da5e7e5a432a77b79afd3fa924437e_1490615_1080x0_resize_q75_box.jpg 1080w ,https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs_hu66da5e7e5a432a77b79afd3fa924437e_1490615_1500x0_resize_q75_box.jpg 1500w ,https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs.jpg 3531w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/warning-signs.jpg alt width=3531 height=1200>
</figure>
<div class=post-content><p><a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>Bootstrap sampling techniques</a> are very appealing, as they don&rsquo;t require knowing much about statistics and opaque formulas. Instead, all one needs to do is resample the given data many times, and calculate the desired statistics. Therefore, bootstrapping has been promoted as an easy way of modelling uncertainty to hackers who don&rsquo;t have much statistical knowledge. For example, the main thesis of the excellent <a href=https://speakerdeck.com/jakevdp/statistics-for-hackers><em>Statistics for Hackers</em></a> talk by Jake VanderPlas is: <em>&ldquo;If you can write a for-loop, you can do statistics&rdquo;</em>. Similar ground was covered by Erik Bernhardsson in <a href=https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html><em>The Hacker&rsquo;s Guide to Uncertainty Estimates</em></a>, which provides more use cases for bootstrapping (with code examples). However, I&rsquo;ve learned in the past few weeks that there are quite a few pitfalls in bootstrapping. Much of what I&rsquo;ve learned is summarised in a paper titled <a href=https://arxiv.org/abs/1411.5279><em>What Teachers Should Know about the Bootstrap: Resampling in the Undergraduate Statistics Curriculum</em></a> by Tim Hesterberg. I doubt that many hackers would be motivated to read a paper with such a title, so my goal with this post is to make some of my discoveries more accessible to a wider audience. To learn more about the issues raised in this post, it&rsquo;s worth reading Hesterberg&rsquo;s paper and other linked resources.</p>
<p>For quick reference, here&rsquo;s a summary of the advice in this post:</p>
<ul>
<li>Use an accurate method for estimating confidence intervals</li>
<li>Use enough resamples – at least 10-15K</li>
<li>Don&rsquo;t compare confidence intervals visually</li>
<li>Ensure that the basic assumptions apply to your situation</li>
</ul>
<h2 id=pitfall-1-inaccurate-confidence-intervals>Pitfall #1: Inaccurate confidence intervals<a hidden class=anchor aria-hidden=true href=#pitfall-1-inaccurate-confidence-intervals>#</a></h2>
<p><a href=https://en.wikipedia.org/wiki/Confidence_interval>Confidence intervals</a> are a common way of quantifying the uncertainty in an estimate of a population parameter. The percentile method is one of the simplest bootstrapping approaches for generating confidence intervals. For example, let&rsquo;s say we have a data sample of size <code>n</code> and we want to estimate a 95% confidence interval for the population mean. We take <code>r</code> bootstrap <em>resamples</em> from the original data sample, where each resample is a sample with replacement of size <code>n</code>. We calculate the mean of each resample and store the means in a sorted array. We then return the 95% confidence interval as the values that fall at the <code>0.025r</code> and <code>0.975r</code> indices of the sorted array (i.e., the 2.5% and 97.5% percentiles). The following table shows what the first two resamples may look like for a data sample of size <code>n=5</code>.</p>
<table>
<thead>
<tr>
<th></th>
<th>Original sample</th>
<th>Resample #1</th>
<th>Resample #2</th>
<th>&mldr;</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Values</strong></td>
<td>10</td>
<td>30</td>
<td>20</td>
<td>&mldr;</td>
</tr>
<tr>
<td></td>
<td>12</td>
<td>20</td>
<td>20</td>
<td></td>
</tr>
<tr>
<td></td>
<td>20</td>
<td>12</td>
<td>30</td>
<td></td>
</tr>
<tr>
<td></td>
<td>30</td>
<td>12</td>
<td>30</td>
<td></td>
</tr>
<tr>
<td></td>
<td>45</td>
<td>45</td>
<td>30</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Mean</strong></td>
<td><em>23.4</em></td>
<td><em>23.8</em></td>
<td><em>26</em></td>
<td><em>&mldr;</em></td>
</tr>
</tbody>
</table>
<p>The percentile method is nice and simple. Any programmer should be able to easily implement it in their favourite programming language, assuming <a href=https://blog.codinghorror.com/why-cant-programmers-program/>they can actually program</a>. Unfortunately, <strong>this method is just not accurate enough for small sample sizes</strong>. Quoting Hesterberg (emphasis mine):</p>
<blockquote>
<p>The sample sizes needed for different intervals to satisfy the &ldquo;reasonably accurate&rdquo; (off by no more than 10% on each side) criterion are: n ≥ 101 for the bootstrap t, 220 for the skewness-adjusted t statistic, 2,235 for expanded percentile, <b style=font-weight:700>2,383 for percentile</b>, 4,815 for ordinary t (which I have rounded up to 5,000 above), 5,063 for t with bootstrap standard errors and something over 8,000 for the reverse percentile method.</p>
</blockquote>
<p>In <a href=https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44859.pdf>a shorter version of the paper cited above</a>, Hesterberg concludes that:</p>
<blockquote>
<p>In practice, implementing some of the more accurate bootstrap methods is difficult (especially those not described here), and people should use a package rather than attempt this themselves.</p>
</blockquote>
<p>In short, <strong>make sure you&rsquo;re using an accurate method for estimating confidence intervals when dealing with sample sizes of less than a few thousand values</strong>. Using a package is a great idea, but unfortunately I don&rsquo;t know of any Python bootstrapping package that is feature-complete: <a href=https://github.com/bashtage/arch/>ARCH</a> and <a href=https://github.com/cgevans/scikits-bootstrap/>scikits-bootstrap</a> support advanced confidence interval methods but don&rsquo;t support analysis of two samples of uneven sizes, while <a href=https://github.com/facebookincubator/bootstrapped/>bootstrapped</a> works with samples of uneven sizes but only supports the percentile and the reverse percentile method (which Hesterberg found to be even less accurate). If you know of any better Python packages, please let me know! (I don&rsquo;t use R, but I suspect the situation is better there). <strong>Update</strong>: <a href=https://github.com/bashtage/arch/releases/tag/4.8.0>ARCH now supports</a> analysis of samples of uneven sizes <a href=https://github.com/bashtage/arch/issues/260>following an issue I reported</a>. It seems to be the best Python bootstrapping package, so I recommend using it.</p>
<h2 id=pitfall-2-not-enough-resamples>Pitfall #2: Not enough resamples<a hidden class=anchor aria-hidden=true href=#pitfall-2-not-enough-resamples>#</a></h2>
<p>Accurate bootstrap estimates require a large number of resamples. Many code snippets use 1,000 resamples, probably because it looks like a large number. However, <em>seeming</em> large isn&rsquo;t enough. Quoting Hesterberg again:</p>
<blockquote>
<p>For both the bootstrap and permutation tests, the number of resamples needs to be 15,000 or more, for 95% probability that simulation-based one-sided levels fall within 10% of the true values, for 95% intervals and 5% tests. I recommend r = 10,000 for routine use, and more when accuracy matters.</p>
<p>[&mldr;]</p>
<p>We want decisions to depend on the data, not random variation in the Monte Carlo implementation. We used r = 500,000 in the Verizon project.</p>
</blockquote>
<p>That&rsquo;s right, half a million resamples! Accuracy mattered in the Verizon case, as the results of the analysis determined whether large penalties were paid or not. In short, <strong>use at least 10-15,000 resamples to be safe</strong>. Don&rsquo;t use 1,000.</p>
<h2 id=pitfall-3-comparison-of-single-sample-confidence-intervals>Pitfall #3: Comparison of single-sample confidence intervals<a hidden class=anchor aria-hidden=true href=#pitfall-3-comparison-of-single-sample-confidence-intervals>#</a></h2>
<p>Confidence intervals are commonly used to decide if the difference between two samples is statistically significant. Bootstrapping provides a straightforward way of estimating confidence intervals without making assumptions about the way the data was generated. For example, given two samples, we can obtain confidence intervals for the mean of each sample and end up with a plot like this:</p>
<figure>
<a href=overlapping-confidence-intervals.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals_hue7fc18354688a60dc90db601b41630cc_12060_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals_hue7fc18354688a60dc90db601b41630cc_12060_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals_hue7fc18354688a60dc90db601b41630cc_12060_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals.png 928w," src=https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals_hue7fc18354688a60dc90db601b41630cc_12060_800x0_resize_box_3.png alt="Overlapping confidence intervals" loading=lazy>
</a>
</figure>
<p>When looking at this plot, some people may conclude that the difference between the groups isn&rsquo;t statistically significant because the confidence intervals overlap. However, <strong>overlapping confidence intervals don&rsquo;t imply a lack of statistical significance</strong> because it is possible for the confidence interval of the <em>difference</em> between the sample means to not contain zero. Prasanna Parasurama explained why this happens in <a href=https://towardsdatascience.com/why-overlapping-confidence-intervals-mean-nothing-about-statistical-significance-48360559900a>this post</a>. While this issue isn&rsquo;t unique to bootstrapping, it&rsquo;s worth remembering that when comparing two groups, we need to obtain the confidence interval for the difference in the parameter we&rsquo;re comparing, not compare single-sample confidence intervals.</p>
<p>For a concrete example, consider a case where we&rsquo;re looking at a binary outcomes (yes/no or 1/0), which occur in coin flips or online A/B tests. Sample A consists of 2,150 zeroes and 350 ones, while sample B consists of 2,250 zeroes and 440 ones. As these are fairly large samples, we can use the bootstrap percentile method to obtain 95% confidence intervals for the mean of each sample. As the following figure shows, these intervals overlap. If we use the same method to also obtain a 95% confidence interval for the difference in means between B and A, we see that it doesn&rsquo;t include zero. Therefore, we can say that the difference between B and A is statistically significant, despite the overlap between the single-sample confidence intervals.</p>
<figure>
<a href=overlapping-confidence-intervals-significant-difference.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals-significant-difference_huf36a44ed8cbc53e714f628a95bea694d_29690_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals-significant-difference_huf36a44ed8cbc53e714f628a95bea694d_29690_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals-significant-difference_huf36a44ed8cbc53e714f628a95bea694d_29690_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals-significant-difference.png 996w," src=https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/overlapping-confidence-intervals-significant-difference_huf36a44ed8cbc53e714f628a95bea694d_29690_800x0_resize_box_3.png alt="Overlapping significance intervals with a statistically significant difference" loading=lazy>
</a>
</figure>
<p>It&rsquo;s worth noting that when analysing binary outcomes, we can make stronger assumptions about the data rather than use bootstrapping to obtain confidence intervals. <a href=https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html>Erik Bernhardsson suggests using the Beta distribution to obtain single-sample confidence intervals</a>, but as we&rsquo;ve seen, they don&rsquo;t tell us enough about the differences between samples. <a href=http://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/>I suggested using a Bayesian approach in the past</a>, which makes explicit modelling assumptions that allow us to encode our prior knowledge on the specific environment where the data was generated. For example, when running online A/B tests, we often have a ballpark figure for reasonable results, which can be used in <a href=https://yanirs.github.io/tools/split-test-calculator/>the Bayesian A/B testing calculator I built</a>.</p>
<h2 id=pitfall-4-unrepresentative-and-dependent-samples>Pitfall #4: Unrepresentative and dependent samples<a hidden class=anchor aria-hidden=true href=#pitfall-4-unrepresentative-and-dependent-samples>#</a></h2>
<p>While the basic bootstrap makes no assumption about the underlying distribution of the data, it is not assumption-free. For example, when dealing with correlated data points from a time series, using the basic bootstrapping approach is wrong because it assumes that the data points are independent. Instead, a <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Block_bootstrap>block bootstrap</a> should be used – see <a href=https://arch.readthedocs.io/en/latest/bootstrap/timeseries-bootstraps.html>the ARCH package</a> for some implementation examples. In addition, bootstrapping doesn&rsquo;t solve problems with the underlying sampling approach. For example, the data sample may not be representative of the population because of its small size, or there may be selection biases and measurement errors. No amount of bootstrapping is going to help with such issues. In general, it always helps to be aware of the data&rsquo;s generation process, e.g., different considerations apply when <a href=https://yanirseroussi.com/2016/06/19/making-bayesian-ab-testing-more-accessible/>dealing with data from online experiments</a> versus <a href=https://yanirseroussi.com/2018/12/24/the-most-practical-causal-inference-book-ive-read-is-still-a-draft/>observational studies</a>.</p>
<h2 id=conclusion-and-next-steps>Conclusion and next steps<a hidden class=anchor aria-hidden=true href=#conclusion-and-next-steps>#</a></h2>
<p>While bootstrapping is a powerful method, its initial impression of simplicity is misleading. To draw valid conclusions, it&rsquo;s a good idea to use a package and be aware of considerations that are specific to the analysed data sample. However, if you&rsquo;re already increasing your awareness of the data and its generation process, it may make sense to explicitly encode your assumptions in the model. This is where another hacker resource would come in handy: <a href=http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/><em>Probabilistic Programming & Bayesian Methods for Hackers</em></a> by Cam Davidson-Pilon. Admittedly, it&rsquo;s a bit longer than the average blog post or conference talk, but it is worth reading.</p>
<p>Going down the bootstrapping rabbit hole has reminded me of an important lesson: Blog posts and talks – especially ones with the word <em>hacker</em> in the title – may be a good starting point, but they shouldn&rsquo;t be relied on for serious work. Instead, it is better to consult peer-reviewed resources and textbooks, such as the <a href=https://arch.readthedocs.io/en/latest/bootstrap/background.html>references listed in ARCH&rsquo;s documentation</a>. In my future explorations of bootstrapping and other methods, I will heed Abraham Lincoln&rsquo;s timeless advice to not trust everything I read on the internet.</p>
<figure>
<a href=dont-believe-everything-you-read-on-the-internet-lincoln.jpg target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 576px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/_hu443dfcd29851ba5e3a0593bd3d3f46da_33137_dbefe08049f120a85e6b8ffeb571b5f7.jpg 360w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/_hu443dfcd29851ba5e3a0593bd3d3f46da_33137_f4242f0d698b489a965ede37d3bf9fda.jpg 480w,
https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/dont-believe-everything-you-read-on-the-internet-lincoln.jpg 576w," src=https://yanirs.github.io/yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/dont-believe-everything-you-read-on-the-internet-lincoln.jpg alt="Abraham Lincoln internet quote" loading=lazy>
</a>
</figure>
<p><strong>Update (Oct 2019)</strong>: I published <a href=https://yanirseroussi.com/2019/10/06/bootstrapping-the-right-way/>a post</a> summarising a talk I gave on the topic, complete with <a href=https://github.com/yanirs/yanirs.github.io/blob/master/talks/bootstrapping-the-right-way/notebook.ipynb>simulation code</a> that illustrates the issues with some bootstrapping algorithms.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/bootstrapping/>bootstrapping</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/data-science/>data science</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/hackers/>hackers</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/software-engineering/>software engineering</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/statistics/>statistics</a></li>
</ul>
</footer><section class=comment-section>
<strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirs.github.io%2fyanirseroussi.com%2f2019%2f01%2f08%2fhackers-beware-bootstrap-sampling-may-be-harmful%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
</section>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://yanirs.github.io/yanirseroussi.com/>Yanir Seroussi | Data science and beyond</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>