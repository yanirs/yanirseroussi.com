<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>The hardest parts of data science | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="climate change,data science,Kaggle,predictive modelling,science communication">
<meta name=description content="Contrary to common belief, the hardest part of data science isn&rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.
The not-so-hard parts Before discussing the hardest parts of data science, it&rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/>
<meta name=google-site-verification content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.d82763b27e3c03fb214855050d02ce82ce126a6a6fa5a13998c2793c6e61cf15.css integrity="sha256-2Cdjsn48A/shSFUFDQLOgs4SampvpaE5mMJ5PG5hzxU=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.89.2">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="The hardest parts of data science">
<meta property="og:description" content="Contrary to common belief, the hardest part of data science isn&rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.
The not-so-hard parts Before discussing the hardest parts of data science, it&rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/">
<meta property="og:image" content="https://yanirseroussi.com/foggy-random-forest.jpg"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2015-11-23T04:14:21+00:00">
<meta property="article:modified_time" content="2021-11-09T15:38:25+10:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirseroussi.com/foggy-random-forest.jpg">
<meta name=twitter:title content="The hardest parts of data science">
<meta name=twitter:description content="Contrary to common belief, the hardest part of data science isn&rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.
The not-so-hard parts Before discussing the hardest parts of data science, it&rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"The hardest parts of data science","item":"https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The hardest parts of data science","name":"The hardest parts of data science","description":"Contrary to common belief, the hardest part of data science isn\u0026rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.\nThe not-so-hard parts Before discussing the hardest parts of data science, it\u0026rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.","keywords":["climate change","data science","Kaggle","predictive modelling","science communication"],"articleBody":"Contrary to common belief, the hardest part of data science isn’t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.\nThe not-so-hard parts Before discussing the hardest parts of data science, it’s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.\nModel fitting is seen by some as particularly hard, or as real data science. This belief is fuelled in part by the success of Kaggle, that calls itself the home of data science. Most Kaggle competitions are focused on model fitting: Participants are given a well-defined problem, a dataset, and a measure to optimise, and they compete to produce the most accurate model. Coupling Kaggle’s excellent marketing with their competition setup leads many people to believe that data science is all about fitting models. In reality, building reasonably-accurate models is not that hard, because many model-building phases can easily be automated. Indeed, there are many companies that offer model fitting as a service (e.g., Microsoft, Amazon, Google and others). Even Ben Hamner, CTO of Kaggle, has said that he is “surprised at the number of ‘black box machine learning in the cloud’ services emerging: model fitting is easy. Problem definition and data collection are not.”\n   Data collection/cleaning is the essential part that everyone loves to hate. DJ Patil (US Chief Data Scientist) is quoted as saying that “the hardest part of data science is getting good, clean data. Cleaning data is often 80% of the work.” While I agree that collecting data and cleaning it can be a lot of work, I don’t think of this part as particularly hard. It’s definitely important and may require careful planning, but in many cases it just isn’t very challenging. In addition, it is often the case that the data is already given, or is collected using previously-developed methods.\nProblem definition is hard There are many reasons why problem definition can be hard. It is sometimes due to stakeholders who don’t know what they want, and expect data scientists to solve all their data problems (either real or imagined). This type of situation is summarised by the following Dilbert strip. It is best handled by cleverly managing stakeholder expectations, while stirring them towards better-defined problems.\n   Well-defined problems are great, for the obvious reason that they can actually be addressed. Examples of such problems include:\n Build a model to predict the sales of a marketing campaign Create a system that runs campaigns that automatically adapt to customer feedback Identify key objects in images Improve click-through rates on search engine results, ads, or any other element Detect whale calls from underwater recordings to prevent collisions  Often, it can be hard to get to the stage where the problem is agreed on, because this requires dealing with people who only have a fuzzy idea of what can be done with data science. Dilbertian situations aside, these people often have real problems that they care about, so exploring the core issues with them is time well-spent.\nSolution measurement is often harder than problem definition Many problems that actually matter have solutions that are really hard to measure. For example, improving the well-being of the population (e.g., a company’s customers or a country’s citizens) is an overarching problem that arises in many situations. However, this problem gives rise to the hard question of how well-being can be measured and aggregated. The following paragraphs discuss issues that occur in solution measurement, often making it the hardest part of data science.\nIdeally, we would always be able to run randomised controlled trials to measure treatment effects. However, the reality is that experimental data is often censored, there many constraints on running experiments (ethics, practicality, budget, etc.), and confounding factors may make it impossible to identify the true causal impact of interventions. These issues seriously influence many aspects of our lives. I’ve written a post on how these issues manifest themselves in research on the connection between nutrition and our health. Here, I’ll discuss another major example: the health effects of smoking and anthropogenic climate change.\nWhile smoking and anthropogenic climate change may seem unrelated, they actually have a lot in common. In both cases it is hard (or impossible) to perform experiments to determine causality, and in both cases this fact has been used to mislead the public by parties with commercial and ideological interests. In the case of smoking, due to ethical reasons, one can’t perform an experiment where a random control group is forced not to smoke, while a treatment group is forced to smoke. Further, since it can take many years for smoking-caused diseases to develop, it’d take a long time to obtain the results of such an experiment. Tobacco companies have exploited this fact for years, claiming that there may be some genetic factor that causes both smoking and a higher susceptibility to smoking-related diseases. Fortunately, we live in a world where these claims have been widely discredited, and it is now clear to most people that smoking is harmful. However, similar doubt-casting techniques are used by polluters and their supporters in the debate on anthropogenic climate change. While no serious climate scientist doubts the fact that human activities are causing climate change, this can’t be proved through experimentation on another Earth. In both cases, the answers should be clear when looking at the evidence and the mechanisms at play without an ideological bias. It doesn’t take a scientist to figure out that pumping your lungs full of smoke on a regular basis is likely to be harmful, as is pumping the atmosphere full of greenhouse gases that have been sequestered for millions of years. However, as said by Upton Sinclair, “it is difficult to get a man to understand something, when his salary depends upon his not understanding it.”\nAssuming that we have addressed the issues raised so far, there is the matter of choosing a measure or metric of success. How do we know that our solution works well? A common approach is to choose a single metric to focus on, such as increasing conversion rates. However, all metrics have their flaws, and there are quite a few problems with metric selection and its maintenance over time.\nFirst, focusing on a single metric can be harmful, because no metric is perfect. A classic example of this issue is the focus on growing the economy, as measured by gross domestic product (GDP). The article What is up with the GDP? by Frank Shostak summarises some of the problems with GDP:\n The GDP framework cannot tell us whether final goods and services that were produced during a particular period of time are a reflection of real wealth expansion, or a reflection of capital consumption.\nFor instance, if a government embarks on the building of a pyramid, which adds absolutely nothing to the well-being of individuals, the GDP framework will regard this as economic growth. In reality, however, the building of the pyramid will divert real funding from wealth-generating activities, thereby stifling the production of wealth.\n[…]\nThe whole idea of GDP gives the impression that there is such a thing as the national output. In the real world, however, wealth is produced by someone and belongs to somebody. In other words, goods and services are not produced in totality and supervised by one supreme leader. This in turn means that the entire concept of GDP is devoid of any basis in reality. It is an empty concept.\n Shostak’s criticism comes from a right-winged viewpoint – his argument is that the GDP is used as an excuse for unnecessary government intervention with the market. However, the focus on GDP growth is also heavily-criticised by the left due to the fact that it doesn’t consider environmental effects and inequalities in the distribution of wealth. It is a bit odd that GDP growth is still considered a worthwhile goal by many people, given that it can easily be skewed by a few powerful individuals who choose to build unnecessary pyramids (though perhaps this is the real reason why the GDP persists – wealthy individuals have an interest in keeping it this way).\nEven if we decide to use multiple metrics to evaluate our solution, our troubles aren’t over yet. Using multiple metrics often means that there are trade-offs between the different metrics. For example, with the precision and recall measures that are commonly used to evaluate the performance of search engines, it is rare to be able to increase both precision and recall at the same time. Precision is the percentage of relevant items out of those that have been returned, while recall is the percentage of relevant items that have been returned out of the overall number of relevant items. Hence, it is easy to artificially increase recall to 100% by always returning all the items in the database, but this would mean settling for near-zero precision. Similarly, one can increase precision by always returning a single item that the algorithm is very confident about, but this means that recall would suffer. Ultimately, the best balance between precision and recall depends on the application.\nAnother issue with choosing metrics is the impossibility of reliably evaluating our choices. This is summarised well by Scott Berkun in his book The Year Without Pants:\n All metrics create temptations. Even with great intentions and smart minds, data runs you faster and faster into a stupid self-destructive circle. Data can’t decide things for you. It can help you see things more clearly if captured carefully, but that’s not the same as deciding. Just as there is an advice paradox, there is a data paradox: no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.\nPut another way, there is no good KPI for measuring KPIs. There are no good metrics for evaluating metrics (or for evaluating metrics for evaluating metrics for evaluating metrics, and on it goes).\n OK, so we’ve picked some flawed measures that we can’t really evaluate, and we’ve accepted the imperfections of the evaluation process. Are we done yet? No. There’s still the small matter of Goodhart’s Law, which states that “when a measure becomes a target, it ceases to be a good measure.” This is often the case because people will tend to manipulate results and game the system (not necessarily maliciously) in order to hit measured goals. However, even without manipulation and gaming, we often deal with moving targets. Just because the measure we’ve chosen is suitable today, it doesn’t mean it will still be relevant in a few months or years because reality changes. For example, in the 1990s, the number of page views was a good measure of interaction with websites, but nowadays it is a pretty weak measure because many websites are single-page applications. Reality changes and so should our problems, solutions, measures, and goals.\nEmbracing ambiguity and uncertainty Personally, I find the complexities of measurement and problem definition quite interesting. However, many people aren’t that interested in this stuff – they just want working solutions and simple stories. As demonstrated by the examples throughout this article, over-simplification of complicated matters is a pervasive issue that goes beyond what’s commonly considered “data science”. This is why storytelling is seen as a key skill that data scientists should possess. I believe it’s also important to maintain one’s integrity and not just make up stories that people would buy, but it’d be naive to assume that this never happens. Either way, good data scientists embrace uncertainty and ambiguity, but can still tell a simple story if needed.\nNote: The ideas in this post were first presented at The Sydney Data Science Breakfast Meetup Group. The slides for that talk are available here.\n","wordCount":"1983","inLanguage":"en","image":"https://yanirseroussi.com/foggy-random-forest.jpg","datePublished":"2015-11-23T04:14:21Z","dateModified":"2021-11-09T15:38:25+10:00","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
<li>
<a href=https://yanirseroussi.com/about/ title=About>
<span>About</span>
</a>
</li>
<li>
<a href=https://yanirseroussi.com/talks/ title=Talks>
<span>Talks</span>
</a>
</li>
<li>
<a href=https://yanirseroussi.com/faq/ title=FAQ>
<span>FAQ</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
The hardest parts of data science
</h1>
<div class=post-meta>November 23, 2015&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2015-11-23-the-hardest-parts-of-data-science/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hub79e18ea0439364131cf541e77991fbc_191404_360x0_resize_q75_box.jpg 360w ,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hub79e18ea0439364131cf541e77991fbc_191404_480x0_resize_q75_box.jpg 480w ,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hub79e18ea0439364131cf541e77991fbc_191404_720x0_resize_q75_box.jpg 720w ,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hub79e18ea0439364131cf541e77991fbc_191404_1080x0_resize_q75_box.jpg 1080w ,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hub79e18ea0439364131cf541e77991fbc_191404_1500x0_resize_q75_box.jpg 1500w ,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg 1960w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg alt width=1960 height=597>
</figure>
<div class=post-content><p>Contrary to common belief, the hardest part of data science isn&rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.</p>
<h2 id=the-not-so-hard-parts>The not-so-hard parts<a hidden class=anchor aria-hidden=true href=#the-not-so-hard-parts>#</a></h2>
<p>Before discussing the hardest parts of data science, it&rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.</p>
<p><strong>Model fitting</strong> is seen by some as particularly hard, or as <em>real</em> data science. This belief is fuelled in part by the success of <a href=https://www.kaggle.com/ target=_blank rel=noopener>Kaggle</a>, that calls itself <em>the home of data science</em>. Most Kaggle competitions are focused on model fitting: Participants are given a well-defined problem, a dataset, and a measure to optimise, and they compete to produce the most accurate model. Coupling Kaggle&rsquo;s excellent marketing with their competition setup leads many people to believe that data science is all about fitting models. In reality, building reasonably-accurate models is not that hard, because many model-building phases can easily be automated. Indeed, there are many companies that offer model fitting as a service (e.g., Microsoft, Amazon, Google and <a href=http://www.shivonzilis.com/machineintelligence target=_blank rel=noopener>others</a>). Even Ben Hamner, CTO of Kaggle, has said that he is &ldquo;surprised at the number of &lsquo;black box machine learning in the cloud&rsquo; services emerging: model fitting is easy. Problem definition and data collection are not.&rdquo;</p>
<figure>
<a href=https://twitter.com/benhamner/status/595850574999990274 target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 569px,
          100vw
        " srcset="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml_hue38d7e4cb07e1ecfcf4351af67252791_46703_360x0_resize_box_3.png 360w,
https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml_hue38d7e4cb07e1ecfcf4351af67252791_46703_480x0_resize_box_3.png 480w,
https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml.png 569w," src=https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml.png alt="Ben Hamner tweet on black box ML in the cloud" loading=lazy>
</a>
</figure>
<p><strong>Data collection/cleaning</strong> is the essential part that everyone loves to hate. DJ Patil (US Chief Data Scientist) is <a href=http://codingvc.com/talk-summary-building-great-data-products target=_blank rel=noopener>quoted as saying</a> that &ldquo;the hardest part of data science is getting good, clean data. Cleaning data is often 80% of the work.&rdquo; While I agree that collecting data and cleaning it can be a lot of work, I don&rsquo;t think of this part as particularly hard. It&rsquo;s definitely important and may require careful planning, but in many cases it just isn&rsquo;t very challenging. In addition, it is often the case that the data is already given, or is collected using previously-developed methods.</p>
<h2 id=problem-definition-is-hard>Problem definition is hard<a hidden class=anchor aria-hidden=true href=#problem-definition-is-hard>#</a></h2>
<p>There are many reasons why problem definition can be hard. It is sometimes due to stakeholders who don&rsquo;t know what they want, and <a href=https://yanirseroussi.com/2015/08/24/you-dont-need-a-data-scientist-yet/>expect data scientists to solve all their data problems (either real or imagined)</a>. This type of situation is summarised by <a href=http://dilbert.com/strip/2012-07-29 target=_blank rel=noopener>the following Dilbert strip</a>. It is best handled by cleverly managing stakeholder expectations, while stirring them towards better-defined problems.</p>
<figure>
<a href=dilbert-big-data.jpg target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu52b7900d669ddfe03bdd894fda67e436_330047_360x0_resize_q75_box.jpg 360w,
https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu52b7900d669ddfe03bdd894fda67e436_330047_480x0_resize_q75_box.jpg 480w,
https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu52b7900d669ddfe03bdd894fda67e436_330047_720x0_resize_q75_box.jpg 720w,
https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data.jpg 904w," src=https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu52b7900d669ddfe03bdd894fda67e436_330047_800x0_resize_q75_box.jpg alt="Dilbert big data" loading=lazy>
</a>
</figure>
<p>Well-defined problems are great, for the obvious reason that they can actually be addressed. Examples of such problems include:</p>
<ul>
<li>Build a model to predict the sales of a marketing campaign</li>
<li>Create a system that runs campaigns that automatically adapt to customer feedback</li>
<li>Identify key objects in images</li>
<li>Improve click-through rates on search engine results, ads, or any other element</li>
<li>Detect whale calls from underwater recordings to prevent collisions</li>
</ul>
<p>Often, it can be hard to get to the stage where the problem is agreed on, because this requires dealing with people who only have a fuzzy idea of what can be done with data science. Dilbertian situations aside, these people often have real problems that they care about, so exploring the core issues with them is time well-spent.</p>
<h2 id=solution-measurement-is-often-harder-than-problem-definition>Solution measurement is often harder than problem definition<a hidden class=anchor aria-hidden=true href=#solution-measurement-is-often-harder-than-problem-definition>#</a></h2>
<p>Many problems that actually matter have solutions that are really hard to measure. For example, improving the well-being of the population (e.g., a company&rsquo;s customers or a country&rsquo;s citizens) is an overarching problem that arises in many situations. However, this problem gives rise to the hard question of how well-being can be measured and aggregated. The following paragraphs discuss issues that occur in solution measurement, often making it the hardest part of data science.</p>
<p>Ideally, we would always be able to run <a href=https://en.wikipedia.org/wiki/Randomized_controlled_trial target=_blank rel=noopener>randomised controlled trials</a> to measure treatment effects. However, the reality is that <a href=https://en.wikipedia.org/wiki/Censoring_%28statistics%29 target=_blank rel=noopener>experimental data is often censored</a>, there many constraints on running experiments (ethics, practicality, budget, etc.), and <a href=https://en.wikipedia.org/wiki/Confounding target=_blank rel=noopener>confounding factors</a> may make it impossible to identify the true causal impact of interventions. These issues seriously influence many aspects of our lives. I&rsquo;ve <a href=https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/>written a post on how these issues manifest themselves in research on the connection between nutrition and our health</a>. Here, I&rsquo;ll discuss another major example: the health effects of smoking and anthropogenic climate change.</p>
<p>While smoking and anthropogenic climate change may seem unrelated, they actually have a lot in common. In both cases it is hard (or impossible) to perform experiments to determine causality, and in both cases <a href=https://en.wikipedia.org/wiki/Merchants_of_Doubt target=_blank rel=noopener>this fact has been used to mislead the public by parties with commercial and ideological interests</a>. In the case of smoking, due to ethical reasons, one can&rsquo;t perform an experiment where a random control group is forced not to smoke, while a treatment group is forced to smoke. Further, since it can take many years for smoking-caused diseases to develop, it&rsquo;d take a long time to obtain the results of such an experiment. Tobacco companies have exploited this fact for years, claiming that there may be some genetic factor that causes both smoking and a higher susceptibility to smoking-related diseases. Fortunately, we live in a world where these claims have been widely discredited, and it is now clear to most people that smoking is harmful. However, similar doubt-casting techniques are used by polluters and their supporters in the debate on anthropogenic climate change. While no serious climate scientist doubts the fact that human activities are causing climate change, this can&rsquo;t be proved through experimentation on another Earth. In both cases, the answers should be clear when looking at the evidence and the mechanisms at play without an ideological bias. It doesn&rsquo;t take a scientist to figure out that pumping your lungs full of smoke on a regular basis is likely to be harmful, as is pumping the atmosphere full of greenhouse gases that have been sequestered for millions of years. However, as said by Upton Sinclair, &ldquo;it is difficult to get a man to understand something, when his salary depends upon his not understanding it.&rdquo;</p>
<p>Assuming that we have addressed the issues raised so far, there is the matter of choosing a measure or metric of success. How do we know that our solution works well? A common approach is to choose a single metric to focus on, such as increasing conversion rates. However, all metrics have their flaws, and there are quite a few problems with metric selection and its maintenance over time.</p>
<p>First, <strong>focusing on a single metric can be harmful</strong>, because no metric is perfect. A classic example of this issue is the focus on growing the economy, as measured by <a href=https://en.wikipedia.org/wiki/Gross_domestic_product target=_blank rel=noopener>gross domestic product (GDP)</a>. The article <a href=https://mises.org/library/what-gdp target=_blank rel=noopener>What is up with the GDP?</a> by Frank Shostak summarises some of the problems with GDP:</p>
<blockquote>
<p>The GDP framework cannot tell us whether final goods and services that were produced during a particular period of time are a reflection of real wealth expansion, or a reflection of capital consumption.</p>
<p>For instance, if a government embarks on the building of a pyramid, which adds absolutely nothing to the well-being of individuals, the GDP framework will regard this as economic growth. In reality, however, the building of the pyramid will divert real funding from wealth-generating activities, thereby stifling the production of wealth.</p>
<p>[&mldr;]</p>
<p>The whole idea of GDP gives the impression that there is such a thing as the national output. In the real world, however, wealth is produced by someone and belongs to somebody. In other words, goods and services are not produced in totality and supervised by one supreme leader. This in turn means that the entire concept of GDP is devoid of any basis in reality. It is an empty concept.</p>
</blockquote>
<p>Shostak&rsquo;s criticism comes from a right-winged viewpoint – his argument is that the GDP is used as an excuse for unnecessary government intervention with the market. However, the focus on GDP growth is also heavily-criticised by the left due to the fact that it doesn&rsquo;t consider environmental effects and inequalities in the distribution of wealth. It is a bit odd that GDP growth is still considered a worthwhile goal by many people, given that it can easily be skewed by a few powerful individuals who choose to build unnecessary pyramids (though perhaps this is the real reason why the GDP persists – wealthy individuals have an interest in keeping it this way).</p>
<p>Even if we decide to use <strong>multiple metrics</strong> to evaluate our solution, our troubles aren&rsquo;t over yet. Using multiple metrics often means that there are trade-offs between the different metrics. For example, with the <a href=https://en.wikipedia.org/wiki/Precision_and_recall target=_blank rel=noopener>precision and recall</a> measures that are commonly used to evaluate the performance of search engines, it is rare to be able to increase both precision and recall at the same time. <em>Precision</em> is the percentage of relevant items out of those that have been returned, while <em>recall</em> is the percentage of relevant items that have been returned out of the overall number of relevant items. Hence, it is easy to artificially increase recall to 100% by always returning all the items in the database, but this would mean settling for near-zero precision. Similarly, one can increase precision by always returning a single item that the algorithm is very confident about, but this means that recall would suffer. Ultimately, the best balance between precision and recall depends on the application.</p>
<p>Another issue with choosing metrics is the impossibility of reliably evaluating our choices. This is summarised well by Scott Berkun in his book <a href=http://scottberkun.com/yearwithoutpants/ target=_blank rel=noopener>The Year Without Pants</a>:</p>
<blockquote>
<p>All metrics create temptations. Even with great intentions and smart minds, data runs you faster and faster into a stupid self-destructive circle. Data can&rsquo;t decide things for you. It can help you see things more clearly if captured carefully, but that&rsquo;s not the same as deciding. Just as there is an advice paradox, there is a data paradox: no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.</p>
<p>Put another way, there is no good KPI for measuring KPIs. There are no good metrics for evaluating metrics (or for evaluating metrics for evaluating metrics for evaluating metrics, and on it goes).</p>
</blockquote>
<p>OK, so we&rsquo;ve picked some flawed measures that we can&rsquo;t really evaluate, and we&rsquo;ve accepted the imperfections of the evaluation process. Are we done yet? No. There&rsquo;s still the small matter of <a href="https://en.wikipedia.org/wiki/Goodhart's_law" target=_blank rel=noopener>Goodhart&rsquo;s Law</a>, which states that &ldquo;when a measure becomes a target, it ceases to be a good measure.&rdquo; This is often the case because people will tend to manipulate results and game the system (not necessarily maliciously) in order to hit measured goals. However, even without manipulation and gaming, we often deal with moving targets. Just because the measure we&rsquo;ve chosen is suitable today, it doesn&rsquo;t mean it will still be relevant in a few months or years because reality changes. For example, in the 1990s, the number of page views was a good measure of interaction with websites, but nowadays it is a pretty weak measure because many websites are single-page applications. Reality changes and so should our problems, solutions, measures, and goals.</p>
<h2 id=embracing-ambiguity-and-uncertainty>Embracing ambiguity and uncertainty<a hidden class=anchor aria-hidden=true href=#embracing-ambiguity-and-uncertainty>#</a></h2>
<p>Personally, I find the complexities of measurement and problem definition quite interesting. However, many people aren&rsquo;t that interested in this stuff – they just want working solutions and simple stories. As demonstrated by the examples throughout this article, over-simplification of complicated matters is a pervasive issue that goes beyond what&rsquo;s commonly considered &ldquo;data science&rdquo;. This is why storytelling is seen as a key skill that data scientists should possess. I believe it&rsquo;s also important to maintain one&rsquo;s integrity and not just make up stories that people would buy, but it&rsquo;d be naive to assume that this never happens. Either way, good data scientists embrace uncertainty and ambiguity, but can still tell a simple story if needed.</p>
<p><small><b>Note:</b> The ideas in this post were first presented at <a href=http://www.meetup.com/The-Sydney-Data-Science-Breakfast-Meetup-Group/ target=_blank rel=noopener>The Sydney Data Science Breakfast Meetup Group</a>. The slides for that talk are available <a href=http://yanirs.github.io/talks/the-hardest-part-of-data-science target=_blank rel=noopener>here</a>.</small></p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirseroussi.com/tags/climate-change/>climate change</a></li>
<li><a href=https://yanirseroussi.com/tags/data-science/>data science</a></li>
<li><a href=https://yanirseroussi.com/tags/kaggle/>Kaggle</a></li>
<li><a href=https://yanirseroussi.com/tags/predictive-modelling/>predictive modelling</a></li>
<li><a href=https://yanirseroussi.com/tags/science-communication/>science communication</a></li>
</ul>
<div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on twitter" href="https://twitter.com/intent/tweet/?text=The%20hardest%20parts%20of%20data%20science&url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&hashtags=climatechange%2cdatascience%2cKaggle%2cpredictivemodelling%2csciencecommunication"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&title=The%20hardest%20parts%20of%20data%20science&summary=The%20hardest%20parts%20of%20data%20science&source=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&title=The%20hardest%20parts%20of%20data%20science"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on whatsapp" href="https://api.whatsapp.com/send?text=The%20hardest%20parts%20of%20data%20science%20-%20https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share The hardest parts of data science on telegram" href="https://telegram.me/share/url?text=The%20hardest%20parts%20of%20data%20science&url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div>
</footer><section class=comment-section>
<strong>7 comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
<div class=comment-level-0 id=comment-881>
<div class=comment-header>
<a href=#comment-881>
<img class=comment-avatar src="https://www.gravatar.com/avatar/52588113ec3afb6f58179544ba5f23df?s=50">
<p class=comment-info>
<strong>RG</strong><br>
<small>2015-11-24 02:37:44</small>
</p>
</a>
</div>
<div class="comment-body post-content">
Excellent excellent common sense article which seems to be very uncommon nowadays in a hype-filled world. Thanks for reminding us that accurate problem description should trump everything else!
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-881&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-0 id=comment-897>
<div class=comment-header>
<a href=#comment-897>
<img class=comment-avatar src="https://www.gravatar.com/avatar/db015de93a5653d51295570f25580bc7?s=50">
<p class=comment-info>
<strong>Dalila</strong><br>
<small>2015-11-30 14:50:28</small>
</p>
</a>
</div>
<div class="comment-body post-content">
<p>Thank you for a great article. Yes, well defined problems and well defined performance evaluation are keys to designing any data driven model.</p>
<p>I also found that sometimes we have the question we want to pursue, but getting to an answer is not straight forward. For instance, I&rsquo;m trying to find
affinity between food ingredients using only data analytics. One may think that this problem is trivial. In fact, to find this, one has to totally rethink how to represent data (having ingredients in a table or a dataset produced nothing.) Yes finding affinity between 2 ingredients is trivial, but when the number grows up, one has to change the setting. In my case, I had to think of ingredients as part of a complete network, where the network is a recipe. It is then and only then, that I was able to find affinity between many ingredients.</p>
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-897&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-0 id=comment-905>
<div class=comment-header>
<a href=#comment-905>
<img class=comment-avatar src="https://www.gravatar.com/avatar/9a6fa828e494e8583e5450e34f0d999a?s=50">
<p class=comment-info>
<strong>andrew</strong><br>
<small>2015-12-04 00:29:33</small>
</p>
</a>
</div>
<div class="comment-body post-content">
Yes, many good points here, thanks for this. There is even another difficulty apart from problem definition and solution measurement: the semantics of the data itself. Are the definitions real (referring to other concepts) or nominal (&ldquo;a cheeseburger is a burger with cheese&rdquo;)? Scope and context can easily be lost, and can only be put back by a human being taking a decision, no amount of empirical modelling can re-discover this. Also precision and accuracy of the data may be unknown and/or insufficient to solve the problem posed. If you have detected these issues, sometimes you can re-formulate the problem,but typically its not clear from the column headings alone (if you even have these). Even worse, the definitions may be incoherent or nonsensical: eg in classical econometric modelling the definition of a rational agent entails that the agent have knowledge of the future!
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-905&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-1 id=comment-913>
<div class=comment-header>
<a href=#comment-913>
<img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50">
<p class=comment-info>
<strong>Yanir Seroussi</strong><br>
<small>2015-12-06 05:44:13</small>
</p>
</a>
</div>
<div class="comment-body post-content">
Thanks Andrew! I agree that often what you can do is very limited by the data. I&rsquo;ve also encountered cases where I had to infer meaning from cryptic column names. In many cases the small arbitrary decisions that we make along the way can have a major influence on the final results!
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-913&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-0 id=comment-919>
<div class=comment-header>
<a href=#comment-919>
<img class=comment-avatar src="https://www.gravatar.com/avatar/6a5c29f57bc8859bf771ca6b5980321a?s=50">
<p class=comment-info>
<strong>Arthur</strong><br>
<small>2015-12-08 00:28:04</small>
</p>
</a>
</div>
<div class="comment-body post-content">
<p>Is this article a Poe? The amount of muddled priors throughout it is disturbing. The word &ldquo;sophistry&rdquo; keeps leaping to mind. E.g.:</p>
<p>> For instance, if a government embarks on the building of a pyramid [&mldr;]
s/&ldquo;a government&rdquo;/Paris/g
s/pyramid/&ldquo;Eiffel Tower&rdquo;/g
How persuasive is Shostak now? Let&rsquo;s just ignore that, generally speaking, pyramids were for the glorification of a ruling class which elicited <em>no guidance</em> fr its populus.</p>
<p>> [&mldr;] no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.
No, I draw <em>conclusions from the data</em>, ponder the evidence, challenge the null hypothesis & take a reasoned position based on best available evidence, accordingly. Mere superstitious nonsense has no part of it. Has Berkun ever heard of the tautology fallacy? Hume&rsquo;s Fork? ISO/ANSI? I do so detest the implied anti-intellectualism of that block quote.</p>
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-919&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-1 id=comment-920>
<div class=comment-header>
<a href=#comment-920>
<img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50">
<p class=comment-info>
<strong>Yanir Seroussi</strong><br>
<small>2015-12-08 00:55:43</small>
</p>
</a>
</div>
<div class="comment-body post-content">
<p>Thank you for your comment, Arthur.</p>
<p>I don&rsquo;t think that replacing &ldquo;a government&rdquo; with Paris and pyramid with &ldquo;Eiffel Tower&rdquo; makes Shostak&rsquo;s argument any less convincing. The point still stands that the GDP measure is flawed because it can easily be manipulated through activities that don&rsquo;t contribute positively to society. Do you think that GDP growth is worth focusing on?</p>
<p>As to the Berkun quote, I suggest you read more of his writings before dismissing it. He is anything but superstitious and an anti-intellectual. Drawing conclusions from data, pondering the evidence, challenging the null hypothesis, and taking a reasoned position based on the best available evidence doesn&rsquo;t contradict depending on your intuition for deciding how to interpret and then apply the data. Intuition is often based on experience and data that hasn&rsquo;t been formally captured. For example, in Bayesian modelling you&rsquo;re free to use your intuition when setting priors, but the weight of these priors becomes smaller as evidence accumulates.</p>
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-920&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
<div class=comment-level-0 id=comment-1169>
<div class=comment-header>
<a href=#comment-1169>
<img class=comment-avatar src="https://www.gravatar.com/avatar/81c74d0e6e59ea3ca387bbeb85a78252?s=50">
<p class=comment-info>
<strong>Richard</strong><br>
<small>2016-04-10 11:00:58</small>
</p>
</a>
</div>
<div class="comment-body post-content">
Thank you Yansir! I found this post extremely enlightening. I was starting to question to what extent the value of a data scientist would be affected by the emergence of automated data cleaning and model building tools. It makes far more sense that the true value of the role is in the experimental design as opposed to applying algorithms.
</div>
<a class="comment-button comment-button-small" href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New reply to https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f%23comment-1169&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Reply via GitHub issue
</a>
</div>
</section>
</article>
</main>
<footer class=footer>
<span>© <a href=https://yanirseroussi.com/about/>Yanir Seroussi</a>  |</span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer><div class=mailing-list-container>
<form class=mailing-list action=https://tinyletter.com/yanir method=post target=popupwindow onsubmit="return window.open('https://tinyletter.com/yanir','popupwindow','scrollbars=yes,width=800,height=600'),!0">
<label for=mailing-list-email>Get new post notifications</label>
<input type=text name=email id=mailing-list-email placeholder="Email address">
<input type=hidden value=1 name=embed>
<input type=submit value=Subscribe>
</form>
</div>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>