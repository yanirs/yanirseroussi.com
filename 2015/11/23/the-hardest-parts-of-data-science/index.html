<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The hardest parts of data science | Yanir Seroussi – AI/ML Success Architect</title>
<meta name="keywords" content="climate change, data science, Kaggle, predictive modelling, science communication">
<meta name="description" content="Defining feasible problems and coming up with reasonable ways of measuring solutions is harder than building accurate models or obtaining clean data.">
<meta name="author" content="Yanir Seroussi">
<link rel="canonical" href="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/">
<meta name="google-site-verification" content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU">
<link crossorigin="anonymous" href="/assets/css/stylesheet.7d100fb77f29fb486fe457f33557e8cb59be0ee9b41107b079d00b3b4e52b30b.css" integrity="sha256-fRAPt38p&#43;0hv5FfzNVfoy1m&#43;Dum0EQewedALO05Ssws=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://yanirseroussi.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yanirseroussi.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yanirseroussi.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yanirseroussi.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://yanirseroussi.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/">
  <meta property="og:site_name" content="Yanir Seroussi – AI/ML Success Architect">
  <meta property="og:title" content="The hardest parts of data science">
  <meta property="og:description" content="Defining feasible problems and coming up with reasonable ways of measuring solutions is harder than building accurate models or obtaining clean data.">
  <meta property="og:locale" content="en-au">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2015-11-23T04:14:21+00:00">
    <meta property="article:modified_time" content="2024-01-16T09:56:03+10:00">
    <meta property="article:tag" content="Climate Change">
    <meta property="article:tag" content="Data Science">
    <meta property="article:tag" content="Kaggle">
    <meta property="article:tag" content="Predictive Modelling">
    <meta property="article:tag" content="Science Communication">
    <meta property="og:image" content="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg">
<meta name="twitter:title" content="The hardest parts of data science">
<meta name="twitter:description" content="Defining feasible problems and coming up with reasonable ways of measuring solutions is harder than building accurate models or obtaining clean data.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Browse Posts",
      "item": "https://yanirseroussi.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "The hardest parts of data science",
      "item": "https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The hardest parts of data science",
  "name": "The hardest parts of data science",
  "description": "Defining feasible problems and coming up with reasonable ways of measuring solutions is harder than building accurate models or obtaining clean data.",
  "keywords": [
    "climate change", "data science", "Kaggle", "predictive modelling", "science communication"
  ],
  "articleBody": "Contrary to common belief, the hardest part of data science isn’t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.\nThe not-so-hard parts Before discussing the hardest parts of data science, it’s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.\nModel fitting is seen by some as particularly hard, or as real data science. This belief is fuelled in part by the success of Kaggle, that calls itself the home of data science. Most Kaggle competitions are focused on model fitting: Participants are given a well-defined problem, a dataset, and a measure to optimise, and they compete to produce the most accurate model. Coupling Kaggle’s excellent marketing with their competition setup leads many people to believe that data science is all about fitting models. In reality, building reasonably-accurate models is not that hard, because many model-building phases can easily be automated. Indeed, there are many companies that offer model fitting as a service (e.g., Microsoft, Amazon, Google and others). Even Ben Hamner, CTO of Kaggle, has said that he is “surprised at the number of ‘black box machine learning in the cloud’ services emerging: model fitting is easy. Problem definition and data collection are not.”\nData collection/cleaning is the essential part that everyone loves to hate. DJ Patil (US Chief Data Scientist) is quoted as saying that “the hardest part of data science is getting good, clean data. Cleaning data is often 80% of the work.” While I agree that collecting data and cleaning it can be a lot of work, I don’t think of this part as particularly hard. It’s definitely important and may require careful planning, but in many cases it just isn’t very challenging. In addition, it is often the case that the data is already given, or is collected using previously-developed methods.\nProblem definition is hard There are many reasons why problem definition can be hard. It is sometimes due to stakeholders who don’t know what they want, and expect data scientists to solve all their data problems (either real or imagined). This type of situation is summarised by the following Dilbert strip. It is best handled by cleverly managing stakeholder expectations, while stirring them towards better-defined problems.\nWell-defined problems are great, for the obvious reason that they can actually be addressed. Examples of such problems include:\nBuild a model to predict the sales of a marketing campaign Create a system that runs campaigns that automatically adapt to customer feedback Identify key objects in images Improve click-through rates on search engine results, ads, or any other element Detect whale calls from underwater recordings to prevent collisions Often, it can be hard to get to the stage where the problem is agreed on, because this requires dealing with people who only have a fuzzy idea of what can be done with data science. Dilbertian situations aside, these people often have real problems that they care about, so exploring the core issues with them is time well-spent.\nSolution measurement is often harder than problem definition Many problems that actually matter have solutions that are really hard to measure. For example, improving the well-being of the population (e.g., a company’s customers or a country’s citizens) is an overarching problem that arises in many situations. However, this problem gives rise to the hard question of how well-being can be measured and aggregated. The following paragraphs discuss issues that occur in solution measurement, often making it the hardest part of data science.\nIdeally, we would always be able to run randomised controlled trials to measure treatment effects. However, the reality is that experimental data is often censored, there many constraints on running experiments (ethics, practicality, budget, etc.), and confounding factors may make it impossible to identify the true causal impact of interventions. These issues seriously influence many aspects of our lives. I’ve written a post on how these issues manifest themselves in research on the connection between nutrition and our health. Here, I’ll discuss another major example: the health effects of smoking and anthropogenic climate change.\nWhile smoking and anthropogenic climate change may seem unrelated, they actually have a lot in common. In both cases it is hard (or impossible) to perform experiments to determine causality, and in both cases this fact has been used to mislead the public by parties with commercial and ideological interests. In the case of smoking, due to ethical reasons, one can’t perform an experiment where a random control group is forced not to smoke, while a treatment group is forced to smoke. Further, since it can take many years for smoking-caused diseases to develop, it’d take a long time to obtain the results of such an experiment. Tobacco companies have exploited this fact for years, claiming that there may be some genetic factor that causes both smoking and a higher susceptibility to smoking-related diseases. Fortunately, we live in a world where these claims have been widely discredited, and it is now clear to most people that smoking is harmful. However, similar doubt-casting techniques are used by polluters and their supporters in the debate on anthropogenic climate change. While no serious climate scientist doubts the fact that human activities are causing climate change, this can’t be proved through experimentation on another Earth. In both cases, the answers should be clear when looking at the evidence and the mechanisms at play without an ideological bias. It doesn’t take a scientist to figure out that pumping your lungs full of smoke on a regular basis is likely to be harmful, as is pumping the atmosphere full of greenhouse gases that have been sequestered for millions of years. However, as said by Upton Sinclair, “it is difficult to get a man to understand something, when his salary depends upon his not understanding it.”\nAssuming that we have addressed the issues raised so far, there is the matter of choosing a measure or metric of success. How do we know that our solution works well? A common approach is to choose a single metric to focus on, such as increasing conversion rates. However, all metrics have their flaws, and there are quite a few problems with metric selection and its maintenance over time.\nFirst, focusing on a single metric can be harmful, because no metric is perfect. A classic example of this issue is the focus on growing the economy, as measured by gross domestic product (GDP). The article What is up with the GDP? by Frank Shostak summarises some of the problems with GDP:\nThe GDP framework cannot tell us whether final goods and services that were produced during a particular period of time are a reflection of real wealth expansion, or a reflection of capital consumption.\nFor instance, if a government embarks on the building of a pyramid, which adds absolutely nothing to the well-being of individuals, the GDP framework will regard this as economic growth. In reality, however, the building of the pyramid will divert real funding from wealth-generating activities, thereby stifling the production of wealth.\n[…]\nThe whole idea of GDP gives the impression that there is such a thing as the national output. In the real world, however, wealth is produced by someone and belongs to somebody. In other words, goods and services are not produced in totality and supervised by one supreme leader. This in turn means that the entire concept of GDP is devoid of any basis in reality. It is an empty concept.\nShostak’s criticism comes from a right-winged viewpoint – his argument is that the GDP is used as an excuse for unnecessary government intervention with the market. However, the focus on GDP growth is also heavily-criticised by the left due to the fact that it doesn’t consider environmental effects and inequalities in the distribution of wealth. It is a bit odd that GDP growth is still considered a worthwhile goal by many people, given that it can easily be skewed by a few powerful individuals who choose to build unnecessary pyramids (though perhaps this is the real reason why the GDP persists – wealthy individuals have an interest in keeping it this way).\nEven if we decide to use multiple metrics to evaluate our solution, our troubles aren’t over yet. Using multiple metrics often means that there are trade-offs between the different metrics. For example, with the precision and recall measures that are commonly used to evaluate the performance of search engines, it is rare to be able to increase both precision and recall at the same time. Precision is the percentage of relevant items out of those that have been returned, while recall is the percentage of relevant items that have been returned out of the overall number of relevant items. Hence, it is easy to artificially increase recall to 100% by always returning all the items in the database, but this would mean settling for near-zero precision. Similarly, one can increase precision by always returning a single item that the algorithm is very confident about, but this means that recall would suffer. Ultimately, the best balance between precision and recall depends on the application.\nAnother issue with choosing metrics is the impossibility of reliably evaluating our choices. This is summarised well by Scott Berkun in his book The Year Without Pants:\nAll metrics create temptations. Even with great intentions and smart minds, data runs you faster and faster into a stupid self-destructive circle. Data can’t decide things for you. It can help you see things more clearly if captured carefully, but that’s not the same as deciding. Just as there is an advice paradox, there is a data paradox: no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.\nPut another way, there is no good KPI for measuring KPIs. There are no good metrics for evaluating metrics (or for evaluating metrics for evaluating metrics for evaluating metrics, and on it goes).\nOK, so we’ve picked some flawed measures that we can’t really evaluate, and we’ve accepted the imperfections of the evaluation process. Are we done yet? No. There’s still the small matter of Goodhart’s Law, which states that “when a measure becomes a target, it ceases to be a good measure.” This is often the case because people will tend to manipulate results and game the system (not necessarily maliciously) in order to hit measured goals. However, even without manipulation and gaming, we often deal with moving targets. Just because the measure we’ve chosen is suitable today, it doesn’t mean it will still be relevant in a few months or years because reality changes. For example, in the 1990s, the number of page views was a good measure of interaction with websites, but nowadays it is a pretty weak measure because many websites are single-page applications. Reality changes and so should our problems, solutions, measures, and goals.\nEmbracing ambiguity and uncertainty Personally, I find the complexities of measurement and problem definition quite interesting. However, many people aren’t that interested in this stuff – they just want working solutions and simple stories. As demonstrated by the examples throughout this article, over-simplification of complicated matters is a pervasive issue that goes beyond what’s commonly considered “data science”. This is why storytelling is seen as a key skill that data scientists should possess. I believe it’s also important to maintain one’s integrity and not just make up stories that people would buy, but it’d be naive to assume that this never happens. Either way, good data scientists embrace uncertainty and ambiguity, but can still tell a simple story if needed.\nNote: The ideas in this post were first presented at The Sydney Data Science Breakfast Meetup Group. The slides for that talk are available here.\n",
  "wordCount" : "1983",
  "inLanguage": "en",
  "image":"https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg","datePublished": "2015-11-23T04:14:21Z",
  "dateModified": "2024-01-16T09:56:03+10:00",
  "author":{
    "@type": "Person",
    "name": "Yanir Seroussi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yanir Seroussi – AI/ML Success Architect",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yanirseroussi.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yanirseroussi.com/" accesskey="h" title="Yanir Seroussi – AI/ML Success Architect (Alt + H)">Yanir Seroussi – AI/ML Success Architect</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <button id="menu-trigger" aria-haspopup="menu" aria-label="Menu Button">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
                <line x1="3" y1="12" x2="21" y2="12"></line>
                <line x1="3" y1="6" x2="21" y2="6"></line>
                <line x1="3" y1="18" x2="21" y2="18"></line>
            </svg>
        </button>
        <ul class="menu hidden">
            <li>
                <a href="https://yanirseroussi.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/posts/" title="Writing">
                    <span>Writing</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/talks/" title="Speaking">
                    <span>Speaking</span>
                </a>
            </li>
            <li>
                <a href="https://yanirseroussi.com/consult/" title="Consulting">
                    <span>Consulting</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      The hardest parts of data science
    </h1>
    <div class="post-meta"><span title='2015-11-23 04:14:21 +0000 UTC'>November 23, 2015</span>

</div>
  </header> 
<figure class="entry-cover">
            <img loading="eager"
                srcset='https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hu_cd4c5887c82d45a.jpg 360w,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hu_83f17db669ceaaec.jpg 480w,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hu_4c25f7169d8fee75.jpg 720w,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hu_46e093f87351e256.jpg 1080w,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest_hu_bc15627245249214.jpg 1500w,https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg 1960w'
                src="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/foggy-random-forest.jpg"
                sizes="(min-width: 768px) 720px, 100vw"
                width="1960" height="597"
                alt="">
        
</figure>
  <div class="post-content"><p>Contrary to common belief, the hardest part of data science isn&rsquo;t building an accurate model or obtaining good, clean data. It is much harder to define feasible problems and come up with reasonable ways of measuring solutions. This post discusses some examples of these issues and how they can be addressed.</p>
<h2 id="the-not-so-hard-parts">The not-so-hard parts<a hidden class="anchor" aria-hidden="true" href="#the-not-so-hard-parts">#</a></h2>
<p>Before discussing the hardest parts of data science, it&rsquo;s worth quickly addressing the two main contenders: model fitting and data collection/cleaning.</p>
<p><strong>Model fitting</strong> is seen by some as particularly hard, or as <em>real</em> data science. This belief is fuelled in part by the success of <a href="https://www.kaggle.com/" target="_blank" rel="noopener">Kaggle</a>, that calls itself <em>the home of data science</em>. Most Kaggle competitions are focused on model fitting: Participants are given a well-defined problem, a dataset, and a measure to optimise, and they compete to produce the most accurate model. Coupling Kaggle&rsquo;s excellent marketing with their competition setup leads many people to believe that data science is all about fitting models. In reality, building reasonably-accurate models is not that hard, because many model-building phases can easily be automated. Indeed, there are many companies that offer model fitting as a service (e.g., Microsoft, Amazon, Google and <a href="http://www.shivonzilis.com/machineintelligence" target="_blank" rel="noopener">others</a>). Even Ben Hamner, CTO of Kaggle, has said that he is &ldquo;surprised at the number of &lsquo;black box machine learning in the cloud&rsquo; services emerging: model fitting is easy. Problem definition and data collection are not.&rdquo;</p>













  
    
      
    
  
    
      
    
  
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="https://twitter.com/benhamner/status/595850574999990274" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 569px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml_hu_75e63862ecad1c21.png 360w,
            
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml_hu_3d54e3f32f36e086.png 480w,
            
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml.png 569w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/ben-hamner-black-box-ml.png"
        
      
        alt="Ben Hamner tweet on black box ML in the cloud"loading="lazy"
    />
  </a>
</figure>

<p><strong>Data collection/cleaning</strong> is the essential part that everyone loves to hate. DJ Patil (US Chief Data Scientist) is <a href="http://codingvc.com/talk-summary-building-great-data-products" target="_blank" rel="noopener">quoted as saying</a> that &ldquo;the hardest part of data science is getting good, clean data. Cleaning data is often 80% of the work.&rdquo; While I agree that collecting data and cleaning it can be a lot of work, I don&rsquo;t think of this part as particularly hard. It&rsquo;s definitely important and may require careful planning, but in many cases it just isn&rsquo;t very challenging. In addition, it is often the case that the data is already given, or is collected using previously-developed methods.</p>
<h2 id="problem-definition-is-hard">Problem definition is hard<a hidden class="anchor" aria-hidden="true" href="#problem-definition-is-hard">#</a></h2>
<p>There are many reasons why problem definition can be hard. It is sometimes due to stakeholders who don&rsquo;t know what they want, and <a href="https://yanirseroussi.com/2015/08/24/you-dont-need-a-data-scientist-yet/">expect data scientists to solve all their data problems (either real or imagined)</a>. This type of situation is summarised by <a href="http://dilbert.com/strip/2012-07-29" target="_blank" rel="noopener">the following Dilbert strip</a>. It is best handled by cleverly managing stakeholder expectations, while stirring them towards better-defined problems.</p>













  
    
      
    
  
    
      
    
  
    
      
    
  
    
  
    
  
  
    
  
  
  



<figure>
  <a href="dilbert-big-data.jpg" target="_blank" rel="noopener">
    <img
      
        sizes="
          (min-width: 768px) 720px,
          100vw
        "
        srcset="
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu_ae6272c8d5946105.jpg 360w,
            
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu_74bebb7b4738c0bf.jpg 480w,
            
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu_9ef61812a6e5e72c.jpg 720w,
            
          
            
              https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data.jpg 904w,
            
          
        "
        
        
        
          src="https://yanirseroussi.com/2015/11/23/the-hardest-parts-of-data-science/dilbert-big-data_hu_51485ba6006e5ac3.jpg"
        
      
        alt="Dilbert big data"loading="lazy"
    />
  </a>
</figure>

<p>Well-defined problems are great, for the obvious reason that they can actually be addressed. Examples of such problems include:</p>
<ul>
<li>Build a model to predict the sales of a marketing campaign</li>
<li>Create a system that runs campaigns that automatically adapt to customer feedback</li>
<li>Identify key objects in images</li>
<li>Improve click-through rates on search engine results, ads, or any other element</li>
<li>Detect whale calls from underwater recordings to prevent collisions</li>
</ul>
<p>Often, it can be hard to get to the stage where the problem is agreed on, because this requires dealing with people who only have a fuzzy idea of what can be done with data science. Dilbertian situations aside, these people often have real problems that they care about, so exploring the core issues with them is time well-spent.</p>
<h2 id="solution-measurement-is-often-harder-than-problem-definition">Solution measurement is often harder than problem definition<a hidden class="anchor" aria-hidden="true" href="#solution-measurement-is-often-harder-than-problem-definition">#</a></h2>
<p>Many problems that actually matter have solutions that are really hard to measure. For example, improving the well-being of the population (e.g., a company&rsquo;s customers or a country&rsquo;s citizens) is an overarching problem that arises in many situations. However, this problem gives rise to the hard question of how well-being can be measured and aggregated. The following paragraphs discuss issues that occur in solution measurement, often making it the hardest part of data science.</p>
<p>Ideally, we would always be able to run <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial" target="_blank" rel="noopener">randomised controlled trials</a> to measure treatment effects. However, the reality is that <a href="https://en.wikipedia.org/wiki/Censoring_%28statistics%29" target="_blank" rel="noopener">experimental data is often censored</a>, there many constraints on running experiments (ethics, practicality, budget, etc.), and <a href="https://en.wikipedia.org/wiki/Confounding" target="_blank" rel="noopener">confounding factors</a> may make it impossible to identify the true causal impact of interventions. These issues seriously influence many aspects of our lives. I&rsquo;ve <a href="https://yanirseroussi.com/2015/10/19/nutritionism-and-the-need-for-complex-models-to-explain-complex-phenomena/">written a post on how these issues manifest themselves in research on the connection between nutrition and our health</a>. Here, I&rsquo;ll discuss another major example: the health effects of smoking and anthropogenic climate change.</p>
<p>While smoking and anthropogenic climate change may seem unrelated, they actually have a lot in common. In both cases it is hard (or impossible) to perform experiments to determine causality, and in both cases <a href="https://en.wikipedia.org/wiki/Merchants_of_Doubt" target="_blank" rel="noopener">this fact has been used to mislead the public by parties with commercial and ideological interests</a>. In the case of smoking, due to ethical reasons, one can&rsquo;t perform an experiment where a random control group is forced not to smoke, while a treatment group is forced to smoke. Further, since it can take many years for smoking-caused diseases to develop, it&rsquo;d take a long time to obtain the results of such an experiment. Tobacco companies have exploited this fact for years, claiming that there may be some genetic factor that causes both smoking and a higher susceptibility to smoking-related diseases. Fortunately, we live in a world where these claims have been widely discredited, and it is now clear to most people that smoking is harmful. However, similar doubt-casting techniques are used by polluters and their supporters in the debate on anthropogenic climate change. While no serious climate scientist doubts the fact that human activities are causing climate change, this can&rsquo;t be proved through experimentation on another Earth. In both cases, the answers should be clear when looking at the evidence and the mechanisms at play without an ideological bias. It doesn&rsquo;t take a scientist to figure out that pumping your lungs full of smoke on a regular basis is likely to be harmful, as is pumping the atmosphere full of greenhouse gases that have been sequestered for millions of years. However, as said by Upton Sinclair, &ldquo;it is difficult to get a man to understand something, when his salary depends upon his not understanding it.&rdquo;</p>
<p>Assuming that we have addressed the issues raised so far, there is the matter of choosing a measure or metric of success. How do we know that our solution works well? A common approach is to choose a single metric to focus on, such as increasing conversion rates. However, all metrics have their flaws, and there are quite a few problems with metric selection and its maintenance over time.</p>
<p>First, <strong>focusing on a single metric can be harmful</strong>, because no metric is perfect. A classic example of this issue is the focus on growing the economy, as measured by <a href="https://en.wikipedia.org/wiki/Gross_domestic_product" target="_blank" rel="noopener">gross domestic product (GDP)</a>. The article <a href="https://mises.org/library/what-gdp" target="_blank" rel="noopener">What is up with the GDP?</a> by Frank Shostak summarises some of the problems with GDP:</p>
<blockquote>
<p>The GDP framework cannot tell us whether final goods and services that were produced during a particular period of time are a reflection of real wealth expansion, or a reflection of capital consumption.</p>
<p>For instance, if a government embarks on the building of a pyramid, which adds absolutely nothing to the well-being of individuals, the GDP framework will regard this as economic growth. In reality, however, the building of the pyramid will divert real funding from wealth-generating activities, thereby stifling the production of wealth.</p>
<p>[&hellip;]</p>
<p>The whole idea of GDP gives the impression that there is such a thing as the national output. In the real world, however, wealth is produced by someone and belongs to somebody. In other words, goods and services are not produced in totality and supervised by one supreme leader. This in turn means that the entire concept of GDP is devoid of any basis in reality. It is an empty concept.</p></blockquote>
<p>Shostak&rsquo;s criticism comes from a right-winged viewpoint – his argument is that the GDP is used as an excuse for unnecessary government intervention with the market. However, the focus on GDP growth is also heavily-criticised by the left due to the fact that it doesn&rsquo;t consider environmental effects and inequalities in the distribution of wealth. It is a bit odd that GDP growth is still considered a worthwhile goal by many people, given that it can easily be skewed by a few powerful individuals who choose to build unnecessary pyramids (though perhaps this is the real reason why the GDP persists – wealthy individuals have an interest in keeping it this way).</p>
<p>Even if we decide to use <strong>multiple metrics</strong> to evaluate our solution, our troubles aren&rsquo;t over yet. Using multiple metrics often means that there are trade-offs between the different metrics. For example, with the <a href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank" rel="noopener">precision and recall</a> measures that are commonly used to evaluate the performance of search engines, it is rare to be able to increase both precision and recall at the same time. <em>Precision</em> is the percentage of relevant items out of those that have been returned, while <em>recall</em> is the percentage of relevant items that have been returned out of the overall number of relevant items. Hence, it is easy to artificially increase recall to 100% by always returning all the items in the database, but this would mean settling for near-zero precision. Similarly, one can increase precision by always returning a single item that the algorithm is very confident about, but this means that recall would suffer. Ultimately, the best balance between precision and recall depends on the application.</p>
<p>Another issue with choosing metrics is the impossibility of reliably evaluating our choices. This is summarised well by Scott Berkun in his book <a href="http://scottberkun.com/yearwithoutpants/" target="_blank" rel="noopener">The Year Without Pants</a>:</p>
<blockquote>
<p>All metrics create temptations. Even with great intentions and smart minds, data runs you faster and faster into a stupid self-destructive circle. Data can&rsquo;t decide things for you. It can help you see things more clearly if captured carefully, but that&rsquo;s not the same as deciding. Just as there is an advice paradox, there is a data paradox: no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.</p>
<p>Put another way, there is no good KPI for measuring KPIs. There are no good metrics for evaluating metrics (or for evaluating metrics for evaluating metrics for evaluating metrics, and on it goes).</p></blockquote>
<p>OK, so we&rsquo;ve picked some flawed measures that we can&rsquo;t really evaluate, and we&rsquo;ve accepted the imperfections of the evaluation process. Are we done yet? No. There&rsquo;s still the small matter of <a href="https://en.wikipedia.org/wiki/Goodhart's_law" target="_blank" rel="noopener">Goodhart&rsquo;s Law</a>, which states that &ldquo;when a measure becomes a target, it ceases to be a good measure.&rdquo; This is often the case because people will tend to manipulate results and game the system (not necessarily maliciously) in order to hit measured goals. However, even without manipulation and gaming, we often deal with moving targets. Just because the measure we&rsquo;ve chosen is suitable today, it doesn&rsquo;t mean it will still be relevant in a few months or years because reality changes. For example, in the 1990s, the number of page views was a good measure of interaction with websites, but nowadays it is a pretty weak measure because many websites are single-page applications. Reality changes and so should our problems, solutions, measures, and goals.</p>
<h2 id="embracing-ambiguity-and-uncertainty">Embracing ambiguity and uncertainty<a hidden class="anchor" aria-hidden="true" href="#embracing-ambiguity-and-uncertainty">#</a></h2>
<p>Personally, I find the complexities of measurement and problem definition quite interesting. However, many people aren&rsquo;t that interested in this stuff – they just want working solutions and simple stories. As demonstrated by the examples throughout this article, over-simplification of complicated matters is a pervasive issue that goes beyond what&rsquo;s commonly considered &ldquo;data science&rdquo;. This is why storytelling is seen as a key skill that data scientists should possess. I believe it&rsquo;s also important to maintain one&rsquo;s integrity and not just make up stories that people would buy, but it&rsquo;d be naive to assume that this never happens. Either way, good data scientists embrace uncertainty and ambiguity, but can still tell a simple story if needed.</p>
<p><small><b>Note:</b> The ideas in this post were first presented at <a href="http://www.meetup.com/The-Sydney-Data-Science-Breakfast-Meetup-Group/" target="_blank" rel="noopener">The Sydney Data Science Breakfast Meetup Group</a>. The slides for that talk are available <a href="http://yanirs.github.io/talks/the-hardest-part-of-data-science" target="_blank" rel="noopener">here</a>.</small></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://yanirseroussi.com/tags/climate-change/">Climate Change</a></li>
      <li><a href="https://yanirseroussi.com/tags/data-science/">Data Science</a></li>
      <li><a href="https://yanirseroussi.com/tags/kaggle/">Kaggle</a></li>
      <li><a href="https://yanirseroussi.com/tags/predictive-modelling/">Predictive Modelling</a></li>
      <li><a href="https://yanirseroussi.com/tags/science-communication/">Science Communication</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on x"
            href="https://x.com/intent/tweet/?text=The%20hardest%20parts%20of%20data%20science&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&amp;hashtags=climatechange%2cdatascience%2cKaggle%2cpredictivemodelling%2csciencecommunication">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&amp;title=The%20hardest%20parts%20of%20data%20science&amp;summary=The%20hardest%20parts%20of%20data%20science&amp;source=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f&title=The%20hardest%20parts%20of%20data%20science">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on whatsapp"
            href="https://api.whatsapp.com/send?text=The%20hardest%20parts%20of%20data%20science%20-%20https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on telegram"
            href="https://telegram.me/share/url?text=The%20hardest%20parts%20of%20data%20science&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share The hardest parts of data science on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=The%20hardest%20parts%20of%20data%20science&u=https%3a%2f%2fyanirseroussi.com%2f2015%2f11%2f23%2fthe-hardest-parts-of-data-science%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>

<a href="/contact/#mailing-list-email" target="_blank" aria-label="subscribe to mailing list" class="mailing-list-link" id="mailing-list-link">
  Subscribe
</a>

<script>
  
  const mailingListButton = document.getElementById("mailing-list-link");
  window.onscroll = function () {
    if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
      mailingListButton.style.visibility = "visible";
      mailingListButton.style.opacity = "1";
    } else {
      mailingListButton.style.visibility = "hidden";
      mailingListButton.style.opacity = "0";
    }
  };
</script>




<div class="mailing-list-container">
  <script src="https://f.convertkit.com/ckjs/ck.5.js"></script>
  <form
    class="mailing-list seva-form formkit-form"
    action="https://app.convertkit.com/forms/6549537/subscriptions"
    method="post"
    data-sv-form="6549537"
    data-uid="9157759fce"
    data-format="inline"
    data-version="5"
    data-options='{&#34;settings&#34;:{&#34;after_subscribe&#34;:{&#34;action&#34;:&#34;message&#34;,&#34;redirect_url&#34;:&#34;&#34;,&#34;success_message&#34;:&#34;Success! Now check your email to confirm your subscription.&#34;},&#34;recaptcha&#34;:{&#34;enabled&#34;:false},&#34;return_visitor&#34;:{&#34;action&#34;:&#34;show&#34;,&#34;custom_content&#34;:&#34;&#34;}},&#34;version&#34;:&#34;5&#34;}'
  >
    <div data-style="clean">
      <ul class="formkit-alert formkit-alert-error" data-element="errors" data-group="alert"></ul>
      <div data-element="fields" data-stacked="false">
        <label for="mailing-list-email">Get new posts in your mailbox</label>
        <input
          id="mailing-list-email"
          name="email_address"
          aria-label="Email address"
          placeholder="Email address"
          required=""
          type="email"
        >
        
        <button data-element="submit">Subscribe</button>
      </div>
    </div>
  </form>
  
  <div class="footer">
    Join hundreds of subscribers. No spam or AI-generated slop. Unsubscribe any time.
  </div>
  
</div>


<section class="comment-section">
  

  <p class="post-content contact-cta">
    Public comments are closed, but I love hearing from readers. Feel free to
    <a href="/contact/" target="_blank">contact me</a> with your thoughts.
  </p>

  
  
  
  
      
      
  
      
      
  
      
      
  
      
      
  
      
      
  
      
      
  
      
      
  

  
    
  <div class="comment-level-0" id="comment-881">
    <div class="comment-header">
      <a href="#comment-881">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/52588113ec3afb6f58179544ba5f23df?s=50">
        
        <p class="comment-info">
          <strong>RG</strong><br>
          <small>2015-11-24 02:37:44</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      Excellent excellent common sense article which seems to be very uncommon nowadays in a hype-filled world. Thanks for reminding us that accurate problem description should trump everything else!
    </div>
  </div>

    
  
    
  <div class="comment-level-0" id="comment-897">
    <div class="comment-header">
      <a href="#comment-897">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/db015de93a5653d51295570f25580bc7?s=50">
        
        <p class="comment-info">
          <strong>Dalila</strong><br>
          <small>2015-11-30 14:50:28</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      <p>Thank you for a great article.  Yes, well defined problems and well defined performance evaluation are keys to designing any data driven model.</p>
<p>I also found that sometimes we have the question we want to pursue, but getting to an answer is not straight forward.  For instance, I&rsquo;m trying to find
affinity between food ingredients using only data analytics.  One may think that this problem is trivial.  In fact, to find this, one has to totally rethink how to represent data (having ingredients in a table or a dataset produced nothing.)  Yes finding affinity between 2 ingredients is trivial, but when the number grows up, one has to change the setting.  In my case, I had to think of ingredients as part of a complete network, where the network is a recipe.  It is then and only then, that I was able to find affinity between many ingredients.</p>

    </div>
  </div>

    
  
    
  <div class="comment-level-0" id="comment-905">
    <div class="comment-header">
      <a href="#comment-905">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/9a6fa828e494e8583e5450e34f0d999a?s=50">
        
        <p class="comment-info">
          <strong>andrew</strong><br>
          <small>2015-12-04 00:29:33</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      Yes, many good points here, thanks for this. There is even another difficulty apart from problem definition and solution measurement:  the semantics of the data itself.  Are the definitions real (referring to other concepts) or nominal (&ldquo;a cheeseburger is a burger with cheese&rdquo;)? Scope and context can easily be lost,  and can only be put back by a human being taking a decision, no amount of empirical modelling can re-discover this. Also precision and accuracy of the data may be unknown and/or insufficient to solve the problem posed.  If you have detected these issues, sometimes you can re-formulate the problem,but typically its not clear from the column headings alone (if you even have these). Even worse, the definitions may be incoherent or nonsensical: eg in classical econometric modelling the definition of a rational agent entails that the agent have knowledge of the future!
    </div>
  </div>

    
      
  <div class="comment-level-1" id="comment-913">
    <div class="comment-header">
      <a href="#comment-913">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50">
        
        <p class="comment-info">
          <strong>Yanir Seroussi</strong><br>
          <small>2015-12-06 05:44:13</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      Thanks Andrew! I agree that often what you can do is very limited by the data. I&rsquo;ve also encountered cases where I had to infer meaning from cryptic column names. In many cases the small arbitrary decisions that we make along the way can have a major influence on the final results!
    </div>
  </div>

      
    
  
    
  <div class="comment-level-0" id="comment-919">
    <div class="comment-header">
      <a href="#comment-919">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/6a5c29f57bc8859bf771ca6b5980321a?s=50">
        
        <p class="comment-info">
          <strong>Arthur</strong><br>
          <small>2015-12-08 00:28:04</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      <p>Is this article a Poe? The amount of muddled priors throughout it is disturbing. The word &ldquo;sophistry&rdquo; keeps leaping to mind. E.g.:</p>
<p>&gt; For instance, if a government embarks on the building of a pyramid [&hellip;]
s/&ldquo;a government&rdquo;/Paris/g
s/pyramid/&ldquo;Eiffel Tower&rdquo;/g
How persuasive is Shostak now? Let&rsquo;s just ignore that, generally speaking, pyramids were for the glorification of a ruling class which elicited <em>no guidance</em> fr its populus.</p>
<p>&gt; [&hellip;]  no matter how much data you have, you still depend on your intuition for deciding how to interpret and then apply the data.
No, I draw <em>conclusions from the data</em>, ponder the evidence, challenge the null hypothesis &amp; take a reasoned position based on best available evidence, accordingly. Mere superstitious nonsense has no part of it. Has Berkun ever heard of the tautology fallacy? Hume&rsquo;s Fork? ISO/ANSI? I do so detest the implied anti-intellectualism of that block quote.</p>

    </div>
  </div>

    
      
  <div class="comment-level-1" id="comment-920">
    <div class="comment-header">
      <a href="#comment-920">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50">
        
        <p class="comment-info">
          <strong>Yanir Seroussi</strong><br>
          <small>2015-12-08 00:55:43</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      <p>Thank you for your comment, Arthur.</p>
<p>I don&rsquo;t think that replacing &ldquo;a government&rdquo; with Paris and pyramid with &ldquo;Eiffel Tower&rdquo; makes Shostak&rsquo;s argument any less convincing. The point still stands that the GDP measure is flawed because it can easily be manipulated through activities that don&rsquo;t contribute positively to society. Do you think that GDP growth is worth focusing on?</p>
<p>As to the Berkun quote, I suggest you read more of his writings before dismissing it. He is anything but superstitious and an anti-intellectual. Drawing conclusions from data, pondering the evidence, challenging the null hypothesis, and taking a reasoned position based on the best available evidence doesn&rsquo;t contradict depending on your intuition for deciding how to interpret and then apply the data. Intuition is often based on experience and data that hasn&rsquo;t been formally captured. For example, in Bayesian modelling you&rsquo;re free to use your intuition when setting priors, but the weight of these priors becomes smaller as evidence accumulates.</p>

    </div>
  </div>

      
    
  
    
  <div class="comment-level-0" id="comment-1169">
    <div class="comment-header">
      <a href="#comment-1169">
        
          <img class="comment-avatar" src="https://www.gravatar.com/avatar/81c74d0e6e59ea3ca387bbeb85a78252?s=50">
        
        <p class="comment-info">
          <strong>Richard</strong><br>
          <small>2016-04-10 11:00:58</small>
        </p>
      </a>
    </div>
    <div class="comment-body post-content">
      Thank you Yansir! I found this post extremely enlightening. I was starting to question to what extent the value of a data scientist would be affected by the emergence of automated data cleaning and model building tools. It makes far more sense that the true value of the role is in the experimental design as opposed to applying algorithms.
    </div>
  </div>

    
  
</section>

<p class="post-content data-webring">
  This site is a part of the <a href="https://randyau.github.io/datawebring/index.html" target="_blank" rel="noopener">Data People Writing Stuff</a> webring.
  <br>
  <a class="data-webring-previous-link" target="_blank" rel="noopener">← previous site</a>
  &nbsp; | &nbsp;
  <a class="data-webring-next-link" target="_blank" rel="noopener">next site →</a>
</p>

<script>
  
  
  function populateDataWebringLinks() {
    
    
    
    const sites = [
      'https://www.randyau.com/',
      'https://vickiboykis.com/',
      'https://www.counting-stuff.com/',
      'https://gecky.me/',
      'https://qethanm.cc/datawebring/',
      'https://mlops.systems/',
      'https://e2eml.school/',
      'https://blog.harterrt.com/',
      'https://www.jessemostipak.com/',
      'https://elliotgunn.github.io/',
      'https://radbrt.com',
      'https://simon.podhajsky.net/blog/',
      'https://www.heltweg.org/',
      'https://emilyriederer.com/',
      'https://kylestratis.com',
      
      
      'https://www.eamoncaddigan.net/',
      'https://karnwong.me/',
      'https://aino-spring.com/',
    ];

    
    
    
    function shuffle(a) {
      let j, x, i;
      for (i = a.length - 1; i > 0; i--) {
        j = Math.floor(Math.random() * (i + 1));
        x = a[i];
        a[i] = a[j];
        a[j] = x;
      }
    }

    shuffle(sites);

    document.querySelector('.data-webring-previous-link').href = sites[0];
    document.querySelector('.data-webring-next-link').href = sites[1];
  }

  populateDataWebringLinks();
</script>


</article>
    </main>
    <div class="global-footer">
  <div class="footer">
    <span>Text and figures licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener">CC BY-NC-ND 4.0</a> by <a href="https://yanirseroussi.com/about/">Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
    <span>
      Powered by
      <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
      <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
  </div>
</div>

<script>
  
  const menuTrigger = document.querySelector("#menu-trigger");
  const menuElem = document.querySelector(".menu");
  menuTrigger.addEventListener("click", function () {
    menuElem.classList.toggle("hidden");
  });
  document.body.addEventListener('click', function (event) {
    if (!menuTrigger.contains(event.target)) {
      menuElem.classList.add("hidden");
    }
  });
</script>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
