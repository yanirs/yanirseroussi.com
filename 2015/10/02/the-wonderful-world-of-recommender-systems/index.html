<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The wonderful world of recommender systems | Yanir Seroussi | Data & AI for Startup Impact</title>
<meta name=keywords content="data science,machine learning,predictive modelling,recommender systems,software engineering"><meta name=description content="Giving an overview of the field and common paradigms, and debunking five common myths about recommender systems."><meta name=author content="Yanir Seroussi"><link rel=canonical href=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/><meta name=google-site-verification content="aWlue7NGcj4dQpjOKJF7YKiAvw3JuHnq6aFqX6VwWAU"><link crossorigin=anonymous href=/assets/css/stylesheet.aae7b8d6eabaa881f37800d50b4d8604e83f1b3aa14069aaa7e0db30a27839d7.css integrity="sha256-que41uq6qIHzeADVC02GBOg/GzqhQGmqp+DbMKJ4Odc=" rel="preload stylesheet" as=style><link rel=icon href=https://yanirseroussi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yanirseroussi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yanirseroussi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://yanirseroussi.com/apple-touch-icon.png><link rel=mask-icon href=https://yanirseroussi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="The wonderful world of recommender systems"><meta property="og:description" content="Giving an overview of the field and common paradigms, and debunking five common myths about recommender systems."><meta property="og:type" content="article"><meta property="og:url" content="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/"><meta property="og:image" content="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-10-02T05:25:57+00:00"><meta property="article:modified_time" content="2024-01-16T09:56:03+10:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe.jpg"><meta name=twitter:title content="The wonderful world of recommender systems"><meta name=twitter:description content="Giving an overview of the field and common paradigms, and debunking five common myths about recommender systems."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Browse Posts","item":"https://yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"The wonderful world of recommender systems","item":"https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The wonderful world of recommender systems","name":"The wonderful world of recommender systems","description":"Giving an overview of the field and common paradigms, and debunking five common myths about recommender systems.","keywords":["data science","machine learning","predictive modelling","recommender systems","software engineering"],"articleBody":"I recently gave a talk about recommender systems at the Data Science Sydney meetup (the slides are available here). This post roughly follows the outline of the talk, expanding on some of the key points in non-slide form (i.e., complete sentences and paragraphs!). The first few sections give a broad overview of the field and the common recommendation paradigms, while the final part is dedicated to debunking five common myths about recommender systems.\nMotivation: Why should we care about recommender systems? The key reason why many people seem to care about recommender systems is money. For companies such as Amazon, Netflix, and Spotify, recommender systems drive significant engagement and revenue. But this is the more cynical view of things. The reason these companies (and others) see increased revenue is because they deliver actual value to their customers – recommender systems provide a scalable way of personalising content for users in scenarios with many items.\nAnother reason why data scientists specifically should care about recommender systems is that it is a true data science problem. That is, at least according to my favourite definition of data science as the intersection between software engineering, machine learning, and statistics. As we will see, building successful recommender systems requires all of these skills (and more).\nDefining recommender systems When trying to the define anything, a reasonable first step is to ask Wikipedia. Unfortunately, as of the day of this post’s publication, Wikipedia defines recommender systems too narrowly, as “a subclass of information filtering system that seek to predict the ‘rating’ or ‘preference’ that a user would give to an item” (I should probably fix it, but this wrong definition helped my talk flow better – let me know if you fix it and I’ll update this paragraph).\nThe problem with Wikipedia’s definition is that there’s so much more to recommender systems than rating prediction. First, recommender is a misnomer – calling it a discovery assistant is better, as the so-called recommendations are far from binding. Second, system means that elements like presentation are important, which is part of what makes recommendation such an interesting data science problem.\nMy definition is simply:\nRecommender systems are systems that help users discover items they may like. Recommendation paradigms Depending on who you ask, there are between two and twenty different recommendation paradigms. The usual classification is by the type of data that is used to generate recommendations. The distinction between approaches is more academic than practical, as it is often a good idea to use hybrids/ensembles to address each method’s limitations. Nonetheless, it is worthwhile discussing the different paradigms. The way I see it, if you ignore trivial approaches that often work surprisingly well (e.g., popular items, and “watch it again”), there are four main paradigms: collaborative filtering, content-based, social/demographic, and contextual recommendation.\nCollaborative filtering is perhaps the most famous approach to recommendation, to the point that it is sometimes seen as synonymous with the field. The main idea is that you’re given a matrix of preferences by users for items, and these are used to predict missing preferences and recommend items with high predictions. One of the key advantages of this approach is that there has been a huge amount of research into collaborative filtering, making it pretty well-understood, with existing libraries that make implementation fairly straightforward. Another important advantage is that collaborative filtering is independent of item properties. All you need to get started is user and item IDs, and some notion of preference by users for items (ratings, views, etc.).\nThe major limitation of collaborative filtering is its reliance on preferences. In a cold-start scenario, where there are no preferences at all, it can’t generate any recommendations. However, cold starts can also occur when there are millions of available preferences, because pure collaborative recommendation doesn’t work for items or users with no ratings, and often performs pretty poorly when there are only a few ratings. Further, the underlying collaborative model may yield disappointing results when the preference matrix is sparse. In fact, this has been my experience in nearly every situation where I deployed collaborative filtering. It always requires tweaking, and never simply works out of the box.\nContent-based algorithms are given user preferences for items, and recommend similar items based on a domain-specific notion of item content. The main advantage of content-based recommendation over collaborative filtering is that it doesn’t require as much user feedback to get going. Even one known user preference can yield many good recommendations (which can lead to the collection of preferences to enable collaborative recommendation). In many scenarios, content-based recommendation is the most natural approach. For example, when recommending news articles or blog posts, it’s natural to compare the textual content of the items. This approach also extends naturally to cases where item metadata is available (e.g., movie stars, book authors, and music genres).\nOne problem with deploying content-based recommendations arises when item similarity is not so easily defined. However, even when it is natural to measure similarity, content-based recommendations may end up being too homogeneous to be useful. Such recommendations may also be too static over time, thereby failing to adjust to changes in individual user tastes and other shifts in the underlying data.\nSocial and demographic recommenders suggest items that are liked by friends, friends of friends, and demographically-similar people. Such recommenders don’t need any preferences by the user to whom recommendations are made, making them very powerful. In my experience, even trivially-implemented approaches can be depressingly accurate. For example, just summing the number of Facebook likes by a person’s close friends can often be enough to paint a pretty accurate picture of what that person likes.\nGiven this power of social and demographic recommenders, it isn’t surprising that social networks don’t easily give their data away. This means that for many practitioners, employing social/demographic recommendation algorithms is simply impossible. However, even when such data is available, it is not always easy to use without creeping users out. Further, privacy concerns need to be carefully addressed to ensure that users are comfortable with using the system.\nContextual recommendation algorithms recommend items that match the user’s current context. This allows them to be more flexible and adaptive to current user needs than methods that ignore context (essentially giving the same weight to all of the user’s history). Hence, contextual algorithms are more likely to elicit a response than approaches that are based only on historical data.\nThe key limitations of contextual recommenders are similar to those of social and demographic recommenders – contextual data may not always be available, and there’s a risk of creeping out the user. For example, ad retargeting can be seen as a form of contextual recommendation that follows users around the web and across devices, without having the explicit consent of the users to being tracked in this manner.\nFive common myths about recommender systems There are some common myths and misconceptions surrounding recommender systems. I’ve picked five to address in this post. If you disagree, agree, or have more to add, I would love to hear from you either privately or in the comment section.\nThe accuracy myth\nOffline optimisation of an accuracy measure is sufficient for creating a successful recommender\nReality\nUsers don't really care about accuracy This is perhaps the most prevalent myth of all, as evidenced by Wikipedia’s definition of recommender systems. It’s somewhat surprising that it still persists, as it’s been almost ten years since McNee et al.’s influential paper on the damage the focus on accuracy measures has done to the field.\nIt is therefore worth asking where this myth came from. My theory is that it is a feedback loop between academia and industry. In academia it is pretty easy to publish papers with infinitesimal improvements to arbitrary accuracy measures on offline datasets (I’m also guilty of doing just that), while it’s relatively hard to run experiments on live systems. However, one of the moves that significantly increased focus on offline predictive accuracy came from industry, in the form of the $1M Netflix prize, where the goal was to improve the accuracy of Netflix’s rating prediction algorithm by 10%.\nNotably, most of the algorithms that came out of the three-year competition were never integrated into Netflix. As discussed on the Netflix blog:\nYou might be wondering what happened with the final Grand Prize ensemble that won the $1M two years later… We evaluated some of the new methods offline but the additional accuracy gains that we measured did not seem to justify the engineering effort needed to bring them into a production environment.\nOur business objective is to maximize member satisfaction and month-to-month subscription retention… Now it is clear that the Netflix Prize objective, accurate prediction of a movie’s rating, is just one of the many components of an effective recommendation system that optimizes our members’ enjoyment.\nThe following chart says it all (taken from the second part of the blog post quoted above):\nAn important question that arises is: If users don’t really care about predictive accuracy, what do they care about? The answer is that predictive accuracy has some importance (as evidenced by the above chart), but it is not the only thing. In my opinion, the key consideration is UI/UX. You can have the most accurate recommendations in the world, but no one would know about it (or care) if they are not served in a timely manner through a friendly interface.\nOf course, even with a great user interface and accurate predictions, there are other issues that require attention when designing recommender systems. Examples include diversity (showing various types of items), serendipity/novelty (showing non-obvious recommendations that users don’t already know about), and coverage (being able to generate recommendations for all users and items). Many other considerations are covered in an excellent survey by Guy Shani and Asela Gunawardana.\nIt’s also worth noting that there is an inherent problem with common accuracy measures. Specifically, when using a measure like root mean square error, a rating prediction algorithm can be made to perform better by reducing errors on low ratings. This is rather pointless, because items with low ratings will not be shown to users in any case.\nFinally, a key issue that arises with offline evaluation is that there are biases in offline datasets that do not necessarily carry over to online scenarios. For instance, in many cases there is an implicit assumption that data is missing at random, when it really isn’t, e.g., the fact that users took the effort to watch and rate a movie already tells us a lot about a bias they have towards this movie (the team that won the Netflix prize used this bias to their advantage). Hiding this rating and trying to predict it is not the same as predicting a rating for a movie that is picked at random from the entire set of movies.\nThe black box myth\nYou can build successful recommender systems without worrying about what's being recommended and how recommendations are being served\nReality\nUI/UX is king, item type is critical A good recommender system has to consider how users interact with the recommendations. For example, the number of displayed recommendations should inform the optimisation procedure (e.g., are you aiming for precision@1 or precision@10?). How these recommendations are laid out (e.g., horizontally/vertically) tends to influence user interaction. In addition, being able to explain the reasons for the recommendations can yield easy wins. Finally, in many cases there are constraints on the amount of time that can be spent generating recommendations.\nIn addition to UI/UX, the design of good recommender systems has to account for what’s being recommended. For example, music tracks and short videos can be played many times, so it’s probably a good idea to recommend items that the user has already seen. On the other hand, items like washing machines and cars don’t get consumed as often. If a user has just bought a washing machine, they’re unlikely to want another one anytime soon (but they may want a dryer or a clothes line).\nHynt is a recommender-system-as-a-service for e-commerce whose development I led up until the middle of last year. The general idea is that merchants simply add a few lines of JavaScript to their shop pages and Hynt does the hard work of recommending relevant items from the store, while considering the user and page context. Going live with Hynt reaffirmed many well-known UI/UX lessons. Most notably:\nAbove the fold is better than below. Engagement with Hynt widgets that were visible without scrolling was higher than those that were lower on the page. More recommendations are better than a few. Hynt widgets are responsive, adapting to the size of the container they’re placed in. Engagement was more likely when more recommendations were displayed, because users were more likely to find something they liked without scrolling through the widget. Fast is better than slow. If recommendations load faster, more people see them, which increases engagement. In Hynt’s case speed was especially important because the widgets load asynchronously after the host page finishes loading. Another important UI/UX element is explanations. Displaying a plausible explanation next to a recommendation can do wonders, without making any changes to the underlying recommendation algorithms. The impact of explanations has been studied extensively by Nava Tintarev and Judith Masthoff. They have identified seven different aims of explanations, which are summarised in the following table (reproduced from their survey of explanations in recommender systems).\nAim Definition Transparency Explain how the system works Scrutability Allow users to tell the system it is wrong Trust Increase user confidence in the system Effectiveness Help users make good decisions Persuasiveness Convince users to try or buy Efficiency Help users make decisions faster Satisfaction Increase ease of usability or enjoyment Explanations are ubiquitous in real-world recommender systems. For example, Amazon uses explanations like “frequently bought together”, and “customers who bought this item also bought”, while Netflix presents different lists of recommendations where each list is driven by a different reason. However, as the following Netflix example shows, it is worth making sure that the explanations you provide don’t make you look stupid.\nThe solved problem myth\nThe space of recommender systems has been exhaustively explored\nReality\nDevelopment of new methods is often required When I finished my PhD, about three years ago, I joined a small startup called Giveable as the first employee (essentially part of the founding team that was formed after Adam Neumann, the original founder, graduated from AngelCube and raised some seed funding). Giveable’s original product was a webapp where users could connect with their Facebook account and find gifts for their friends.\nAt the time, there wasn’t much published research on gift recommendation, and there was more or less nothing about the specific problem of recommending gifts for Facebook friends using liked pages. Here are some of the ways this problem differs from classic recommendation scenarios.\nNeed to consider giver and receiver. Unlike traditional scenarios, the recommended items aren’t consumed by the user to whom they’re shown. In practice, this meant that we had to ensure the items are giftable, and take into account the relationship between the giver and the receiver. For example, the type of gift your mum may give you is different from gifts your partner may give you. Likes are historical, sparse, and often nonsensical. This is best illustrated by an example: What does liking a page such as Tony Abbott – Worst PM in Australian History tell us about gifts the user may like? Tony Abbott is no longer prime minister (thankfully), so it’s historical, and while this page is quite popular, there are many other pages out there that are difficult to interpret and are liked by only a handful of people (this video is a good summary of why Tony is disliked, for those who are unfamiliar with Australian politics). Likes are not for recommended items. As the above example shows, just because you like disliking Tony, it doesn’t exactly lead to useful gifts. Even with things that are more related to interests, such as authors and bands, the liked pages aren’t recommendable as gifts. Likes are not always available offline. This was an important engineering consideration: We didn’t have much time to generate recommendations from the point where a new user gave us permission to view their likes and the likes of their friends. Ideally, recommendation generation would take less than a second from the time we got all the data from Facebook. This puts a strong constraint on the types of algorithms we could use. The key to effectively addressing the Giveable recommendation problem was doing as much processing offline as possible. Specifically:\nSimilar pages were inferred using Latent Dirichlet Allocation (which can be seen as a collaborative filtering technique). This made it possible to use information from pages that are not directly linked to giftable products, e.g., for the above Tony Abbott example, people who dislike him are likely to be left-leaning, which implies many other interests. Facebook pages were matched to giftable products with heuristics + Mechanical Turk + machine learning. This took a few iterations of what was essentially partly-manual semi-supervised learning, where we obtained high-confidence matches through heuristics and manual tagging, and then used this to train a classifier that was used to classify uncertain matches. The results of classification on a hold-out set were then verified through manual tagging of subsamples. We enriched the page and product data with structured information from the Freebase knowledge graph (which has since been deprecated). This allowed us to easily match giftable products to liked pages, e.g., books to authors. The online part included taking a receiver’s liked pages, inferring likes for similar pages, and matching all these pages to a ranked and diversified list of giftable product recommendations. These recommendations came with explanations, which were quite important in this case because the giver of a gift has to know why they’re giving it.\nThe silver bullet myth\nOptimising a single measure or using a single algorithm is sufficient for generating a good recommendation list\nReality\nHybrids work best Netflix provides another example for how focusing on a single algorithm or measure of success is far from sufficient. In a recent blog post, they talk about how they use multiple algorithms to optimise the order of different recommendation lists and each list’s internal ranking, while considering device-specific UI constraints, relevance, engagement, diversity, business requirements, and more.\nAn example from my experience comes from Giveable (which ended up evolving into Hynt), where a single list was generated by mixing the outputs of the following recommendation approaches: contextual, direct likes, inferred likes, content-based, social, collaborative filtering of products, previously viewed items, and popular interests/products. The weight of each algorithm in the mix was static – it was either set manually or through A/B testing, and then left as a hardcoded constant.\nThis kind of static mix can get you very far, but there’s a better way that I haven’t gotten around to implementing before leaving to work on other things. This way is described in a series of posts on bandits for recommenders by Sergey Feldman of RichRelevance. The general idea is to train recommendation models offline using a small number of strategies/paradigms. Online, recommendations are served from strategies that maximise clickthrough and revenue, given a context of features that describe the user, merchant, and web page where the RichRelevance widget is embedded. Rather than setting static weights for the strategies, the bandit model continuously adjusts the weights, while balancing between exploring new strategy weights and exploiting strategies that have been known to work well in a specific context. This allows the overall recommendation engine to adjust to changes in reality and in the underlying data.\nThe omnipresence myth\nEvery personalised system is a recommender system\nReality\nThis one is kinda true, but not necessarily useful... The first conference I attended as a PhD student was the 18th International Conference on User Modeling, Adaptation and Personalization (UMAP), back in 2010. The field of recommender systems was getting increased attention, and Peter Brusilovsky, who has been working in the UMAP field for decades, argued that recommender systems are the new expert systems. This was partly because the hype was causing people to broaden the definition of the field to allow them to say that they’re working on recommender systems.\nI don’t think it’s incorrect that personalisation and recommender systems are different things. However, one problem that this may cause is making people think that common recommendation techniques would apply in scenarios where they’re unlikely to work. For example, web search can be seen as a recommender system for pages that gives a high weight to the user’s intent, as captured by the query. Hence, when personalising web search, it seems sensible to use collaborative filtering techniques. This was indeed my experience with the Yandex search personalisation competition: employing a matrix factorisation approach that was inspired by collaborative filtering turned out to be a waste of time compared to domain-specific methods.\nIn conclusion, recommenders are about as murky as data science. Just like data science, the boundaries of recommender systems are hard to define and they are sometimes over-hyped. This hype may lead to people investing in a recommender system they don’t really need, just like the common issue of premature investment in data science. However, the hype is based on real value, which can definitely be delivered by recommender systems when they are used correctly.\n","wordCount":"3577","inLanguage":"en","image":"https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe.jpg","datePublished":"2015-10-02T05:25:57Z","dateModified":"2024-01-16T09:56:03+10:00","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data \u0026 AI for Startup Impact","logo":{"@type":"ImageObject","url":"https://yanirseroussi.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data & AI for Startup Impact (Alt + H)">Yanir Seroussi | Data & AI for Startup Impact</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><button id=menu-trigger aria-haspopup=menu aria-label="Menu Button"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><ul class="menu hidden"><li><a href=https://yanirseroussi.com/about/ title=About><span>About</span></a></li><li><a href=https://yanirseroussi.com/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://yanirseroussi.com/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://yanirseroussi.com/consult/ title=Consulting><span>Consulting</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">The wonderful world of recommender systems</h1><div class=post-meta><span title='2015-10-02 05:25:57 +0000 UTC'>October 2, 2015</span></div></header><figure class=entry-cover><img loading=eager srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe_hu194975773615667364.jpg 360w ,https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe_hu11817484941306126095.jpg 480w ,https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe_hu12835472225657309981.jpg 720w ,https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe_hu3663975827953547593.jpg 1080w ,https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe_hu13525262427519218380.jpg 1500w ,https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe.jpg 4961w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/recommender-universe.jpg alt width=4961 height=2468></figure><div class=post-content><p>I recently gave a talk about recommender systems at the <a href=http://www.meetup.com/Data-Science-Sydney/ target=_blank rel=noopener>Data Science Sydney meetup</a> (the slides are available <a href=http://yanirs.github.io/talks/the-wonderful-world-of-recommender-systems target=_blank rel=noopener>here</a>). This post roughly follows the outline of the talk, expanding on some of the key points in non-slide form (i.e., complete sentences and paragraphs!). The first few sections give a broad overview of the field and the common recommendation paradigms, while the final part is dedicated to debunking five common myths about recommender systems.</p><h3 id=motivation-why-should-we-care-about-recommender-systems>Motivation: Why should we care about recommender systems?<a hidden class=anchor aria-hidden=true href=#motivation-why-should-we-care-about-recommender-systems>#</a></h3><p>The key reason why many people seem to care about recommender systems is <em>money</em>. For companies such as Amazon, Netflix, and Spotify, recommender systems drive significant engagement and revenue. But this is the more cynical view of things. The reason these companies (and others) see increased revenue is because they deliver actual <em>value</em> to their customers – recommender systems provide a scalable way of personalising content for users in scenarios with many items.</p><p>Another reason why data scientists specifically should care about recommender systems is that it is a true data science problem. That is, at least according to <a href=https://yanirseroussi.com/2014/10/23/what-is-data-science/>my favourite definition of data science</a> as the intersection between software engineering, machine learning, and statistics. As we will see, building successful recommender systems requires all of these skills (and more).</p><h3 id=defining-recommender-systems>Defining recommender systems<a hidden class=anchor aria-hidden=true href=#defining-recommender-systems>#</a></h3><p>When trying to the define anything, a reasonable first step is to ask Wikipedia. Unfortunately, as of the day of this post&rsquo;s publication, <a href=http://en.wikipedia.org/wiki/Recommender_system target=_blank rel=noopener>Wikipedia defines recommender systems too narrowly</a>, as &ldquo;a subclass of information filtering system that seek to predict the ‘rating&rsquo; or ‘preference&rsquo; that a user would give to an item&rdquo; (I should probably fix it, but this wrong definition helped my talk flow better – let me know if you fix it and I&rsquo;ll update this paragraph).</p><p>The problem with Wikipedia&rsquo;s definition is that there&rsquo;s so much more to recommender systems than rating prediction. First, <em>recommender</em> is a misnomer – calling it a discovery assistant is better, as the so-called recommendations are far from binding. Second, <em>system</em> means that elements like presentation are important, which is part of what makes recommendation such an interesting data science problem.</p><p>My definition is simply:</p><p class=highlight-box><i>Recommender systems are systems that help users discover items they may like.</i></p><h3 id=recommendation-paradigms>Recommendation paradigms<a hidden class=anchor aria-hidden=true href=#recommendation-paradigms>#</a></h3><p>Depending on who you ask, there are between two and twenty different recommendation paradigms. The usual classification is by the type of data that is used to generate recommendations. The distinction between approaches is more academic than practical, as it is often a good idea to use hybrids/ensembles to address each method&rsquo;s limitations. Nonetheless, it is worthwhile discussing the different paradigms. The way I see it, if you ignore trivial approaches that often work surprisingly well (e.g., popular items, and &ldquo;watch it again&rdquo;), there are four main paradigms: collaborative filtering, content-based, social/demographic, and contextual recommendation.</p><p><strong>Collaborative filtering</strong> is perhaps the most famous approach to recommendation, to the point that it is sometimes seen as synonymous with the field. The main idea is that you&rsquo;re given a matrix of preferences by users for items, and these are used to predict missing preferences and recommend items with high predictions. One of the key advantages of this approach is that there has been a huge amount of research into collaborative filtering, making it pretty well-understood, with existing libraries that make implementation fairly straightforward. Another important advantage is that collaborative filtering is independent of item properties. All you need to get started is user and item IDs, and some notion of preference by users for items (ratings, views, etc.).</p><p>The major limitation of collaborative filtering is its reliance on preferences. In a cold-start scenario, where there are no preferences at all, it can&rsquo;t generate any recommendations. However, cold starts can also occur when there are millions of available preferences, because pure collaborative recommendation doesn&rsquo;t work for items or users with no ratings, and <a href=https://dl.dropboxusercontent.com/u/25632965/SeroussiBohnertZukerman2011.pdf target=_blank rel=noopener>often performs pretty poorly when there are only a few ratings</a>. Further, the underlying collaborative model may yield disappointing results when the preference matrix is sparse. In fact, this has been my experience in <a href=https://yanirseroussi.com/2014/09/19/bandcamp-recommendation-and-discovery-algorithms/>nearly every situation where I deployed collaborative filtering</a>. It always requires tweaking, and never simply works out of the box.</p><p><strong>Content-based</strong> algorithms are given user preferences for items, and recommend similar items based on a domain-specific notion of item content. The main advantage of content-based recommendation over collaborative filtering is that it doesn&rsquo;t require as much user feedback to get going. Even one known user preference can yield many good recommendations (which can lead to the collection of preferences to enable collaborative recommendation). In many scenarios, content-based recommendation is the most natural approach. For example, when recommending news articles or blog posts, it&rsquo;s natural to compare the textual content of the items. This approach also extends naturally to cases where item metadata is available (e.g., movie stars, book authors, and music genres).</p><p>One problem with deploying content-based recommendations arises when item similarity is not so easily defined. However, even when it is natural to measure similarity, content-based recommendations may end up being too homogeneous to be useful. Such recommendations may also be too static over time, thereby failing to adjust to changes in individual user tastes and other shifts in the underlying data.</p><p><strong>Social and demographic</strong> recommenders suggest items that are liked by friends, friends of friends, and demographically-similar people. Such recommenders don&rsquo;t need any preferences by the user to whom recommendations are made, making them very powerful. In my experience, even trivially-implemented approaches can be depressingly accurate. For example, just summing the number of Facebook likes by a person&rsquo;s close friends can often be enough to paint a pretty accurate picture of what that person likes.</p><p>Given this power of social and demographic recommenders, it isn&rsquo;t surprising that social networks don&rsquo;t easily give their data away. This means that for many practitioners, employing social/demographic recommendation algorithms is simply impossible. However, even when such data is available, it is not always easy to use without creeping users out. Further, privacy concerns need to be carefully addressed to ensure that users are comfortable with using the system.</p><p><strong>Contextual</strong> recommendation algorithms recommend items that match the user&rsquo;s current context. This allows them to be more flexible and adaptive to current user needs than methods that ignore context (essentially giving the same weight to all of the user&rsquo;s history). Hence, contextual algorithms are more likely to elicit a response than approaches that are based only on historical data.</p><p>The key limitations of contextual recommenders are similar to those of social and demographic recommenders – contextual data may not always be available, and there&rsquo;s a risk of creeping out the user. For example, <a href=https://en.wikipedia.org/wiki/Behavioral_retargeting target=_blank rel=noopener>ad retargeting</a> can be seen as a form of contextual recommendation that follows users around the web and across devices, without having the explicit consent of the users to being tracked in this manner.</p><h3 id=five-common-myths-about-recommender-systems>Five common myths about recommender systems<a hidden class=anchor aria-hidden=true href=#five-common-myths-about-recommender-systems>#</a></h3><p>There are some common myths and misconceptions surrounding recommender systems. I&rsquo;ve picked five to address in this post. If you disagree, agree, or have more to add, I would love to hear from you either <a href=https://yanirseroussi.com/about/>privately</a> or in the comment section.</p><p class=highlight-box><b>The accuracy myth</b><br>Offline optimisation of an accuracy measure is sufficient for creating a successful recommender<br><b>Reality</b><br>Users don't really care about accuracy</p><p>This is perhaps the most prevalent myth of all, as evidenced by Wikipedia&rsquo;s definition of recommender systems. It&rsquo;s somewhat surprising that it still persists, as it&rsquo;s been almost ten years since <a href="http://dl.acm.org/citation.cfm?id=1125659" target=_blank rel=noopener>McNee et al.&rsquo;s influential paper on the damage the focus on accuracy measures has done to the field</a>.</p><p>It is therefore worth asking where this myth came from. My theory is that it is a feedback loop between academia and industry. In academia it is pretty easy to publish papers with infinitesimal improvements to arbitrary accuracy measures on offline datasets (<a href=https://dl.dropboxusercontent.com/u/25632965/SeroussiBohnertZukerman2011.pdf target=_blank rel=noopener>I&rsquo;m also guilty of doing just that</a>), while it&rsquo;s relatively hard to run experiments on live systems. However, one of the moves that significantly increased focus on offline predictive accuracy came from industry, in the form of the <a href=https://en.wikipedia.org/wiki/Netflix_Prize target=_blank rel=noopener>$1M Netflix prize</a>, where the goal was to improve the accuracy of Netflix&rsquo;s rating prediction algorithm by 10%.</p><p>Notably, most of the algorithms that came out of the three-year competition were never integrated into Netflix. As <a href=http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html target=_blank rel=noopener>discussed on the Netflix blog</a>:</p><blockquote><p>You might be wondering what happened with the final Grand Prize ensemble that won the $1M two years later&mldr; We evaluated some of the new methods offline but the additional accuracy gains that we measured did not seem to justify the engineering effort needed to bring them into a production environment.</p><p>Our business objective is to maximize member satisfaction and month-to-month subscription retention&mldr; Now it is clear that the Netflix Prize objective, accurate prediction of a movie&rsquo;s rating, is just one of the many components of an effective recommendation system that optimizes our members&rsquo; enjoyment.</p></blockquote><p>The following chart says it all (taken from <a href=http://techblog.netflix.com/2012/06/netflix-recommendations-beyond-5-stars.html target=_blank rel=noopener>the second part of the blog post quoted above</a>):</p><figure><a href=netflix-rating-prediction-contribution.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-rating-prediction-contribution_hu17191970390287438292.png 360w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-rating-prediction-contribution_hu17736443663197590432.png 480w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-rating-prediction-contribution_hu13843013049181938312.png 720w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-rating-prediction-contribution.png 908w," src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-rating-prediction-contribution_hu13901382034990325091.png alt="Netflix rating prediction: contribution of ratings" loading=lazy></a></figure><p>An important question that arises is: If users don&rsquo;t really care about predictive accuracy, what do they care about? The answer is that predictive accuracy has some importance (as evidenced by the above chart), but it is not the only thing. In my opinion, the key consideration is UI/UX. You can have the most accurate recommendations in the world, but no one would know about it (or care) if they are not served in a timely manner through a friendly interface.</p><p>Of course, even with a great user interface and accurate predictions, there are other issues that require attention when designing recommender systems. Examples include diversity (showing various types of items), serendipity/novelty (showing non-obvious recommendations that users don&rsquo;t already know about), and coverage (being able to generate recommendations for all users and items). Many other considerations are covered in <a href=http://www.bgu.ac.il/~shanigu/Publications/EvaluationMetrics.17.pdf target=_blank rel=noopener>an excellent survey by Guy Shani and Asela Gunawardana</a>.</p><p>It&rsquo;s also worth noting that there is an inherent problem with common accuracy measures. Specifically, when using a measure like root mean square error, a rating prediction algorithm can be made to perform better by reducing errors on low ratings. This is rather pointless, because items with low ratings will not be shown to users in any case.</p><p>Finally, a key issue that arises with offline evaluation is that there are biases in offline datasets that do not necessarily carry over to online scenarios. For instance, in many cases there is an implicit assumption that <a href=http://users.cs.fiu.edu/~lzhen001/activities/KDD_USB_key_2010/docs/p713.pdf target=_blank rel=noopener>data is missing at random</a>, when it really isn&rsquo;t, e.g., the fact that users took the effort to watch and rate a movie already tells us a lot about a bias they have towards this movie (the team that won the Netflix prize used this bias to their advantage). Hiding this rating and trying to predict it is not the same as predicting a rating for a movie that is picked at random from the entire set of movies.</p><p class=highlight-box><b>The black box myth</b><br>You can build successful recommender systems without worrying about what's being recommended and how recommendations are being served<br><b>Reality</b><br>UI/UX is king, item type is critical</p><p>A good recommender <em>system</em> has to consider how users interact with the recommendations. For example, the number of displayed recommendations should inform the optimisation procedure (e.g., are you aiming for <a href=https://en.wikipedia.org/wiki/Precision_and_recall#Precision target=_blank rel=noopener>precision@1 or precision@10</a>?). How these recommendations are laid out (e.g., horizontally/vertically) tends to influence user interaction. In addition, being able to explain the reasons for the recommendations can yield easy wins. Finally, in many cases there are constraints on the amount of time that can be spent generating recommendations.</p><p>In addition to UI/UX, the design of good recommender <em>systems</em> has to account for what&rsquo;s being recommended. For example, music tracks and short videos can be played many times, so it&rsquo;s probably a good idea to recommend items that the user has already seen. On the other hand, items like washing machines and cars don&rsquo;t get consumed as often. If a user has just bought a washing machine, they&rsquo;re unlikely to want another one anytime soon (but they may want a dryer or a clothes line).</p><figure><a href=hynt-screenshot.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/hynt-screenshot_hu17008018622414803394.png 360w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/hynt-screenshot_hu16912368895272562788.png 480w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/hynt-screenshot_hu9102468640053471026.png 720w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/hynt-screenshot.png 750w," src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/hynt-screenshot.png alt="Hynt recommendation widget" loading=lazy></a></figure><p><a href=https://hynt.com target=_blank rel=noopener>Hynt</a> is a recommender-system-as-a-service for e-commerce whose development I led up until the middle of last year. The general idea is that merchants simply add a few lines of JavaScript to their shop pages and Hynt does the hard work of recommending relevant items from the store, while considering the user and page context. Going live with Hynt reaffirmed many well-known UI/UX lessons. Most notably:</p><ul><li><em>Above the fold is better than below.</em> Engagement with Hynt widgets that were visible without scrolling was higher than those that were lower on the page.</li><li><em>More recommendations are better than a few.</em> Hynt widgets are responsive, adapting to the size of the container they&rsquo;re placed in. Engagement was more likely when more recommendations were displayed, because users were more likely to find something they liked without scrolling through the widget.</li><li><em>Fast is better than slow.</em> If recommendations load faster, more people see them, which increases engagement. In Hynt&rsquo;s case speed was especially important because the widgets load asynchronously after the host page finishes loading.</li></ul><p>Another important UI/UX element is explanations. Displaying a plausible explanation next to a recommendation can do wonders, without making any changes to the underlying recommendation algorithms. The impact of explanations has been studied extensively by Nava Tintarev and Judith Masthoff. They have identified seven different aims of explanations, which are summarised in the following table (reproduced from their <a href=http://homepages.abdn.ac.uk/n.tintarev/pages/papers/TintarevMasthoffICDE07.pdf target=_blank rel=noopener>survey of explanations in recommender systems</a>).</p><table><thead><tr><th>Aim</th><th>Definition</th></tr></thead><tbody><tr><td>Transparency</td><td>Explain how the system works</td></tr><tr><td>Scrutability</td><td>Allow users to tell the system it is wrong</td></tr><tr><td>Trust</td><td>Increase user confidence in the system</td></tr><tr><td>Effectiveness</td><td>Help users make good decisions</td></tr><tr><td>Persuasiveness</td><td>Convince users to try or buy</td></tr><tr><td>Efficiency</td><td>Help users make decisions faster</td></tr><tr><td>Satisfaction</td><td>Increase ease of usability or enjoyment</td></tr></tbody></table><p>Explanations are ubiquitous in real-world recommender systems. For example, Amazon uses explanations like &ldquo;frequently bought together&rdquo;, and &ldquo;customers who bought this item also bought&rdquo;, while Netflix presents different lists of recommendations where each list is driven by a different reason. However, as the following Netflix example shows, it is worth making sure that the explanations you provide don&rsquo;t <a href=http://funnyjunk.com/Thanks+netflix/funny-pictures/5040772/ target=_blank rel=noopener>make you look stupid</a>.</p><figure><a href=amazon-frequently-bought-together.png target=_blank rel=noopener><img sizes="(min-width: 768px) 633px,
100vw" srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/amazon-frequently-bought-together_hu15589678651873710813.png 360w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/amazon-frequently-bought-together_hu18021758773494046297.png 480w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/amazon-frequently-bought-together.png 633w," src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/amazon-frequently-bought-together.png alt="Amazon frequently bought together" loading=lazy></a></figure><figure><a href=netflix-because-you-watched.png target=_blank rel=noopener><img sizes="(min-width: 768px) 720px,
100vw" srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-because-you-watched_hu14742179188839002198.png 360w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-because-you-watched_hu3565877031699174505.png 480w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-because-you-watched_hu3560546326789046040.png 720w,
https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-because-you-watched.png 752w," src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/netflix-because-you-watched.png alt="Netflix because you watched" loading=lazy></a></figure><p class=highlight-box><b>The solved problem myth</b><br>The space of recommender systems has been exhaustively explored<br><b>Reality</b><br>Development of new methods is often required</p><p>When I finished <a href=https://yanirseroussi.com/phd-work/>my PhD</a>, about three years ago, I joined a small startup called Giveable as the first employee (essentially part of the founding team that was formed after Adam Neumann, the original founder, graduated from <a href=http://angelcube.com/ target=_blank rel=noopener>AngelCube</a> and raised some seed funding). Giveable&rsquo;s original product was a webapp where users could connect with their Facebook account and find gifts for their friends.</p><figure><a href=giveable-logo.png target=_blank rel=noopener><img sizes="(min-width: 768px) 250px,
100vw" srcset="https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/giveable-logo.png 250w," src=https://yanirseroussi.com/2015/10/02/the-wonderful-world-of-recommender-systems/giveable-logo.png alt="Giveable logo" loading=lazy></a></figure><p>At the time, there wasn&rsquo;t much published research on gift recommendation, and there was more or less nothing about the specific problem of recommending gifts for Facebook friends using liked pages. Here are some of the ways this problem differs from classic recommendation scenarios.</p><ul><li><em>Need to consider giver and receiver.</em> Unlike traditional scenarios, the recommended items aren&rsquo;t consumed by the user to whom they&rsquo;re shown. In practice, this meant that we had to ensure the items are <em>giftable</em>, and take into account the relationship between the giver and the receiver. For example, the type of gift your mum may give you is different from gifts your partner may give you.</li><li><em>Likes are historical, sparse, and often nonsensical.</em> This is best illustrated by an example: What does liking a page such as <a href=https://www.facebook.com/Tony-Abbott-Worst-PM-in-Australian-History-151576228341304 target=_blank rel=noopener>Tony Abbott – Worst PM in Australian History</a> tell us about gifts the user may like? Tony Abbott is no longer prime minister (thankfully), so it&rsquo;s historical, and while this page is quite popular, there are many other pages out there that are difficult to interpret and are liked by only a handful of people (<a href="https://www.youtube.com/watch?v=c3IaKVmkXuk" target=_blank rel=noopener>this video is a good summary of why Tony is disliked, for those who are unfamiliar with Australian politics</a>).</li><li><em>Likes are not for recommended items.</em> As the above example shows, just because you like disliking Tony, it doesn&rsquo;t exactly lead to useful gifts. Even with things that are more related to interests, such as authors and bands, the liked pages aren&rsquo;t recommendable as gifts.</li><li><em>Likes are not always available offline.</em> This was an important engineering consideration: We didn&rsquo;t have much time to generate recommendations from the point where a new user gave us permission to view their likes and the likes of their friends. Ideally, recommendation generation would take less than a second from the time we got all the data from Facebook. This puts a strong constraint on the types of algorithms we could use.</li></ul><p>The key to effectively addressing the Giveable recommendation problem was doing as much processing offline as possible. Specifically:</p><ul><li>Similar pages were inferred using <a href=https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation target=_blank rel=noopener>Latent Dirichlet Allocation</a> (which can be seen as a collaborative filtering technique). This made it possible to use information from pages that are not directly linked to giftable products, e.g., for the above Tony Abbott example, people who dislike him are likely to be left-leaning, which implies many other interests.</li><li>Facebook pages were matched to giftable products with heuristics + <a href=https://www.mturk.com/ target=_blank rel=noopener>Mechanical Turk</a> + machine learning. This took a few iterations of what was essentially partly-manual <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning target=_blank rel=noopener>semi-supervised learning</a>, where we obtained high-confidence matches through heuristics and manual tagging, and then used this to train a classifier that was used to classify uncertain matches. The results of classification on a hold-out set were then verified through manual tagging of subsamples.</li><li>We enriched the page and product data with structured information from the Freebase knowledge graph (<a href=https://plus.google.com/109936836907132434202/posts/3aYFVNf92A1 target=_blank rel=noopener>which has since been deprecated</a>). This allowed us to easily match giftable products to liked pages, e.g., books to authors.</li></ul><p>The online part included taking a receiver&rsquo;s liked pages, inferring likes for similar pages, and matching all these pages to a ranked and diversified list of giftable product recommendations. These recommendations came with explanations, which were quite important in this case because the giver of a gift has to know why they&rsquo;re giving it.</p><p class=highlight-box><b>The silver bullet myth</b><br>Optimising a single measure or using a single algorithm is sufficient for generating a good recommendation list<br><b>Reality</b><br>Hybrids work best</p><p>Netflix provides another example for how focusing on a single algorithm or measure of success is far from sufficient. In a <a href=http://techblog.netflix.com/2015/04/learning-personalized-homepage.html target=_blank rel=noopener>recent blog post</a>, they talk about how they use multiple algorithms to optimise the order of different recommendation lists and each list&rsquo;s internal ranking, while considering device-specific UI constraints, relevance, engagement, diversity, business requirements, and more.</p><p>An example from my experience comes from Giveable (which ended up evolving into Hynt), where a single list was generated by mixing the outputs of the following recommendation approaches: contextual, direct likes, inferred likes, content-based, social, collaborative filtering of products, previously viewed items, and popular interests/products. The weight of each algorithm in the mix was static – it was either set manually or through A/B testing, and then left as a hardcoded constant.</p><p>This kind of static mix can get you very far, but there&rsquo;s a better way that I haven&rsquo;t gotten around to implementing before leaving to work on other things. This way is described in <a href=http://engineering.richrelevance.com/bandits-recommendation-systems/ target=_blank rel=noopener>a series of posts on bandits for recommenders by Sergey Feldman of RichRelevance</a>. The general idea is to train recommendation models offline using a small number of strategies/paradigms. Online, recommendations are served from strategies that maximise clickthrough and revenue, given a context of features that describe the user, merchant, and web page where the RichRelevance widget is embedded. Rather than setting static weights for the strategies, the bandit model continuously adjusts the weights, while balancing between exploring new strategy weights and exploiting strategies that have been known to work well in a specific context. This allows the overall recommendation engine to adjust to changes in reality and in the underlying data.</p><p class=highlight-box><b>The omnipresence myth</b><br>Every personalised system is a recommender system<br><b>Reality</b><br>This one is kinda true, but not necessarily useful...</p><p>The first conference I attended as a PhD student was the 18th International Conference on User Modeling, Adaptation and Personalization (UMAP), back in 2010. The field of recommender systems was getting increased attention, and <a href=https://en.wikipedia.org/wiki/Peter_Brusilovsky target=_blank rel=noopener>Peter Brusilovsky</a>, who has been working in the UMAP field for decades, argued that recommender systems are the new <a href=https://en.wikipedia.org/wiki/Expert_system target=_blank rel=noopener>expert systems</a>. This was partly because the hype was causing people to broaden the definition of the field to allow them to say that they&rsquo;re working on recommender systems.</p><p>I don&rsquo;t think it&rsquo;s incorrect that personalisation and recommender systems are different things. However, one problem that this may cause is making people think that common recommendation techniques would apply in scenarios where they&rsquo;re unlikely to work. For example, web search can be seen as a recommender system for pages that gives a high weight to the user&rsquo;s intent, as captured by the query. Hence, when personalising web search, it seems sensible to use collaborative filtering techniques. This was indeed my experience with <a href=https://yanirseroussi.com/2015/02/11/learning-to-rank-for-personalised-search-yandex-search-personalisation-kaggle-competition-summary-part-2/>the Yandex search personalisation competition</a>: employing a matrix factorisation approach that was inspired by collaborative filtering turned out to be a waste of time compared to domain-specific methods.</p><p><strong>In conclusion</strong>, recommenders are about as murky as data science. Just like data science, the boundaries of recommender systems are hard to define and they are sometimes over-hyped. This hype may lead to people investing in a recommender system they don&rsquo;t really need, just like <a href=https://yanirseroussi.com/2015/08/24/you-dont-need-a-data-scientist-yet/>the common issue of premature investment in data science</a>. However, the hype is based on real value, which can definitely be delivered by recommender systems when they are used correctly.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yanirseroussi.com/tags/data-science/>Data Science</a></li><li><a href=https://yanirseroussi.com/tags/machine-learning/>Machine Learning</a></li><li><a href=https://yanirseroussi.com/tags/predictive-modelling/>Predictive Modelling</a></li><li><a href=https://yanirseroussi.com/tags/recommender-systems/>Recommender Systems</a></li><li><a href=https://yanirseroussi.com/tags/software-engineering/>Software Engineering</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on x" href="https://x.com/intent/tweet/?text=The%20wonderful%20world%20of%20recommender%20systems&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f&amp;hashtags=datascience%2cmachinelearning%2cpredictivemodelling%2crecommendersystems%2csoftwareengineering"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f&amp;title=The%20wonderful%20world%20of%20recommender%20systems&amp;summary=The%20wonderful%20world%20of%20recommender%20systems&amp;source=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f&title=The%20wonderful%20world%20of%20recommender%20systems"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on whatsapp" href="https://api.whatsapp.com/send?text=The%20wonderful%20world%20of%20recommender%20systems%20-%20https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on telegram" href="https://telegram.me/share/url?text=The%20wonderful%20world%20of%20recommender%20systems&amp;url=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share The wonderful world of recommender systems on ycombinator" href="https://news.ycombinator.com/submitlink?t=The%20wonderful%20world%20of%20recommender%20systems&u=https%3a%2f%2fyanirseroussi.com%2f2015%2f10%2f02%2fthe-wonderful-world-of-recommender-systems%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><a href=/contact/#mailing-list-email target=_blank aria-label="subscribe to mailing list" class=mailing-list-link id=mailing-list-link>Subscribe
</a><script>const mailingListButton=document.getElementById("mailing-list-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mailingListButton.style.visibility="visible",mailingListButton.style.opacity="1"):(mailingListButton.style.visibility="hidden",mailingListButton.style.opacity="0")}</script><div class=mailing-list-container><script src=https://f.convertkit.com/ckjs/ck.5.js></script><form class="mailing-list seva-form formkit-form" action=https://app.convertkit.com/forms/6549537/subscriptions method=post data-sv-form=6549537 data-uid=9157759fce data-format=inline data-version=5 data-options='{"settings":{"after_subscribe":{"action":"message","redirect_url":"","success_message":"Success! Now check your email to confirm your subscription."},"recaptcha":{"enabled":false},"return_visitor":{"action":"show","custom_content":""}},"version":"5"}'><div data-style=clean><ul class="formkit-alert formkit-alert-error" data-element=errors data-group=alert></ul><div data-element=fields data-stacked=false><label for=mailing-list-email>Get weekly posts in your mailbox</label>
<input id=mailing-list-email name=email_address aria-label="Email address" placeholder="Email address" required type=email>
<button data-element=submit>Subscribe</button></div></div></form><div class=footer>Join hundreds of subscribers. No spam or AI-generated slop. Unsubscribe any time.</div></div><section class=comment-section><p class="post-content contact-cta">Public comments are closed, but I love hearing from readers. Feel free to
<a href=/contact/ target=_blank>contact me</a> with your thoughts.</p><div class=comment-level-0 id=comment-702><div class=comment-header><a href=#comment-702><img class=comment-avatar src="https://www.gravatar.com/avatar/54f70981ce3758ccbfd5420bbff28df6?s=50"><p class=comment-info><strong>Zygmunt</strong><br><small>2015-10-02 16:51:09</small></p></a></div><div class="comment-body post-content"><p>How did you arrive at the conclusion that accuracy doesn&rsquo;t matter? The Netflix quote and chart don&rsquo;t seem connected to me. The quote refers to the massive ensembling used to achieve the challenge score threshold. The chart seems to show that you can go a long way from the baseline by improving features and models.</p><p>I&rsquo;d say accuracy, or more generally, score used for evaluation, doesn&rsquo;t matter <em>as long as it&rsquo;s good enough</em>. However, it&rsquo;s not that easy to arrive at &ldquo;good enough&rdquo;. Consider Spotify. I find their daily recommendations abysmal. Discover Weekly is much better, but still has room to improve.</p></div></div><div class=comment-level-1 id=comment-706><div class=comment-header><a href=#comment-706><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2015-10-02 20:36:57</small></p></a></div><div class="comment-body post-content"><p>I agree. I said that predictive accuracy has some importance, but it is not the only thing that matters. You&rsquo;re right about it needing to be <em>good enough</em>, where the definition of good enough is domain-dependent.</p><p><a href=http://cgi.csc.liv.ac.uk/~wda2001/Panel_Presentations/Lopresti/Lopresti_files/v3_document.htm target=_blank rel=nofollow>Daniel Lopresti</a> said it well years ago (he spoke about web search but it applies to recommendation scenarios where suggestions are browsable):</p><blockquote>Browsing is a comfortable and powerful paradigm (the serendipity effect). Search results don't have to be very good.
Recall? Not important (as long as you get at least some good hits).
Precision? Not important (as long as at least some of the hits on the first page you return are good).</blockquote></div></div><div class=comment-level-2 id=comment-1037><div class=comment-header><a href=#comment-1037><img class=comment-avatar src="https://www.gravatar.com/avatar/b3fdb35b6d4d527be6adef9dd103e352?s=50"><p class=comment-info><strong>flower</strong><br><small>2016-01-26 18:47:02</small></p></a></div><div class="comment-body post-content">it does not clear to me why accuracy is not important in recommender and searching??</div></div><div class=comment-level-3 id=comment-1038><div class=comment-header><a href=#comment-1038><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2016-01-26 19:21:55</small></p></a></div><div class="comment-body post-content"><p>It is important, but its importance tends to be exaggerated to the exclusion of all other metrics. As I said in the post, things like the way you present your results (UI/UX) and novelty/serendipity are also very important. In addition, the goal of the system is often to optimise a different goal from offline accuracy, such as revenue or engagement. In such cases it is best to focus on what you want to improve rather than offline accuracy.</p><p>By the way, I attended a talk by Ted Dunning a few months ago, where he said that one of the most important tweaks in real-life recommender system is adding random recommendations (essentially decreasing offline accuracy). This allows the system to learn from user feedback on a wider range of items, improving performance in the long run.</p></div></div><div class=comment-level-2 id=comment-1040><div class=comment-header><a href=#comment-1040><img class=comment-avatar src="https://www.gravatar.com/avatar/b3fdb35b6d4d527be6adef9dd103e352?s=50"><p class=comment-info><strong>flower</strong><br><small>2016-01-26 21:00:40</small></p></a></div><div class="comment-body post-content">Thank you very much for your fast response.
would you please send me the ted talk&rsquo;s tilte ? so I can watch it.</div></div><div class=comment-level-3 id=comment-1041><div class=comment-header><a href=#comment-1041><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2016-01-26 21:05:13</small></p></a></div><div class="comment-body post-content">It&rsquo;s a talk by Ted Dunning, not a TED talk :)
Anyway, the video is here: <a href="https://www.youtube.com/watch?v=FKAFe2iN_Yw" target=_blank rel=noopener>https://www.youtube.com/watch?v=FKAFe2iN_Yw</a> (both talks in the video are excellent)</div></div><div class=comment-level-0 id=comment-704><div class=comment-header><a href=#comment-704><img class=comment-avatar src="https://www.gravatar.com/avatar/b5a286f0ade6f558ff4cf0e3c3f9813a?s=50"><p class=comment-info><strong>rriveramx</strong><br><small>2015-10-02 18:19:27</small></p></a></div><div class="comment-body post-content"><p>Two points that were not discussed but I see it recurrently, at least in E-Commerce, it is how people underestimate the effort necessary to build an online realtime recommender system and overestimate its impact. Offline recommendations are enough for the majority of cases. The second one, there is an obsession with novel algorithms, when often bread and butter ALS + domain knowledge reflected in business rules bring better impact.</p><p>Overall, really good overview, and I fully agree with all points!</p></div></div><div class=comment-level-0 id=comment-710><div class=comment-header><a href=#comment-710><img class=comment-avatar src="https://www.gravatar.com/avatar/8d9aba79be37c3e972c9d572ee7dc66b?s=50"><p class=comment-info><strong>Francis Kim</strong><br><small>2015-10-04 02:32:30</small></p></a></div><div class="comment-body post-content">This was an excellent read - would highly recommend ;) - thank you.</div></div><div class=comment-level-0 id=comment-1170><div class=comment-header><a href=#comment-1170><img class=comment-avatar src="https://www.gravatar.com/avatar/c675bbf4b77d907c484368b1c54d20c1?s=50"><p class=comment-info><strong>Divyesh Patel</strong><br><small>2016-04-10 14:24:59</small></p></a></div><div class="comment-body post-content">Thanks a lot for giving an awesome overview of recommender systems. Have you considered writing a textbook on the topic?</div></div><div class=comment-level-1 id=comment-1171><div class=comment-header><a href=#comment-1171><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2016-04-10 20:38:34</small></p></a></div><div class="comment-body post-content">Nah, there already many books out there and it&rsquo;s too much work to write another one :)</div></div><div class=comment-level-0 id=comment-1227><div class=comment-header><a href=#comment-1227><img class=comment-avatar src="https://www.gravatar.com/avatar/488c63cf544384eec6968efeb1ee3292?s=50"><p class=comment-info><strong>AA</strong><br><small>2016-06-12 13:25:42</small></p></a></div><div class="comment-body post-content">Hi! Thank you for the article. It a bit much help me for my project. However, can you suggest me any book or link that can show me how to apply the algorithm in coding? I guess it a little bit difficult. I do not found any article related to application of the algorithm in coding, especially in Java because currently I&rsquo;m developing the recommender apps. I&rsquo;m stuck at the algorithm. Hope you or anyone can help. Thank you!</div></div><div class=comment-level-1 id=comment-1228><div class=comment-header><a href=#comment-1228><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2016-06-13 02:03:18</small></p></a></div><div class="comment-body post-content">Thank you for your comment. You can check out Mahout in Action (<a href=https://www.manning.com/books/mahout-in-action target=_blank rel=noopener>https://www.manning.com/books/mahout-in-action</a>) or Oryx (<a href=http://oryx.io/ target=_blank rel=noopener>http://oryx.io/</a>) for some examples.</div></div><div class=comment-level-0 id=comment-1489><div class=comment-header><a href=#comment-1489><img class=comment-avatar src="https://www.gravatar.com/avatar/b1d3ea05e634c6db0aa1d0fa57c5bad7?s=50"><p class=comment-info><strong>gluemesch</strong><br><small>2017-03-30 09:35:33</small></p></a></div><div class="comment-body post-content">Hi Yanir, thanks a lot for a comprehensive article on recommender systems. What I&rsquo;m interested in particular is a recommender systems for subscription box businesses, as in the case of BarkBox, Birchbox, Blue Apron, Harry’s, OwlCrate, Trunk Club, and Winc. What type of recommeder system do they use and why is beneficial?</div></div><div class=comment-level-1 id=comment-1492><div class=comment-header><a href=#comment-1492><img class=comment-avatar src="https://www.gravatar.com/avatar/dda019c47a6183120608a6aeac2db6c5?s=50"><p class=comment-info><strong>Yanir Seroussi</strong><br><small>2017-03-31 08:01:35</small></p></a></div><div class="comment-body post-content">Thanks for your comment. Unfortunately, I&rsquo;m not familiar with those businesses so I don&rsquo;t really know what recommender systems they use&mldr;</div></div></section></article></main><div class=global-footer><div class=footer><span>Text and figures licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank rel=noopener>CC BY-NC-ND 4.0</a> by <a href=https://yanirseroussi.com/about/>Yanir Seroussi</a>, except where noted otherwise&nbsp;&nbsp;|</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
      <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></div></div><script>const menuTrigger=document.querySelector("#menu-trigger"),menuElem=document.querySelector(".menu");menuTrigger.addEventListener("click",function(){menuElem.classList.toggle("hidden")}),document.body.addEventListener("click",function(e){menuTrigger.contains(e.target)||menuElem.classList.add("hidden")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>