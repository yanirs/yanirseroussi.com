<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Hopping on the deep learning bandwagon | Yanir Seroussi | Data science and beyond</title>
<meta name=keywords content="bandcamp,data science,deep learning,machine learning,predictive modelling">
<meta name=description content="I&rsquo;ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.
As mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty.">
<meta name=author content="Yanir Seroussi">
<link rel=canonical href=https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/>
<link crossorigin=anonymous href=/yanirseroussi.com/assets/css/stylesheet.min.51e68192da3381c9040a063242bafad56d6d28666fff1f9e523f9eaad0207a83.css integrity="sha256-UeaBktozgckECgYyQrr61W1tKGZv/x+eUj+eqtAgeoM=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/yanirseroussi.com/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://yanirs.github.io/yanirseroussi.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://yanirs.github.io/yanirseroussi.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://yanirs.github.io/yanirseroussi.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://yanirs.github.io/yanirseroussi.com/apple-touch-icon.png>
<link rel=mask-icon href=https://yanirs.github.io/yanirseroussi.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.88.1">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Hopping on the deep learning bandwagon">
<meta property="og:description" content="I&rsquo;ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.
As mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/">
<meta property="og:image" content="https://yanirs.github.io/yanirseroussi.com/bandcamp-album-covers-by-genre-shuffled.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2015-06-06T05:00:22+00:00">
<meta property="article:modified_time" content="2015-06-06T05:00:22+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanirs.github.io/yanirseroussi.com/bandcamp-album-covers-by-genre-shuffled.png">
<meta name=twitter:title content="Hopping on the deep learning bandwagon">
<meta name=twitter:description content="I&rsquo;ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.
As mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yanirs.github.io/yanirseroussi.com/posts/"},{"@type":"ListItem","position":2,"name":"Hopping on the deep learning bandwagon","item":"https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hopping on the deep learning bandwagon","name":"Hopping on the deep learning bandwagon","description":"I\u0026rsquo;ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.\nAs mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty.","keywords":["bandcamp","data science","deep learning","machine learning","predictive modelling"],"articleBody":"I’ve been meaning to get into deep learning for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.\nAs mentioned in a previous post on getting started as a data scientist, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty. Despite being familiar with high-level terminology and having some understanding of how it all works, I don’t have any practical experience applying deep learning. The purpose of this project is to fix this experience gap by working on a real problem.\nThe problem: Inferring genre from album covers Deep learning has been very successful at image classification. Therefore, it makes sense to work on an image classification problem for this project. Rather than using an existing dataset, I decided to make things a bit more interesting by building my own dataset. Over the last year, I’ve been running BCRecommender – a recommendation system for Bandcamp music. I’ve noticed that album covers vary by genre, though it’s hard to quantify exactly how they vary. So the question I’ll be trying to answer with this project is how accurately can genre be inferred from Bandcamp album covers?\nAs the goal of this project is to learn about deep learning rather than make a novel contribution, I didn’t do a comprehensive search to see whether this problem has been addressed before. However, I did find a recent post by Alexandre Passant that describes his use of Clarifai’s API to tag the content of Spotify album covers (identifying elements such as men, night, dark, etc.), and then using these tags to infer the album’s genre. Another related project is Karayev et al.’s Recognizing image style paper, in which the authors classified datasets of images from Flickr and Wikipedia by style and art genre, respectively. In all these cases, the results are pretty good, supporting my intuition that the genre inference task is feasible.\nData collection \u0026 splits As I’ve already been crawling Bandcamp data for BCRecommender, creating the dataset was relatively straightforward. Currently, I have data on about 1.8 million tracks and albums. Bandcamp artists assign multiple tags to each release. To create the dataset, I selected 10 of the top tags: ambient, dubstep, folk, hiphop_rap, jazz, metal, pop, punk, rock, and soul. Then, I randomly selected 10,000 album covers that have exactly one of those tags, with 1,000 albums for each tag/genre. Each cover image size is 350×350. The following image shows a sample of the dataset.\n   It is apparent that some genres can be inferred more easily than others, especially when browsing through the full dataset. For example, metal albums tend to be pretty distinct. I doubt that predictive accuracy would be very high, but I think that it can definitely be much better than the random baseline of 10%.\nFor training, validation and testing I decided to use a static stratified 80%/10%/10% split of the dataset. It quickly became apparently that the full dataset is too big for development purposes, making it hard to quickly test code on my local machine. To address this, I created a local development dataset, using an 80%/10%/10% split of 1,000 images from the full training subset.\nThe code for downloading the dataset and creating the splits is available from the project repository on GitHub. This repository will include all the code for the project as it evolves. I will try to keep it well-documented enough to be useful for others, though it assumes some familiarity with Python. If you experience any issues running the code or find any bugs, please let me know.\nGetting started One of the things that has stopped me from playing with deep learning in the past is the feeling that there is a bit of a steep learning curve around the tools and methods. A lot of the deep learning libraries out there don’t seem as mature as general machine learning libraries, such as scikit-learn. There are also many more parameters to play with when building deep neural networks than when using linear models or algorithms such as random forests. Further, to enable any kind of meaningful experimentation, using a GPU is essential.\nFortunately, the tools and documentation have matured a lot in recent years. Motivated by Daniel Nouri’s excellent tutorial on detecting facial keypoints with convolutional neural nets, I decided to use the Lasagne package as my starting point. My plan was simple: Convert the MNIST example code to work on my dataset locally, setup an AWS machine with a GPU for full-scale experiments, and then play with various network architectures and techniques to improve accuracy and gain a deeper understanding of deep learning.\nInitial environment setup While Lasagne’s MNIST example code is pretty clear – especially once you get your head around the way Theano works – it doesn’t really lend itself to easy experimentation. I addressed this by refactoring the code in several iterations, until I got to the current state, where there’s a simple command-line interface that allows me to experiment with different datasets and architectures. This will probably change and become more complex as I start doing more sophisticated things.\nTo enable rapid experimentation, I had to set up an AWS machine with a GPU (g2.2xlarge instance). I wrote some simple deployment code using Fabric, which allows me to setup a machine from scratch, install all the requirements, package the project, and copy it to the remote machine.\nGetting the code running on the CPU was trivial, but I hit several issues when running on the GPU. First, the vanilla Ubuntu 14.04 server I used didn’t come with CUDA installed. After trying and failing to get it working by following some tutorials, I ended up going down the easier path of using the AMI supplied by Caffe. This AMI also has the advantage of coming with Caffe installed (surprisingly), which I may end up using at some point.\nThe second issue I encountered was that using the GPU to run Lasagne’s enhanced example code on my full dataset was impossible due to memory constraints. The problem was that the example assumes that the entire dataset can fit in the GPU’s memory (as discussed here and here). This took a while to resolve, even though the solution is conceptually simple – just copy the dataset to the GPU in chunks rather than attempt to copy it all in one go. Resolving this issue was a good way of getting a better understanding of what the code does, since I ended up rewriting most of the original example code.\nNext steps So far, I left the network architecture from the original example mostly untouched, as I was busy collecting the dataset, getting the environment set up, and resolving various issues. One thing I did notice was that the example’s architecture diverges on my dataset, so instead I tested my code using a basic multi-layer perceptron architecture with a single hidden layer. This performs about as well as a random classifier on my dataset, but at least it converges. I also tested the modified code on the MNIST dataset and the results are decent, so now it is time to move forward and actually do some modelling, starting with convolutional neural nets.\nThe high level plan is to iteratively read tutorials/papers/books, implement ideas, play with parameters, and visualise parts of the network until I’m satisfied with the results. The main goal remains to learn as much as possible and get a good intuition of how things work. I’ll write more about my experiences in subsequent posts. Stay tuned!\nUpdate: The second post in the series is now available.\n","wordCount":"1311","inLanguage":"en","image":"https://yanirs.github.io/yanirseroussi.com/bandcamp-album-covers-by-genre-shuffled.png","datePublished":"2015-06-06T05:00:22Z","dateModified":"2015-06-06T05:00:22Z","author":{"@type":"Person","name":"Yanir Seroussi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/"},"publisher":{"@type":"Organization","name":"Yanir Seroussi | Data science and beyond","logo":{"@type":"ImageObject","url":"https://yanirs.github.io/yanirseroussi.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://yanirs.github.io/yanirseroussi.com/ accesskey=h title="Yanir Seroussi | Data science and beyond (Alt + H)">Yanir Seroussi | Data science and beyond</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Hopping on the deep learning bandwagon
</h1>
<div class=post-meta>June 6, 2015&nbsp;·&nbsp;Yanir Seroussi&nbsp;|&nbsp;<a href=https://github.com/yanirs/yanirseroussi.com/blob/master/content/posts/2015-06-06-hopping-on-the-deep-learning-bandwagon/index.md rel="noopener noreferrer" target=_blank>Suggest changes</a>
</div>
</header>
<figure class=entry-cover>
<img loading=lazy srcset="https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre-shuffled_hu7dd57cb220c55d3023581cbc705ac82b_182096_360x0_resize_box_3.png 360w ,https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre-shuffled_hu7dd57cb220c55d3023581cbc705ac82b_182096_480x0_resize_box_3.png 480w ,https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre-shuffled_hu7dd57cb220c55d3023581cbc705ac82b_182096_720x0_resize_box_3.png 720w ,https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre-shuffled.png 748w" sizes="(min-width: 768px) 720px, 100vw" src=https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre-shuffled.png alt width=748 height=128>
</figure>
<div class=post-content><p>I&rsquo;ve been meaning to get into <a href=https://en.wikipedia.org/wiki/Deep_learning target=_blank rel=noopener>deep learning</a> for the last few years. Now, the stars having finally aligned and I have the time and motivation to work on a small project that will hopefully improve my understanding of the field. This is the first in a series of posts that will document my progress on this project.</p>
<p>As mentioned in a <a href=http://yanirseroussi.com/2015/05/02/first-steps-in-data-science-author-aware-sentiment-analysis/>previous post on getting started as a data scientist</a>, I believe that the best way of becoming proficient at solving data science problems is by getting your hands dirty. Despite being familiar with high-level terminology and having some understanding of how it all works, I don&rsquo;t have any practical experience applying deep learning. The purpose of this project is to fix this experience gap by working on a real problem.</p>
<h3 id=the-problem-inferring-genre-from-album-covers>The problem: Inferring genre from album covers<a hidden class=anchor aria-hidden=true href=#the-problem-inferring-genre-from-album-covers>#</a></h3>
<p>Deep learning has been very successful at image classification. Therefore, it makes sense to work on an image classification problem for this project. Rather than using an existing dataset, I decided to make things a bit more interesting by building my own dataset. Over the last year, I&rsquo;ve been running <a href=http://www.bcrecommender.com target=_blank rel=noopener>BCRecommender – a recommendation system for Bandcamp music</a>. I&rsquo;ve noticed that album covers vary by genre, though it&rsquo;s hard to quantify exactly <em>how</em> they vary. So the question I&rsquo;ll be trying to answer with this project is <em>how accurately can genre be inferred from Bandcamp album covers?</em></p>
<p>As the goal of this project is to learn about deep learning rather than make a novel contribution, I didn&rsquo;t do a comprehensive search to see whether this problem has been addressed before. However, I did find <a href=http://apassant.net/2015/05/14/album-covers-music-deep-learning/ target=_blank rel=noopener>a recent post by Alexandre Passant</a> that describes his use of Clarifai&rsquo;s API to tag the content of Spotify album covers (identifying elements such as men, night, dark, etc.), and then using these tags to infer the album&rsquo;s genre. Another related project is <a href=http://sergeykarayev.com/files/1311.3715v3.pdf target=_blank rel=noopener>Karayev et al.&rsquo;s <em>Recognizing image style</em> paper</a>, in which the authors classified datasets of images from Flickr and Wikipedia by style and art genre, respectively. In all these cases, the results are pretty good, supporting my intuition that the genre inference task is feasible.</p>
<h3 id=data-collection--splits>Data collection & splits<a hidden class=anchor aria-hidden=true href=#data-collection--splits>#</a></h3>
<p>As I&rsquo;ve already been crawling Bandcamp data for BCRecommender, creating the dataset was relatively straightforward. Currently, I have data on about 1.8 million tracks and albums. Bandcamp artists assign multiple tags to each release. To create the dataset, I selected 10 of the top tags: <em>ambient, dubstep, folk, hiphop_rap, jazz, metal, pop, punk, rock,</em> and <em>soul</em>. Then, I randomly selected 10,000 album covers that have exactly one of those tags, with 1,000 albums for each tag/genre. Each cover image size is 350×350. The following image shows a sample of the dataset.</p>
<figure>
<a href=bandcamp-album-covers-by-genre.png target=_blank rel=noopener>
<img sizes="
          (min-width: 768px) 720px,
          100vw
        " srcset="https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre_hu98267f967d1b66bf7a519f3fa620b70e_1042875_360x0_resize_box_3.png 360w,
https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre_hu98267f967d1b66bf7a519f3fa620b70e_1042875_480x0_resize_box_3.png 480w,
https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre_hu98267f967d1b66bf7a519f3fa620b70e_1042875_720x0_resize_box_3.png 720w,
https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre.png 828w," src=https://yanirs.github.io/yanirseroussi.com/2015/06/06/hopping-on-the-deep-learning-bandwagon/bandcamp-album-covers-by-genre_hu98267f967d1b66bf7a519f3fa620b70e_1042875_800x0_resize_box_3.png alt="Bandcamp album covers by genre" loading=lazy>
</a>
</figure>
<p>It is apparent that some genres can be inferred more easily than others, especially when browsing through the full dataset. For example, metal albums tend to be pretty distinct. I doubt that predictive accuracy would be very high, but I think that it can definitely be much better than the random baseline of 10%.</p>
<p>For training, validation and testing I decided to use a static stratified 80%/10%/10% split of the dataset. It quickly became apparently that the full dataset is too big for development purposes, making it hard to quickly test code on my local machine. To address this, I created a local development dataset, using an 80%/10%/10% split of 1,000 images from the full training subset.</p>
<p>The code for downloading the dataset and creating the splits is available from the <a href=https://github.com/yanirs/bandcamp-deep-learning target=_blank rel=noopener>project repository on GitHub</a>. This repository will include all the code for the project as it evolves. I will try to keep it well-documented enough to be useful for others, though it assumes some familiarity with Python. If you experience any issues running the code or find any bugs, please let me know.</p>
<h3 id=getting-started>Getting started<a hidden class=anchor aria-hidden=true href=#getting-started>#</a></h3>
<p>One of the things that has stopped me from playing with deep learning in the past is the feeling that there is a bit of a steep learning curve around the tools and methods. A lot of the deep learning libraries out there don&rsquo;t seem as mature as general machine learning libraries, such as <a href=http://scikit-learn.org/ target=_blank rel=noopener>scikit-learn</a>. There are also many more parameters to play with when building deep neural networks than when using linear models or algorithms such as random forests. Further, to enable any kind of meaningful experimentation, using a GPU is essential.</p>
<p>Fortunately, the tools and documentation have matured a lot in recent years. Motivated by <a href=http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/ target=_blank rel=noopener>Daniel Nouri&rsquo;s excellent tutorial on detecting facial keypoints with convolutional neural nets</a>, I decided to use the <a href=http://lasagne.readthedocs.org/ target=_blank rel=noopener>Lasagne package</a> as my starting point. My plan was simple: Convert the MNIST example code to work on my dataset locally, setup an AWS machine with a GPU for full-scale experiments, and then play with various network architectures and techniques to improve accuracy and gain a deeper understanding of deep learning.</p>
<h3 id=initial-environment-setup>Initial environment setup<a hidden class=anchor aria-hidden=true href=#initial-environment-setup>#</a></h3>
<p>While Lasagne&rsquo;s MNIST example code is pretty clear – especially once you get your head around the way <a href=http://www.deeplearning.net/software/theano/ target=_blank rel=noopener>Theano</a> works – it doesn&rsquo;t really lend itself to easy experimentation. I addressed this by refactoring the code in several iterations, until I got to the current state, where there&rsquo;s a simple command-line interface that allows me to experiment with different datasets and architectures. This will probably change and become more complex as I start doing more sophisticated things.</p>
<p>To enable rapid experimentation, I had to set up an AWS machine with a GPU (g2.2xlarge instance). I wrote some simple deployment code using <a href=http://www.fabfile.org/ target=_blank rel=noopener>Fabric</a>, which allows me to setup a machine from scratch, install all the requirements, package the project, and copy it to the remote machine.</p>
<p>Getting the code running on the CPU was trivial, but I hit several issues when running on the GPU. First, the vanilla Ubuntu 14.04 server I used didn&rsquo;t come with CUDA installed. After trying and failing to get it working by following some tutorials, I ended up going down the easier path of using the <a href=https://github.com/BVLC/caffe/wiki/Caffe-on-EC2-Ubuntu-14.04-Cuda-7 target=_blank rel=noopener>AMI supplied by Caffe</a>. This AMI also has the advantage of coming with Caffe installed (surprisingly), which I may end up using at some point.</p>
<p>The second issue I encountered was that using the GPU to run Lasagne&rsquo;s enhanced example code on my full dataset was impossible due to memory constraints. The problem was that the example assumes that the entire dataset can fit in the GPU&rsquo;s memory (as discussed <a href=https://github.com/Lasagne/Lasagne/issues/12 target=_blank rel=noopener>here</a> and <a href=https://groups.google.com/forum/#!topic/lasagne-users/6F3gCfgviks target=_blank rel=noopener>here</a>). This took a while to resolve, even though the solution is conceptually simple – just copy the dataset to the GPU in chunks rather than attempt to copy it all in one go. Resolving this issue was a good way of getting a better understanding of what the code does, since I ended up rewriting most of the original example code.</p>
<h3 id=next-steps>Next steps<a hidden class=anchor aria-hidden=true href=#next-steps>#</a></h3>
<p>So far, I left the network architecture from the original example mostly untouched, as I was busy collecting the dataset, getting the environment set up, and resolving various issues. One thing I did notice was that the example&rsquo;s architecture diverges on my dataset, so instead I tested my code using a basic multi-layer perceptron architecture with a single hidden layer. This performs about as well as a random classifier on my dataset, but at least it converges. I also tested the modified code on the MNIST dataset and the results are decent, so now it is time to move forward and actually do some modelling, starting with <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network target=_blank rel=noopener>convolutional neural nets</a>.</p>
<p>The high level plan is to iteratively read tutorials/papers/books, implement ideas, play with parameters, and visualise parts of the network until I&rsquo;m satisfied with the results. The main goal remains to learn as much as possible and get a good intuition of how things work. I&rsquo;ll write more about my experiences in subsequent posts. Stay tuned!</p>
<p><strong>Update</strong>: <a href=http://yanirseroussi.com/2015/07/06/learning-about-deep-learning-through-album-cover-classification/>The second post in the series is now available</a>.</p>
</div>
<footer class=post-footer>
<ul class=post-tags>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/bandcamp/>bandcamp</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/data-science/>data science</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/deep-learning/>deep learning</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/machine-learning/>machine learning</a></li>
<li><a href=https://yanirs.github.io/yanirseroussi.com/tags/predictive-modelling/>predictive modelling</a></li>
</ul>
</footer><section class=comment-section>
<strong>No comments</strong>
<a class=comment-button href="https://github.com/yanirs/yanirseroussi.com/issues/new?title=New comment on https%3a%2f%2fyanirs.github.io%2fyanirseroussi.com%2f2015%2f06%2f06%2fhopping-on-the-deep-learning-bandwagon%2f&body=<!-- Post your comment here and it may get added to the site -->" rel="noopener noreferrer" target=_blank>
Comment via GitHub issue
</a>
</section>
</article>
</main>
<footer class=footer>
<span>&copy; 2021 <a href=https://yanirs.github.io/yanirseroussi.com/>Yanir Seroussi | Data science and beyond</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>